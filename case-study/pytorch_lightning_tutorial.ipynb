{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "BjP7HcLrywDA",
        "6J9mE7HzzSyX",
        "urZIM7GNz7qp",
        "FG6TDDRw2l0s",
        "DaBI9Va_3mfi"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# pytorch擴充包：pytorch-lightning [Video](https://www.youtube.com/watch?v=O7dNXpgdWbo) + [GitHub](https://github.com/kwea123/pytorch-lightning-tutorial)"
      ],
      "metadata": {
        "id": "ec_G3RzrP3Kt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color=\"red\">Step 1--建立`資料夾(名為models)`</font>"
      ],
      "metadata": {
        "id": "BjP7HcLrywDA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir models"
      ],
      "metadata": {
        "id": "BfhEMtGNtBjg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color=\"red\">Step 2--執行`%%writefile models/networks.py`(下一個cell)</font>"
      ],
      "metadata": {
        "id": "6J9mE7HzzSyX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# models資料夾需要是先建立在Colab\n",
        "%%writefile models/networks.py\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "from einops import rearrange, reduce, repeat\n",
        "\n",
        "\n",
        "class LinearModel(nn.Module):\n",
        "    def __init__(self, hidden_dim):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(28 * 28, hidden_dim),\n",
        "            nn.ReLU(True),\n",
        "            nn.Linear(hidden_dim, 10)\n",
        "            )\n",
        "\n",
        "    def forward(self, x): # x 已經用transform=T.ToTensor()轉成tensor，因此x大小不是(B, 28, 28)\n",
        "\n",
        "        # x = x.flatten() #\n",
        "        \"\"\"\n",
        "        x: (B, 1, 28, 28) batch of images\n",
        "        \"\"\"\n",
        "        x = rearrange(x, 'b 1 x y -> b (x y)', x=28, y=28)\n",
        "        # 也可以是 x = rearrange(x, 'b 1 x y -> b (x y)')\n",
        "        return self.net(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0kAm9_pR8OkU",
        "outputId": "b412fdd8-a962-40b3-de72-cf09753c85d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing models/networks.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color=\"red\">Step 3--執行`%%writefile opt.py`(下一個cell)</font>"
      ],
      "metadata": {
        "id": "urZIM7GNz7qp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile opt.py\n",
        "import argparse\n",
        "\n",
        "def get_opts():\n",
        "    parser = argparse.ArgumentParser()\n",
        "\n",
        "    parser.add_argument('--root_dir', type=str, required=True,\n",
        "                        help='root directory of dataset')\n",
        "    parser.add_argument('--hidden_dim', type=int, default=128,\n",
        "                        help='number of hidden dimensions')\n",
        "\n",
        "    parser.add_argument('--val_size', type=int, default=5000,\n",
        "                        help='size of validation set')\n",
        "\n",
        "    parser.add_argument('--batch_size', type=int, default=128,\n",
        "                        help='number of batch size')\n",
        "    parser.add_argument('--lr', type=float, default=1e-4,\n",
        "                        help='learning rate')\n",
        "    parser.add_argument('--num_epochs', type=int, default=10,\n",
        "                        help='number of epochs')\n",
        "    parser.add_argument('--num_workers', type=int, default=4,\n",
        "                        help='number of workers for data loader')\n",
        "\n",
        "    parser.add_argument('--exp_name', type=str, default='exp',\n",
        "                        help='experiment name')\n",
        "\n",
        "    return parser.parse_args()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D8XNJehTaet1",
        "outputId": "dce2ae63-fed5-40e9-e1f3-ae5dae838e40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing opt.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color=\"red\">Step 4--執行`%%writefile train.py`(下一個cell)</font>"
      ],
      "metadata": {
        "id": "jl1CMh2E0N0W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color=\"red\">`train.py`</font>\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "注意：在執行`!python train.py`時, scheduler(在configure_optimizer中)沒法運行，不管是pytorch_lightning==1.6.0 或是 >2 的版本以上，會出現\n",
        "\n",
        "```\n",
        "The provided lr scheduler CosineAnnealingLR doesn't follow PyTorch's LRScheduler API.\n",
        "You should override the LightningModule.lr_scheduler_step hook with your own logic if you are using a custom LR scheduler.\n",
        "```\n",
        "估計是在Colab上pytorch 與 pytorch_lightning 不匹配(在本機上的solution如下一個cell)。\n",
        "\n",
        "因此在使用(Colab)當下default torch版本，`train.py`不使用scheduler，pytorch_lightning==1.6.0\n"
      ],
      "metadata": {
        "id": "FG6TDDRw2l0s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "若在本機在執行`python train.py`關於錯誤\n",
        "```\n",
        "pytorch_lightning.utilities.exceptions.MisconfigurationException:\n",
        "The provided lr scheduler `CosineAnnealingLR` doesn't follow PyTorch's LRScheduler API.\n",
        "You should override the `LightningModule.lr_scheduler_step` hook with your own logic if you are using a custom LR scheduler.\n",
        "```\n",
        "的[解決方法之一](https://blog.csdn.net/yangyu0515/article/details/131945195)(用在本機)\n"
      ],
      "metadata": {
        "id": "rZsuil3bcNdy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile train.py\n",
        "import torch\n",
        "from torch.nn import functional as F\n",
        "\n",
        "from opt import get_opts\n",
        "\n",
        "# datasets\n",
        "from torchvision.datasets import MNIST\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision import transforms as T\n",
        "\n",
        "# models\n",
        "from models.networks import LinearModel\n",
        "\n",
        "# optimizer\n",
        "from torch.optim import Adam\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "\n",
        "from pytorch_lightning import LightningModule, Trainer, seed_everything\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint, TQDMProgressBar\n",
        "from pytorch_lightning.loggers import TensorBoardLogger\n",
        "\n",
        "seed_everything(1234, workers=True) # 固定所有的亂數。workers=True讓取data也會是固定的，而非亂數\n",
        "\n",
        "\n",
        "def get_learning_rate(optimizer):\n",
        "    for param_group in optimizer.param_groups:\n",
        "        return param_group['lr']\n",
        "\n",
        "\n",
        "class MNISTSystem(LightningModule):\n",
        "    def __init__(self, hparams):\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters(hparams) # 將使用過的 hyperparameters 都存起來\n",
        "\n",
        "        # 定義模型：\n",
        "        # self.net = nn.Sequential(\n",
        "        #     nn.Linear(28*28, self.hparams.hidden_dim),\n",
        "        #     nn.ReLU(True),\n",
        "        #     nn.Linear(self.hparams.hidden_dim, 10)\n",
        "        # )\n",
        "\n",
        "        # 定義模型：由分開的檔案(models/networks.py)存放模型，再引入\n",
        "        self.net = LinearModel(self.hparams.hidden_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # 改變x的形狀大小。此步驟移至分開的檔案(models/networks.py)\n",
        "        # x = rearrange(x, 'b 1 x y -> b (x y)', x=28, y=28)\n",
        "        return self.net(x)\n",
        "\n",
        "    def prepare_data(self): # 下載資料\n",
        "        \"\"\"\n",
        "        download data once (下載資料--只會執行一次)\n",
        "        \"\"\"\n",
        "        MNIST(self.hparams.root_dir, train=True, download=True)\n",
        "        MNIST(self.hparams.root_dir, train=False, download=True)\n",
        "\n",
        "    def setup(self, stage=None): # 讀取資料\n",
        "        \"\"\"\n",
        "        setup dataset for each machine (分配資料到每一個運行的實際硬體單元--會執行多次)\n",
        "        \"\"\"\n",
        "        dataset = MNIST(self.hparams.root_dir,\n",
        "                  train=True,\n",
        "                  download=False,\n",
        "                  transform=T.ToTensor())\n",
        "        train_length = len(dataset) # 60000\n",
        "        self.train_dataset, self.val_dataset = \\\n",
        "            random_split(dataset,\n",
        "                   [train_length-self.hparams.val_size, self.hparams.val_size])\n",
        "\n",
        "    def train_dataloader(self): # 定義loader (訓練)\n",
        "        return DataLoader(self.train_dataset,\n",
        "                  shuffle=True,\n",
        "                  num_workers=self.hparams.num_workers, # 與GPU數目有關\n",
        "                  batch_size=self.hparams.batch_size, # batch_size並非無上限，理論上是不能超過(GPU)memory大小\n",
        "                  pin_memory=True) # 使用GPU時，用pin_memory運行，速度會較快\n",
        "\n",
        "    def val_dataloader(self): # 定義loader (檢驗)\n",
        "        return DataLoader(self.val_dataset,\n",
        "                  shuffle=False,\n",
        "                  num_workers=self.hparams.num_workers,\n",
        "                  batch_size=self.hparams.batch_size,\n",
        "                  pin_memory=True)\n",
        "\n",
        "    def configure_optimizers(self): # 定義：使用何種方法進行梯度下降處理(設定優化器)\n",
        "        self.optimizer = Adam(self.net.parameters(), lr=self.hparams.lr) # self.net.parameters()，把前面定義的模型之參數放入\n",
        "\n",
        "        # scheduler = CosineAnnealingLR(self.optimizer,\n",
        "        #                  T_max=self.hparams.num_epochs, # 最大訓練epochs的量\n",
        "        #                  eta_min=self.hparams.lr/1e2)  # 最小學習率\n",
        "\n",
        "        # return [self.optimizer], [scheduler]\n",
        "        # return [optimizer_A, optimizer_B],[scheduler_A, scheduler_B] # 在GAN中就可以這麼用\n",
        "        return self.optimizer # 如果沒用scheduler，可以只回傳optimizer\n",
        "\n",
        "    def training_step(self, batch, batch_idx): # batch 來自 train_dataloader，batch_idx就是batch的編號，少用到（可以不用）\n",
        "        images, labels = batch # 圖片資料, 圖片標籤(對應的one-hot vector)\n",
        "        logits_predicted = self(images) # self()會呼叫forward()函數來執行\n",
        "\n",
        "        loss = F.cross_entropy(logits_predicted, labels)\n",
        "\n",
        "        self.log('lr', get_learning_rate(self.optimizer))\n",
        "        self.log('train/loss', loss) # 如果要顯示loss 的progress bar 進度，可加參數`prog_bar=True`\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx): # batch_idx會被使用到的情況，通常是為了紀錄log時\n",
        "        images, labels = batch\n",
        "        logits_predicted = self(images)\n",
        "\n",
        "        loss = F.cross_entropy(logits_predicted, labels)\n",
        "        acc = torch.sum(torch.eq(torch.argmax(logits_predicted, -1), labels).to(torch.float32)) / len(labels)\n",
        "\n",
        "        log = {'val_loss': loss,\n",
        "             'val_acc': acc}\n",
        "\n",
        "        return log\n",
        "\n",
        "    def validation_epoch_end(self, outputs):\n",
        "        mean_loss = torch.stack([x['val_loss'] for x in outputs]).mean()\n",
        "        mean_acc = torch.stack([x['val_acc'] for x in outputs]).mean()\n",
        "\n",
        "        self.log('val/loss', mean_loss, prog_bar=True)\n",
        "        self.log('val/acc', mean_acc, prog_bar=True)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    hparams = get_opts()\n",
        "    mnistsystem = MNISTSystem(hparams)\n",
        "\n",
        "    # 模型保存點\n",
        "    ckpt_cb = ModelCheckpoint(dirpath=f'ckpts/{hparams.exp_name}', # 設定模型保存路徑(每個實驗都有各自的名稱)\n",
        "                   filename='{epoch:d}',\n",
        "                   monitor='val/acc', # 檢測 val/acc。如果檢測 val/loss，則mode設為min\n",
        "                   mode='max',     # 最大\n",
        "                   save_top_k=5)    # 5筆（若要全部保存，就設為-1）\n",
        "    pbar = TQDMProgressBar(refresh_rate=1)     # 一步就更新進度條\n",
        "    callbacks = [ckpt_cb, pbar]\n",
        "\n",
        "    # 設定log記錄點\n",
        "    logger = TensorBoardLogger(save_dir=\"logs\",     # 設定檔案夾\n",
        "                   name=hparams.exp_name,  # 實驗名稱\n",
        "                   default_hp_metric=False)\n",
        "\n",
        "    trainer = Trainer(max_epochs=hparams.num_epochs, # 設定最大epochs數\n",
        "              callbacks=callbacks,       # 保存點與進度條\n",
        "              # resume_from_checkpoint= hparams.ckpt_path, # 訓練中斷，可保存中斷點，重啟時可從此保存點繼續訓練\n",
        "              logger=logger,          # 紀錄log的地方\n",
        "              enable_model_summary=True,    # 開始顯示模型的初始構造\n",
        "              accelerator='auto',        # 自動偵測要使用GPU或是CPU\n",
        "              devices=1,             # 多少GPU\n",
        "              num_sanity_val_steps=1,      # 開始訓練前，指定先運行val的次數\n",
        "              benchmark=True,   # 使用CUDN(深度學習框架)為True時，input尺度相同時，會找出最好的演算法使速度加快\n",
        "              # profile='simple',      # 顯示訓練時，不同步驟所需的時間，可用以improvement(如果使用，會顯示很多)\n",
        "              )\n",
        "    # 啟動訓練\n",
        "    trainer.fit(mnistsystem)"
      ],
      "metadata": {
        "id": "ECSYlQVtzvFD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb6b65fd-2bcc-4619-b000-1b4bbc0deced"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing train.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color=\"red\">`train_u.py`</font>"
      ],
      "metadata": {
        "id": "ozqS7EdR2XUe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "前面提到，由於在Colab執行`python train.py`(原始)時，會出現關於scheduler的問題，因此安裝 pytorch_lightning > 2.0 版本，但執行`python train.py`(原始)又會出現新的錯誤(如下)\n",
        "\n",
        "```\n",
        "NotImplementedError: Support for `validation_epoch_end` has been removed in v2.0.0. `MNISTSystem` implements this method.\n",
        "You can use the `on_validation_epoch_end` hook instead. To access outputs, save them in-memory as instance attributes.\n",
        "You can find migration examples in https://github.com/Lightning-AI/lightning/pull/16520.\n",
        "```\n",
        "`train_u.py`主要是把 `def validation_epoch_end(self, outputs): `改成 `def on_validation_epoch_end(self):` ，還有其他兩處，共修改三處，如此就可以在Colab中正常使用\n",
        "\n"
      ],
      "metadata": {
        "id": "pHT7439VDlOs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e-GS32EeIp-s",
        "outputId": "cfd7075e-6678-4582-dc4c-05079bbea658"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing train_u.py\n"
          ]
        }
      ],
      "source": [
        "# %%writefile train_u.py\n",
        "import torch\n",
        "from torch.nn import functional as F\n",
        "\n",
        "from opt import get_opts\n",
        "\n",
        "# datasets\n",
        "from torchvision.datasets import MNIST\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision import transforms as T\n",
        "\n",
        "# models\n",
        "from models.networks import LinearModel\n",
        "\n",
        "# optimizer\n",
        "from torch.optim import Adam\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "\n",
        "from pytorch_lightning import LightningModule, Trainer, seed_everything\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint, TQDMProgressBar\n",
        "from pytorch_lightning.loggers import TensorBoardLogger\n",
        "\n",
        "seed_everything(1234, workers=True) # 固定所有的亂數。workers=True讓取data也會是固定的，而非亂數\n",
        "\n",
        "\n",
        "def get_learning_rate(optimizer):\n",
        "    for param_group in optimizer.param_groups:\n",
        "        return param_group['lr']\n",
        "\n",
        "\n",
        "class MNISTSystem(LightningModule):\n",
        "    def __init__(self, hparams):\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters(hparams) # 將使用過的 hyperparameters 都存起來\n",
        "        '''為了configure_optimizers(self)的scheduler'''\n",
        "        self.validation_step_outputs = []\n",
        "        # 定義模型：\n",
        "        # self.net = nn.Sequential(\n",
        "        #     nn.Linear(28*28, self.hparams.hidden_dim),\n",
        "        #     nn.ReLU(True),\n",
        "        #     nn.Linear(self.hparams.hidden_dim, 10)\n",
        "        # )\n",
        "\n",
        "        # 定義模型：由分開的檔案(models/networks.py)存放模型，再引入\n",
        "        self.net = LinearModel(self.hparams.hidden_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # 改變x的形狀大小。此步驟移至分開的檔案(models/networks.py)\n",
        "        # x = rearrange(x, 'b 1 x y -> b (x y)', x=28, y=28)\n",
        "        return self.net(x)\n",
        "\n",
        "    def prepare_data(self): # 下載資料\n",
        "        \"\"\"\n",
        "        download data once (下載資料--只會執行一次)\n",
        "        \"\"\"\n",
        "        MNIST(self.hparams.root_dir, train=True, download=True)\n",
        "        MNIST(self.hparams.root_dir, train=False, download=True)\n",
        "\n",
        "    def setup(self, stage=None): # 讀取資料\n",
        "        \"\"\"\n",
        "        setup dataset for each machine (分配資料到每一個運行的實際硬體單元--會執行多次)\n",
        "        \"\"\"\n",
        "        dataset = MNIST(self.hparams.root_dir,\n",
        "                  train=True,\n",
        "                  download=False,\n",
        "                  transform=T.ToTensor())\n",
        "        train_length = len(dataset) # 60000\n",
        "        self.train_dataset, self.val_dataset = \\\n",
        "            random_split(dataset,\n",
        "                   [train_length-self.hparams.val_size, self.hparams.val_size])\n",
        "\n",
        "    def train_dataloader(self): # 定義loader (訓練)\n",
        "        return DataLoader(self.train_dataset,\n",
        "                  shuffle=True,\n",
        "                  num_workers=self.hparams.num_workers, # 與GPU數目有關\n",
        "                  batch_size=self.hparams.batch_size, # batch_size並非無上限，理論上是不能超過(GPU)memory大小\n",
        "                  pin_memory=True) # 使用GPU時，用pin_memory運行，速度會較快\n",
        "\n",
        "    def val_dataloader(self): # 定義loader (檢驗)\n",
        "        return DataLoader(self.val_dataset,\n",
        "                  shuffle=False,\n",
        "                  num_workers=self.hparams.num_workers,\n",
        "                  batch_size=self.hparams.batch_size,\n",
        "                  pin_memory=True)\n",
        "\n",
        "    def configure_optimizers(self): # 定義：使用何種方法進行梯度下降處理(設定優化器)\n",
        "        self.optimizer = Adam(self.net.parameters(), lr=self.hparams.lr) # self.net.parameters()，把前面定義的模型之參數放入\n",
        "\n",
        "        scheduler = CosineAnnealingLR(self.optimizer,\n",
        "                         T_max=self.hparams.num_epochs, # 最大訓練epochs的量\n",
        "                         eta_min=self.hparams.lr/1e2)  # 最小學習率\n",
        "\n",
        "        # scheduler = CosineAnnealingLR(self.optimizer, T_max=20, eta_min = 1e-5)\n",
        "\n",
        "        return [self.optimizer], [scheduler]\n",
        "        # return [optimizer_A, optimizer_B],[scheduler_A, scheduler_B] # 在GAN中就可以這麼用\n",
        "        # return self.optimizer # 如果沒用scheduler，可以只回傳optimizer\n",
        "\n",
        "    def training_step(self, batch, batch_idx): # batch 來自 train_dataloader，batch_idx就是batch的編號，少用到（可以不用）\n",
        "        images, labels = batch # 圖片資料, 圖片標籤(對應的one-hot vector)\n",
        "        logits_predicted = self(images) # self()會呼叫forward()函數來執行\n",
        "\n",
        "        loss = F.cross_entropy(logits_predicted, labels)\n",
        "\n",
        "        self.log('lr', get_learning_rate(self.optimizer))\n",
        "        self.log('train/loss', loss) # 如果要顯示loss 的progress bar 進度，可加參數`prog_bar=True`\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx): # batch_idx會被使用到的情況，通常是為了紀錄log時\n",
        "        images, labels = batch\n",
        "        logits_predicted = self(images)\n",
        "\n",
        "        loss = F.cross_entropy(logits_predicted, labels)\n",
        "        acc = torch.sum(torch.eq(torch.argmax(logits_predicted, -1), labels).to(torch.float32)) / len(labels)\n",
        "\n",
        "        log = {'val_loss': loss,\n",
        "             'val_acc': acc}\n",
        "\n",
        "        self.validation_step_outputs.append(log)\n",
        "\n",
        "        return log\n",
        "\n",
        "    '''原本是validation_epoch_end(self)，為了configure_optimizers(self)的scheduler而改'''\n",
        "    def on_validation_epoch_end(self):\n",
        "        '''為了configure_optimizers(self)的scheduler'''\n",
        "        outputs = self.validation_step_outputs\n",
        "        mean_loss = torch.stack([x['val_loss'] for x in outputs]).mean()\n",
        "        mean_acc = torch.stack([x['val_acc'] for x in outputs]).mean()\n",
        "\n",
        "        self.log('val/loss', mean_loss, prog_bar=True)\n",
        "        self.log('val/acc', mean_acc, prog_bar=True)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    hparams = get_opts()\n",
        "    mnistsystem = MNISTSystem(hparams)\n",
        "\n",
        "    # 模型保存點\n",
        "    ckpt_cb = ModelCheckpoint(dirpath=f'ckpts/{hparams.exp_name}', # 設定模型保存路徑(每個實驗都有各自的名稱)\n",
        "                   filename='{epoch:d}',\n",
        "                   monitor='val/acc', # 檢測 val/acc。如果檢測 val/loss，則mode設為min\n",
        "                   mode='max',     # 最大\n",
        "                   save_top_k=5)    # 5筆（若要全部保存，就設為-1）\n",
        "    pbar = TQDMProgressBar(refresh_rate=1)     # 一步就更新進度條\n",
        "    callbacks = [ckpt_cb, pbar]\n",
        "\n",
        "    # 設定log記錄點\n",
        "    logger = TensorBoardLogger(save_dir=\"logs\",     # 設定檔案夾\n",
        "                   name=hparams.exp_name,  # 實驗名稱\n",
        "                   default_hp_metric=False)\n",
        "\n",
        "    trainer = Trainer(max_epochs=hparams.num_epochs, # 設定最大epochs數\n",
        "              callbacks=callbacks,       # 保存點與進度條\n",
        "              # resume_from_checkpoint= hparams.ckpt_path, # 訓練中斷，可保存中斷點，重啟時可從此保存點繼續訓練\n",
        "              logger=logger,          # 紀錄log的地方\n",
        "              enable_model_summary=True,    # 開始顯示模型的初始構造\n",
        "              accelerator='auto',        # 自動偵測要使用GPU或是CPU\n",
        "              devices=1,             # 多少GPU\n",
        "              num_sanity_val_steps=1,      # 開始訓練前，指定先運行val的次數\n",
        "              benchmark=True,   # 使用CUDN(深度學習框架)為True時，input尺度相同時，會找出最好的演算法使速度加快\n",
        "              # profile='simple',      # 顯示訓練時，不同步驟所需的時間，可用以improvement(如果使用，會顯示很多)\n",
        "              )\n",
        "    # 啟動訓練\n",
        "    trainer.fit(mnistsystem)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```python\n",
        "for param_group in optimizer.param_groups:\n",
        "  return param_group['lr']\n",
        "\n",
        "# optimizer.param_groups長相，舉例\n",
        "[{'amsgrad': False,\n",
        "  'betas': (0.9, 0.999),\n",
        "  'eps': 1e-08,\n",
        "  'lr': 0.001,\n",
        "  'params': [tensor([[ 2.9064, -0.2141, -0.4037],\n",
        "           [-0.5718,  1.0375, -0.6862],\n",
        "           [-0.8372,  0.4380, -0.1572]])],\n",
        "  'weight_decay': 0}]\n",
        "```\n",
        "[optimizer.param_groups的參考](https://www.jb51.net/article/213735.htm)\n",
        "\n"
      ],
      "metadata": {
        "id": "XHehgFW_SaLZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color=\"red\">Step 5--安裝`pytorch_lightning`與`einops`</font>"
      ],
      "metadata": {
        "id": "QxbF5vQs2DDg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "注意，此`train.py`(原始)有修改一處，不執行在configure_optimizer中scheduler，以下實驗是配合`pytorch_lightning==1.6.0`"
      ],
      "metadata": {
        "id": "HchekPKsYo21"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch_lightning==1.6.0 --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k6ECwBmC0l2g",
        "outputId": "1ead5fbc-4770-4999-adae-3cfe1940b1a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m582.1/582.1 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m840.4/840.4 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch_lightning==2.0.0 --quiet\n",
        "# !pip install pytorch_lightning==2.0.1.post0 --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0QNK44DDtQX3",
        "outputId": "d408576e-6643-4c25-f36e-e43f93f77cf3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m715.6/715.6 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m840.4/840.4 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install einops==0.4.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "svPuq-P0zJuD",
        "outputId": "7278847f-2e2b-4e62-f935-1b7c3ecdc6d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting einops==0.4.1\n",
            "  Downloading einops-0.4.1-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: einops\n",
            "Successfully installed einops-0.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 測試用\n",
        "# import pytorch_lightning\n",
        "# pytorch_lightning.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "M6TWp939dYnI",
        "outputId": "d4bc4739-2115-47b4-a11e-b04300cffaa3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.0.1.post0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color=\"red\">Step 6 -- 執行 `!python train.py 選項`(下一個cell)</font>"
      ],
      "metadata": {
        "id": "RDCaO5UU3Zyf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color=\"red\">執行`train.py`</font>"
      ],
      "metadata": {
        "id": "DaBI9Va_3mfi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --root_dir \"./\" --num_epoch 50 --exp_name train_50"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5koia-QEURwB",
        "outputId": "4fdda22c-153f-469a-e70e-1bd3d1398d74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-03-07 05:43:07.095839: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-03-07 05:43:07.095897: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-03-07 05:43:07.097745: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-03-07 05:43:08.235550: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Global seed set to 1234\n",
            "GPU available: True, used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./MNIST/raw/train-images-idx3-ubyte.gz\n",
            "100% 9912422/9912422 [00:00<00:00, 100357760.53it/s]\n",
            "Extracting ./MNIST/raw/train-images-idx3-ubyte.gz to ./MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "100% 28881/28881 [00:00<00:00, 143866619.74it/s]\n",
            "Extracting ./MNIST/raw/train-labels-idx1-ubyte.gz to ./MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./MNIST/raw/t10k-images-idx3-ubyte.gz\n",
            "100% 1648877/1648877 [00:00<00:00, 38607147.66it/s]\n",
            "Extracting ./MNIST/raw/t10k-images-idx3-ubyte.gz to ./MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "100% 4542/4542 [00:00<00:00, 32454052.42it/s]\n",
            "Extracting ./MNIST/raw/t10k-labels-idx1-ubyte.gz to ./MNIST/raw\n",
            "\n",
            "Missing logger folder: logs/train_50\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name | Type        | Params\n",
            "-------------------------------------\n",
            "0 | net  | LinearModel | 101 K \n",
            "-------------------------------------\n",
            "101 K     Trainable params\n",
            "0         Non-trainable params\n",
            "101 K     Total params\n",
            "0.407     Total estimated model params size (MB)\n",
            "Sanity Checking: 0it [00:00, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Epoch 0:  91% 430/470 [00:07<00:00, 54.81it/s, loss=0.624, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 0:  96% 450/470 [00:08<00:00, 52.70it/s, loss=0.624, v_num=0]\n",
            "Epoch 0: 100% 470/470 [00:08<00:00, 52.90it/s, loss=0.624, v_num=0, val/loss=0.614, val/acc=0.865]\n",
            "Epoch 1:  91% 430/470 [00:15<00:01, 27.33it/s, loss=0.431, v_num=0, val/loss=0.614, val/acc=0.865]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 1:  96% 450/470 [00:16<00:00, 27.86it/s, loss=0.431, v_num=0, val/loss=0.614, val/acc=0.865]\n",
            "Epoch 1: 100% 470/470 [00:16<00:00, 28.65it/s, loss=0.431, v_num=0, val/loss=0.404, val/acc=0.896]\n",
            "Epoch 2:  91% 430/470 [00:24<00:02, 17.71it/s, loss=0.363, v_num=0, val/loss=0.404, val/acc=0.896]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2:  96% 450/470 [00:24<00:01, 18.22it/s, loss=0.363, v_num=0, val/loss=0.404, val/acc=0.896]\n",
            "Epoch 2: 100% 470/470 [00:24<00:00, 18.84it/s, loss=0.363, v_num=0, val/loss=0.337, val/acc=0.911]\n",
            "Epoch 3:  91% 430/470 [00:32<00:02, 13.37it/s, loss=0.292, v_num=0, val/loss=0.337, val/acc=0.911]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 3:  96% 450/470 [00:32<00:01, 13.71it/s, loss=0.292, v_num=0, val/loss=0.337, val/acc=0.911]\n",
            "Epoch 3: 100% 470/470 [00:33<00:00, 14.16it/s, loss=0.292, v_num=0, val/loss=0.303, val/acc=0.917]\n",
            "Epoch 4:  91% 430/470 [00:40<00:03, 10.60it/s, loss=0.282, v_num=0, val/loss=0.303, val/acc=0.917]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 4:  96% 450/470 [00:41<00:01, 10.97it/s, loss=0.282, v_num=0, val/loss=0.303, val/acc=0.917]\n",
            "Epoch 4: 100% 470/470 [00:41<00:00, 11.40it/s, loss=0.282, v_num=0, val/loss=0.282, val/acc=0.922]\n",
            "Epoch 5:  91% 430/470 [00:49<00:04,  8.75it/s, loss=0.256, v_num=0, val/loss=0.282, val/acc=0.922]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 5:  96% 450/470 [00:49<00:02,  9.07it/s, loss=0.256, v_num=0, val/loss=0.282, val/acc=0.922]\n",
            "Epoch 5: 100% 470/470 [00:49<00:00,  9.43it/s, loss=0.256, v_num=0, val/loss=0.266, val/acc=0.925]\n",
            "Epoch 6:  91% 430/470 [00:56<00:05,  7.58it/s, loss=0.265, v_num=0, val/loss=0.266, val/acc=0.925]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 6:  96% 450/470 [00:57<00:02,  7.87it/s, loss=0.265, v_num=0, val/loss=0.266, val/acc=0.925]\n",
            "Epoch 6: 100% 470/470 [00:57<00:00,  8.19it/s, loss=0.265, v_num=0, val/loss=0.251, val/acc=0.929]\n",
            "Epoch 7:  91% 430/470 [01:05<00:06,  6.52it/s, loss=0.241, v_num=0, val/loss=0.251, val/acc=0.929]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 7:  96% 450/470 [01:06<00:02,  6.77it/s, loss=0.241, v_num=0, val/loss=0.251, val/acc=0.929]\n",
            "Epoch 7: 100% 470/470 [01:06<00:00,  7.05it/s, loss=0.241, v_num=0, val/loss=0.239, val/acc=0.931]\n",
            "Epoch 8:  91% 430/470 [01:14<00:06,  5.76it/s, loss=0.238, v_num=0, val/loss=0.239, val/acc=0.931]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 8:  96% 450/470 [01:15<00:03,  6.00it/s, loss=0.238, v_num=0, val/loss=0.239, val/acc=0.931]\n",
            "Epoch 8: 100% 470/470 [01:15<00:00,  6.24it/s, loss=0.238, v_num=0, val/loss=0.227, val/acc=0.934]\n",
            "Epoch 9:  91% 430/470 [01:22<00:07,  5.23it/s, loss=0.233, v_num=0, val/loss=0.227, val/acc=0.934]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 9:  96% 450/470 [01:22<00:03,  5.44it/s, loss=0.233, v_num=0, val/loss=0.227, val/acc=0.934]\n",
            "Epoch 9: 100% 470/470 [01:22<00:00,  5.67it/s, loss=0.233, v_num=0, val/loss=0.219, val/acc=0.939]\n",
            "Epoch 10:  91% 430/470 [01:30<00:08,  4.73it/s, loss=0.219, v_num=0, val/loss=0.219, val/acc=0.939]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 10:  96% 450/470 [01:31<00:04,  4.92it/s, loss=0.219, v_num=0, val/loss=0.219, val/acc=0.939]\n",
            "Epoch 10: 100% 470/470 [01:31<00:00,  5.13it/s, loss=0.219, v_num=0, val/loss=0.210, val/acc=0.940]\n",
            "Epoch 11:  91% 430/470 [01:39<00:09,  4.31it/s, loss=0.19, v_num=0, val/loss=0.210, val/acc=0.940] \n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 11:  96% 450/470 [01:40<00:04,  4.49it/s, loss=0.19, v_num=0, val/loss=0.210, val/acc=0.940]\n",
            "Epoch 11: 100% 470/470 [01:40<00:00,  4.68it/s, loss=0.19, v_num=0, val/loss=0.200, val/acc=0.942]\n",
            "Epoch 12:  91% 430/470 [01:47<00:09,  4.01it/s, loss=0.194, v_num=0, val/loss=0.200, val/acc=0.942]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 12:  96% 450/470 [01:47<00:04,  4.17it/s, loss=0.194, v_num=0, val/loss=0.200, val/acc=0.942]\n",
            "Epoch 12: 100% 470/470 [01:48<00:00,  4.35it/s, loss=0.194, v_num=0, val/loss=0.194, val/acc=0.944]\n",
            "Epoch 13:  91% 430/470 [01:55<00:10,  3.71it/s, loss=0.167, v_num=0, val/loss=0.194, val/acc=0.944]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 13:  96% 450/470 [01:56<00:05,  3.87it/s, loss=0.167, v_num=0, val/loss=0.194, val/acc=0.944]\n",
            "Epoch 13: 100% 470/470 [01:56<00:00,  4.03it/s, loss=0.167, v_num=0, val/loss=0.188, val/acc=0.945]\n",
            "Epoch 14:  91% 430/470 [02:04<00:11,  3.46it/s, loss=0.185, v_num=0, val/loss=0.188, val/acc=0.945]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 14:  96% 450/470 [02:05<00:05,  3.60it/s, loss=0.185, v_num=0, val/loss=0.188, val/acc=0.945]\n",
            "Epoch 14: 100% 470/470 [02:05<00:00,  3.75it/s, loss=0.185, v_num=0, val/loss=0.180, val/acc=0.948]\n",
            "Epoch 15:  91% 430/470 [02:12<00:12,  3.25it/s, loss=0.164, v_num=0, val/loss=0.180, val/acc=0.948]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 15:  96% 450/470 [02:12<00:05,  3.38it/s, loss=0.164, v_num=0, val/loss=0.180, val/acc=0.948]\n",
            "Epoch 15: 100% 470/470 [02:13<00:00,  3.53it/s, loss=0.164, v_num=0, val/loss=0.175, val/acc=0.949]\n",
            "Epoch 16:  91% 430/470 [02:21<00:13,  3.05it/s, loss=0.128, v_num=0, val/loss=0.175, val/acc=0.949]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 16:  96% 450/470 [02:21<00:06,  3.18it/s, loss=0.128, v_num=0, val/loss=0.175, val/acc=0.949]\n",
            "Epoch 16: 100% 470/470 [02:21<00:00,  3.31it/s, loss=0.128, v_num=0, val/loss=0.169, val/acc=0.952]\n",
            "Epoch 17:  91% 430/470 [02:29<00:13,  2.88it/s, loss=0.161, v_num=0, val/loss=0.169, val/acc=0.952]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 17:  96% 450/470 [02:29<00:06,  3.00it/s, loss=0.161, v_num=0, val/loss=0.169, val/acc=0.952]\n",
            "Epoch 17: 100% 470/470 [02:30<00:00,  3.13it/s, loss=0.161, v_num=0, val/loss=0.164, val/acc=0.952]\n",
            "Epoch 18:  91% 430/470 [02:37<00:14,  2.73it/s, loss=0.166, v_num=0, val/loss=0.164, val/acc=0.952]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 18:  96% 450/470 [02:38<00:07,  2.84it/s, loss=0.166, v_num=0, val/loss=0.164, val/acc=0.952]\n",
            "Epoch 18: 100% 470/470 [02:38<00:00,  2.97it/s, loss=0.166, v_num=0, val/loss=0.158, val/acc=0.954]\n",
            "Epoch 19:  91% 430/470 [02:46<00:15,  2.58it/s, loss=0.136, v_num=0, val/loss=0.158, val/acc=0.954]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 19:  96% 450/470 [02:46<00:07,  2.69it/s, loss=0.136, v_num=0, val/loss=0.158, val/acc=0.954]\n",
            "Epoch 19: 100% 470/470 [02:47<00:00,  2.81it/s, loss=0.136, v_num=0, val/loss=0.156, val/acc=0.954]\n",
            "Epoch 20:  91% 430/470 [02:54<00:16,  2.47it/s, loss=0.129, v_num=0, val/loss=0.156, val/acc=0.954]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 20:  96% 450/470 [02:54<00:07,  2.57it/s, loss=0.129, v_num=0, val/loss=0.156, val/acc=0.954]\n",
            "Epoch 20: 100% 470/470 [02:55<00:00,  2.68it/s, loss=0.129, v_num=0, val/loss=0.151, val/acc=0.956]\n",
            "Epoch 21:  91% 430/470 [03:03<00:17,  2.35it/s, loss=0.147, v_num=0, val/loss=0.151, val/acc=0.956]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 21:  96% 450/470 [03:03<00:08,  2.45it/s, loss=0.147, v_num=0, val/loss=0.151, val/acc=0.956]\n",
            "Epoch 21: 100% 470/470 [03:03<00:00,  2.56it/s, loss=0.147, v_num=0, val/loss=0.147, val/acc=0.958]\n",
            "Epoch 22:  91% 430/470 [03:11<00:17,  2.24it/s, loss=0.136, v_num=0, val/loss=0.147, val/acc=0.958]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 22:  96% 450/470 [03:12<00:08,  2.34it/s, loss=0.136, v_num=0, val/loss=0.147, val/acc=0.958]\n",
            "Epoch 22: 100% 470/470 [03:12<00:00,  2.44it/s, loss=0.136, v_num=0, val/loss=0.143, val/acc=0.959]\n",
            "Epoch 23:  91% 430/470 [03:19<00:18,  2.16it/s, loss=0.117, v_num=0, val/loss=0.143, val/acc=0.959]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 23:  96% 450/470 [03:20<00:08,  2.25it/s, loss=0.117, v_num=0, val/loss=0.143, val/acc=0.959]\n",
            "Epoch 23: 100% 470/470 [03:20<00:00,  2.35it/s, loss=0.117, v_num=0, val/loss=0.139, val/acc=0.958]\n",
            "Epoch 24:  91% 430/470 [03:28<00:19,  2.07it/s, loss=0.136, v_num=0, val/loss=0.139, val/acc=0.958]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 24:  96% 450/470 [03:28<00:09,  2.16it/s, loss=0.136, v_num=0, val/loss=0.139, val/acc=0.958]\n",
            "Epoch 24: 100% 470/470 [03:28<00:00,  2.25it/s, loss=0.136, v_num=0, val/loss=0.137, val/acc=0.959]\n",
            "Epoch 25:  91% 430/470 [03:37<00:20,  1.98it/s, loss=0.107, v_num=0, val/loss=0.137, val/acc=0.959]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 25:  96% 450/470 [03:37<00:09,  2.07it/s, loss=0.107, v_num=0, val/loss=0.137, val/acc=0.959]\n",
            "Epoch 25: 100% 470/470 [03:37<00:00,  2.16it/s, loss=0.107, v_num=0, val/loss=0.133, val/acc=0.961]\n",
            "Epoch 26:  91% 430/470 [03:44<00:20,  1.91it/s, loss=0.112, v_num=0, val/loss=0.133, val/acc=0.961]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 26:  96% 450/470 [03:45<00:10,  2.00it/s, loss=0.112, v_num=0, val/loss=0.133, val/acc=0.961]\n",
            "Epoch 26: 100% 470/470 [03:45<00:00,  2.09it/s, loss=0.112, v_num=0, val/loss=0.130, val/acc=0.960]\n",
            "Epoch 27:  91% 430/470 [03:53<00:21,  1.84it/s, loss=0.103, v_num=0, val/loss=0.130, val/acc=0.960]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 27:  96% 450/470 [03:53<00:10,  1.93it/s, loss=0.103, v_num=0, val/loss=0.130, val/acc=0.960]\n",
            "Epoch 27: 100% 470/470 [03:53<00:00,  2.01it/s, loss=0.103, v_num=0, val/loss=0.128, val/acc=0.962]\n",
            "Epoch 28:  91% 430/470 [04:01<00:22,  1.78it/s, loss=0.109, v_num=0, val/loss=0.128, val/acc=0.962]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 28:  96% 450/470 [04:02<00:10,  1.86it/s, loss=0.109, v_num=0, val/loss=0.128, val/acc=0.962]\n",
            "Epoch 28: 100% 470/470 [04:02<00:00,  1.94it/s, loss=0.109, v_num=0, val/loss=0.126, val/acc=0.963]\n",
            "Epoch 29:  91% 430/470 [04:09<00:23,  1.72it/s, loss=0.108, v_num=0, val/loss=0.126, val/acc=0.963]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 29:  96% 450/470 [04:10<00:11,  1.80it/s, loss=0.108, v_num=0, val/loss=0.126, val/acc=0.963]\n",
            "Epoch 29: 100% 470/470 [04:10<00:00,  1.88it/s, loss=0.108, v_num=0, val/loss=0.123, val/acc=0.963]\n",
            "Epoch 30:  91% 430/470 [04:18<00:24,  1.66it/s, loss=0.0989, v_num=0, val/loss=0.123, val/acc=0.963]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 30:  96% 450/470 [04:19<00:11,  1.74it/s, loss=0.0989, v_num=0, val/loss=0.123, val/acc=0.963]\n",
            "Epoch 30: 100% 470/470 [04:19<00:00,  1.81it/s, loss=0.0989, v_num=0, val/loss=0.121, val/acc=0.964]\n",
            "Epoch 31:  91% 430/470 [04:27<00:24,  1.61it/s, loss=0.098, v_num=0, val/loss=0.121, val/acc=0.964]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 31:  96% 450/470 [04:28<00:11,  1.68it/s, loss=0.098, v_num=0, val/loss=0.121, val/acc=0.964]\n",
            "Epoch 31: 100% 470/470 [04:28<00:00,  1.75it/s, loss=0.098, v_num=0, val/loss=0.120, val/acc=0.964]\n",
            "Epoch 32:  91% 430/470 [04:35<00:25,  1.56it/s, loss=0.103, v_num=0, val/loss=0.120, val/acc=0.964]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 32:  96% 450/470 [04:35<00:12,  1.63it/s, loss=0.103, v_num=0, val/loss=0.120, val/acc=0.964]\n",
            "Epoch 32: 100% 470/470 [04:36<00:00,  1.70it/s, loss=0.103, v_num=0, val/loss=0.118, val/acc=0.966]\n",
            "Epoch 33:  91% 430/470 [04:44<00:26,  1.51it/s, loss=0.11, v_num=0, val/loss=0.118, val/acc=0.966]  \n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 33:  96% 450/470 [04:44<00:12,  1.58it/s, loss=0.11, v_num=0, val/loss=0.118, val/acc=0.966]\n",
            "Epoch 33: 100% 470/470 [04:45<00:00,  1.65it/s, loss=0.11, v_num=0, val/loss=0.114, val/acc=0.967]\n",
            "Epoch 34:  91% 430/470 [04:52<00:27,  1.47it/s, loss=0.0804, v_num=0, val/loss=0.114, val/acc=0.967]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 34:  96% 450/470 [04:53<00:13,  1.53it/s, loss=0.0804, v_num=0, val/loss=0.114, val/acc=0.967]\n",
            "Epoch 34: 100% 470/470 [04:53<00:00,  1.60it/s, loss=0.0804, v_num=0, val/loss=0.113, val/acc=0.967]\n",
            "Epoch 35:  91% 430/470 [05:00<00:27,  1.43it/s, loss=0.103, v_num=0, val/loss=0.113, val/acc=0.967]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 35:  96% 450/470 [05:01<00:13,  1.49it/s, loss=0.103, v_num=0, val/loss=0.113, val/acc=0.967]\n",
            "Epoch 35: 100% 470/470 [05:01<00:00,  1.56it/s, loss=0.103, v_num=0, val/loss=0.112, val/acc=0.967]\n",
            "Epoch 36:  91% 430/470 [05:09<00:28,  1.39it/s, loss=0.0834, v_num=0, val/loss=0.112, val/acc=0.967]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 36:  96% 450/470 [05:10<00:13,  1.45it/s, loss=0.0834, v_num=0, val/loss=0.112, val/acc=0.967]\n",
            "Epoch 36: 100% 470/470 [05:10<00:00,  1.51it/s, loss=0.0834, v_num=0, val/loss=0.110, val/acc=0.967]\n",
            "Epoch 37:  91% 430/470 [05:18<00:29,  1.35it/s, loss=0.0852, v_num=0, val/loss=0.110, val/acc=0.967]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 37:  96% 450/470 [05:18<00:14,  1.41it/s, loss=0.0852, v_num=0, val/loss=0.110, val/acc=0.967]\n",
            "Epoch 37: 100% 470/470 [05:19<00:00,  1.47it/s, loss=0.0852, v_num=0, val/loss=0.109, val/acc=0.967]\n",
            "Epoch 38:  91% 430/470 [05:26<00:30,  1.32it/s, loss=0.0814, v_num=0, val/loss=0.109, val/acc=0.967]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 38:  96% 450/470 [05:26<00:14,  1.38it/s, loss=0.0814, v_num=0, val/loss=0.109, val/acc=0.967]\n",
            "Epoch 38: 100% 470/470 [05:27<00:00,  1.44it/s, loss=0.0814, v_num=0, val/loss=0.109, val/acc=0.968]\n",
            "Epoch 39:  91% 430/470 [05:35<00:31,  1.28it/s, loss=0.0737, v_num=0, val/loss=0.109, val/acc=0.968]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 39:  96% 450/470 [05:35<00:14,  1.34it/s, loss=0.0737, v_num=0, val/loss=0.109, val/acc=0.968]\n",
            "Epoch 39: 100% 470/470 [05:35<00:00,  1.40it/s, loss=0.0737, v_num=0, val/loss=0.106, val/acc=0.968]\n",
            "Epoch 40:  91% 430/470 [05:43<00:31,  1.25it/s, loss=0.0797, v_num=0, val/loss=0.106, val/acc=0.968]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 40:  96% 450/470 [05:44<00:15,  1.31it/s, loss=0.0797, v_num=0, val/loss=0.106, val/acc=0.968]\n",
            "Epoch 40: 100% 470/470 [05:44<00:00,  1.36it/s, loss=0.0797, v_num=0, val/loss=0.105, val/acc=0.967]\n",
            "Epoch 41:  91% 430/470 [05:51<00:32,  1.22it/s, loss=0.0837, v_num=0, val/loss=0.105, val/acc=0.967]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 41:  96% 450/470 [05:52<00:15,  1.28it/s, loss=0.0837, v_num=0, val/loss=0.105, val/acc=0.967]\n",
            "Epoch 41: 100% 470/470 [05:52<00:00,  1.33it/s, loss=0.0837, v_num=0, val/loss=0.105, val/acc=0.968]\n",
            "Epoch 42:  91% 430/470 [06:00<00:33,  1.19it/s, loss=0.0875, v_num=0, val/loss=0.105, val/acc=0.968]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 42:  96% 450/470 [06:00<00:16,  1.25it/s, loss=0.0875, v_num=0, val/loss=0.105, val/acc=0.968]\n",
            "Epoch 42: 100% 470/470 [06:01<00:00,  1.30it/s, loss=0.0875, v_num=0, val/loss=0.104, val/acc=0.969]\n",
            "Epoch 43:  91% 430/470 [06:08<00:34,  1.17it/s, loss=0.0798, v_num=0, val/loss=0.104, val/acc=0.969]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 43:  96% 450/470 [06:09<00:16,  1.22it/s, loss=0.0798, v_num=0, val/loss=0.104, val/acc=0.969]\n",
            "Epoch 43: 100% 470/470 [06:09<00:00,  1.27it/s, loss=0.0798, v_num=0, val/loss=0.102, val/acc=0.970]\n",
            "Epoch 44:  91% 430/470 [06:17<00:35,  1.14it/s, loss=0.0853, v_num=0, val/loss=0.102, val/acc=0.970]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 44:  96% 450/470 [06:17<00:16,  1.19it/s, loss=0.0853, v_num=0, val/loss=0.102, val/acc=0.970]\n",
            "Epoch 44: 100% 470/470 [06:17<00:00,  1.24it/s, loss=0.0853, v_num=0, val/loss=0.0998, val/acc=0.969]\n",
            "Epoch 45:  91% 430/470 [06:25<00:35,  1.11it/s, loss=0.0767, v_num=0, val/loss=0.0998, val/acc=0.969]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 45:  96% 450/470 [06:26<00:17,  1.17it/s, loss=0.0767, v_num=0, val/loss=0.0998, val/acc=0.969]\n",
            "Epoch 45: 100% 470/470 [06:26<00:00,  1.22it/s, loss=0.0767, v_num=0, val/loss=0.0991, val/acc=0.970]\n",
            "Epoch 46:  91% 430/470 [06:33<00:36,  1.09it/s, loss=0.0764, v_num=0, val/loss=0.0991, val/acc=0.970]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 46:  96% 450/470 [06:34<00:17,  1.14it/s, loss=0.0764, v_num=0, val/loss=0.0991, val/acc=0.970]\n",
            "Epoch 46: 100% 470/470 [06:34<00:00,  1.19it/s, loss=0.0764, v_num=0, val/loss=0.0976, val/acc=0.971]\n",
            "Epoch 47:  91% 430/470 [06:42<00:37,  1.07it/s, loss=0.0612, v_num=0, val/loss=0.0976, val/acc=0.971]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 47:  96% 450/470 [06:42<00:17,  1.12it/s, loss=0.0612, v_num=0, val/loss=0.0976, val/acc=0.971]\n",
            "Epoch 47: 100% 470/470 [06:42<00:00,  1.17it/s, loss=0.0612, v_num=0, val/loss=0.0972, val/acc=0.971]\n",
            "Epoch 48:  91% 430/470 [06:50<00:38,  1.05it/s, loss=0.058, v_num=0, val/loss=0.0972, val/acc=0.971] \n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 48:  96% 450/470 [06:51<00:18,  1.09it/s, loss=0.058, v_num=0, val/loss=0.0972, val/acc=0.971]\n",
            "Epoch 48: 100% 470/470 [06:51<00:00,  1.14it/s, loss=0.058, v_num=0, val/loss=0.0964, val/acc=0.971]\n",
            "Epoch 49:  91% 430/470 [06:58<00:38,  1.03it/s, loss=0.0565, v_num=0, val/loss=0.0964, val/acc=0.971]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 49:  96% 450/470 [06:58<00:18,  1.07it/s, loss=0.0565, v_num=0, val/loss=0.0964, val/acc=0.971]\n",
            "Epoch 49: 100% 470/470 [06:59<00:00,  1.12it/s, loss=0.0565, v_num=0, val/loss=0.0952, val/acc=0.971]\n",
            "Epoch 49: 100% 470/470 [06:59<00:00,  1.12it/s, loss=0.0565, v_num=0, val/loss=0.0952, val/acc=0.971]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color=\"red\">執行`train_u.py`</font>"
      ],
      "metadata": {
        "id": "xGLk6TR53aON"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 使用GPU 且 pytorch_lightning >= 2.0\n",
        "!python train_u.py --root_dir \"./\" --num_epoch 50 --exp_name train_u_50"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ePeVej7-pIRD",
        "outputId": "ecee1050-2b5b-4445-bb84-a5fd9a89e903"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Global seed set to 1234\n",
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./MNIST/raw/train-images-idx3-ubyte.gz\n",
            "100% 9912422/9912422 [00:00<00:00, 111035560.80it/s]\n",
            "Extracting ./MNIST/raw/train-images-idx3-ubyte.gz to ./MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "100% 28881/28881 [00:00<00:00, 171337615.03it/s]\n",
            "Extracting ./MNIST/raw/train-labels-idx1-ubyte.gz to ./MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./MNIST/raw/t10k-images-idx3-ubyte.gz\n",
            "100% 1648877/1648877 [00:00<00:00, 31542397.26it/s]\n",
            "Extracting ./MNIST/raw/t10k-images-idx3-ubyte.gz to ./MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "100% 4542/4542 [00:00<00:00, 34018801.37it/s]\n",
            "Extracting ./MNIST/raw/t10k-labels-idx1-ubyte.gz to ./MNIST/raw\n",
            "\n",
            "Missing logger folder: logs/train_u_50\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name | Type        | Params\n",
            "-------------------------------------\n",
            "0 | net  | LinearModel | 101 K \n",
            "-------------------------------------\n",
            "101 K     Trainable params\n",
            "0         Non-trainable params\n",
            "101 K     Total params\n",
            "0.407     Total estimated model params size (MB)\n",
            "2024-03-07 07:31:08.937913: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-03-07 07:31:08.937976: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-03-07 07:31:08.939278: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-03-07 07:31:10.335878: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Sanity Checking: 0it [00:00, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Epoch 0: 100% 430/430 [00:06<00:00, 62.68it/s, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  50% 20/40 [00:00<00:00, 82.82it/s]\u001b[A\n",
            "Epoch 0: 100% 430/430 [00:07<00:00, 56.52it/s, v_num=0, val/loss=0.654, val/acc=0.847]\n",
            "Epoch 1: 100% 430/430 [00:07<00:00, 55.34it/s, v_num=0, val/loss=0.654, val/acc=0.847]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  50% 20/40 [00:00<00:00, 79.02it/s]\u001b[A\n",
            "Epoch 1: 100% 430/430 [00:08<00:00, 50.89it/s, v_num=0, val/loss=0.529, val/acc=0.871]\n",
            "Epoch 2: 100% 430/430 [00:07<00:00, 60.45it/s, v_num=0, val/loss=0.529, val/acc=0.871]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  50% 20/40 [00:00<00:00, 62.85it/s]\u001b[A\n",
            "Epoch 2: 100% 430/430 [00:08<00:00, 52.60it/s, v_num=0, val/loss=0.466, val/acc=0.884]\n",
            "Epoch 3: 100% 430/430 [00:06<00:00, 63.98it/s, v_num=0, val/loss=0.466, val/acc=0.884]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  50% 20/40 [00:00<00:00, 94.97it/s]\u001b[A\n",
            "Epoch 3: 100% 430/430 [00:07<00:00, 58.03it/s, v_num=0, val/loss=0.426, val/acc=0.892]\n",
            "Epoch 4: 100% 430/430 [00:07<00:00, 54.72it/s, v_num=0, val/loss=0.426, val/acc=0.892]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  50% 20/40 [00:00<00:00, 82.59it/s]\u001b[A\n",
            "Epoch 4: 100% 430/430 [00:08<00:00, 50.43it/s, v_num=0, val/loss=0.397, val/acc=0.898]\n",
            "Epoch 5: 100% 430/430 [00:06<00:00, 63.36it/s, v_num=0, val/loss=0.397, val/acc=0.898]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  50% 20/40 [00:00<00:00, 84.41it/s]\u001b[A\n",
            "Epoch 5: 100% 430/430 [00:07<00:00, 57.72it/s, v_num=0, val/loss=0.376, val/acc=0.902]\n",
            "Epoch 6: 100% 430/430 [00:07<00:00, 55.24it/s, v_num=0, val/loss=0.376, val/acc=0.902]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  50% 20/40 [00:00<00:00, 79.63it/s]\u001b[A\n",
            "Epoch 6: 100% 430/430 [00:08<00:00, 50.82it/s, v_num=0, val/loss=0.358, val/acc=0.906]\n",
            "Epoch 7: 100% 430/430 [00:07<00:00, 55.48it/s, v_num=0, val/loss=0.358, val/acc=0.906]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  50% 20/40 [00:00<00:00, 80.83it/s]\u001b[A\n",
            "Epoch 7: 100% 430/430 [00:08<00:00, 50.52it/s, v_num=0, val/loss=0.344, val/acc=0.909]\n",
            "Epoch 8: 100% 430/430 [00:06<00:00, 63.49it/s, v_num=0, val/loss=0.344, val/acc=0.909]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  50% 20/40 [00:00<00:00, 82.79it/s]\u001b[A\n",
            "Epoch 8: 100% 430/430 [00:07<00:00, 57.59it/s, v_num=0, val/loss=0.331, val/acc=0.912]\n",
            "Epoch 9: 100% 430/430 [00:07<00:00, 54.76it/s, v_num=0, val/loss=0.331, val/acc=0.912]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  50% 20/40 [00:00<00:00, 111.70it/s]\u001b[A\n",
            "Epoch 9: 100% 430/430 [00:08<00:00, 50.23it/s, v_num=0, val/loss=0.320, val/acc=0.914]\n",
            "Epoch 10: 100% 430/430 [00:06<00:00, 62.03it/s, v_num=0, val/loss=0.320, val/acc=0.914]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  50% 20/40 [00:00<00:00, 57.23it/s]\u001b[A\n",
            "Epoch 10: 100% 430/430 [00:08<00:00, 53.69it/s, v_num=0, val/loss=0.311, val/acc=0.916]\n",
            "Epoch 11: 100% 430/430 [00:07<00:00, 59.85it/s, v_num=0, val/loss=0.311, val/acc=0.916]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  50% 20/40 [00:00<00:00, 66.04it/s]\u001b[A\n",
            "Epoch 11: 100% 430/430 [00:07<00:00, 54.58it/s, v_num=0, val/loss=0.302, val/acc=0.918]\n",
            "Epoch 12: 100% 430/430 [00:07<00:00, 55.93it/s, v_num=0, val/loss=0.302, val/acc=0.918]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  50% 20/40 [00:00<00:00, 91.29it/s]\u001b[A\n",
            "Epoch 12: 100% 430/430 [00:08<00:00, 51.44it/s, v_num=0, val/loss=0.294, val/acc=0.920]\n",
            "Epoch 13: 100% 430/430 [00:06<00:00, 63.96it/s, v_num=0, val/loss=0.294, val/acc=0.920]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  50% 20/40 [00:00<00:00, 80.71it/s]\u001b[A\n",
            "Epoch 13: 100% 430/430 [00:07<00:00, 58.00it/s, v_num=0, val/loss=0.287, val/acc=0.922]\n",
            "Epoch 14: 100% 430/430 [00:07<00:00, 56.18it/s, v_num=0, val/loss=0.287, val/acc=0.922]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  50% 20/40 [00:00<00:00, 93.19it/s]\u001b[A\n",
            "Epoch 14: 100% 430/430 [00:08<00:00, 51.62it/s, v_num=0, val/loss=0.280, val/acc=0.924]\n",
            "Epoch 15: 100% 430/430 [00:07<00:00, 54.98it/s, v_num=0, val/loss=0.280, val/acc=0.924]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  50% 20/40 [00:00<00:00, 106.54it/s]\u001b[A\n",
            "Epoch 15: 100% 430/430 [00:08<00:00, 50.40it/s, v_num=0, val/loss=0.274, val/acc=0.925]\n",
            "Epoch 16: 100% 430/430 [00:06<00:00, 65.16it/s, v_num=0, val/loss=0.274, val/acc=0.925]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  50% 20/40 [00:00<00:00, 91.83it/s]\u001b[A\n",
            "Epoch 16: 100% 430/430 [00:07<00:00, 58.75it/s, v_num=0, val/loss=0.268, val/acc=0.926]\n",
            "Epoch 17: 100% 430/430 [00:07<00:00, 55.21it/s, v_num=0, val/loss=0.268, val/acc=0.926]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  50% 20/40 [00:00<00:00, 90.49it/s]\u001b[A\n",
            "Epoch 17: 100% 430/430 [00:08<00:00, 50.62it/s, v_num=0, val/loss=0.263, val/acc=0.928]\n",
            "Epoch 18: 100% 430/430 [00:06<00:00, 62.60it/s, v_num=0, val/loss=0.263, val/acc=0.928]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  50% 20/40 [00:00<00:00, 59.65it/s]\u001b[A\n",
            "Epoch 18: 100% 430/430 [00:07<00:00, 54.01it/s, v_num=0, val/loss=0.258, val/acc=0.929]\n",
            "Epoch 19: 100% 430/430 [00:07<00:00, 59.47it/s, v_num=0, val/loss=0.258, val/acc=0.929]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  50% 20/40 [00:00<00:00, 90.52it/s]\u001b[A\n",
            "Epoch 19: 100% 430/430 [00:07<00:00, 54.39it/s, v_num=0, val/loss=0.253, val/acc=0.930]\n",
            "Epoch 20: 100% 430/430 [00:07<00:00, 55.52it/s, v_num=0, val/loss=0.253, val/acc=0.930]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  50% 20/40 [00:00<00:00, 67.25it/s]\u001b[A\n",
            "Epoch 20: 100% 430/430 [00:08<00:00, 50.92it/s, v_num=0, val/loss=0.249, val/acc=0.931]\n",
            "Epoch 21: 100% 430/430 [00:06<00:00, 63.81it/s, v_num=0, val/loss=0.249, val/acc=0.931]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  50% 20/40 [00:00<00:00, 96.42it/s]\u001b[A\n",
            "Epoch 21: 100% 430/430 [00:07<00:00, 57.83it/s, v_num=0, val/loss=0.245, val/acc=0.932]\n",
            "Epoch 22: 100% 430/430 [00:07<00:00, 56.48it/s, v_num=0, val/loss=0.245, val/acc=0.932]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  50% 20/40 [00:00<00:00, 90.46it/s]\u001b[A\n",
            "Epoch 22: 100% 430/430 [00:08<00:00, 51.85it/s, v_num=0, val/loss=0.241, val/acc=0.933]\n",
            "Epoch 23: 100% 430/430 [00:07<00:00, 57.30it/s, v_num=0, val/loss=0.241, val/acc=0.933]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  50% 20/40 [00:00<00:00, 47.75it/s]\u001b[A\n",
            "Epoch 23: 100% 430/430 [00:08<00:00, 50.67it/s, v_num=0, val/loss=0.237, val/acc=0.934]\n",
            "Epoch 24: 100% 430/430 [00:06<00:00, 63.00it/s, v_num=0, val/loss=0.237, val/acc=0.934]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  50% 20/40 [00:00<00:00, 87.97it/s]\u001b[A\n",
            "Epoch 24: 100% 430/430 [00:07<00:00, 57.09it/s, v_num=0, val/loss=0.234, val/acc=0.935]\n",
            "Epoch 25: 100% 430/430 [00:07<00:00, 56.01it/s, v_num=0, val/loss=0.234, val/acc=0.935]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  50% 20/40 [00:00<00:00, 87.31it/s]\u001b[A\n",
            "Epoch 25: 100% 430/430 [00:08<00:00, 51.42it/s, v_num=0, val/loss=0.230, val/acc=0.936]\n",
            "Epoch 26: 100% 430/430 [00:06<00:00, 64.82it/s, v_num=0, val/loss=0.230, val/acc=0.936]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  50% 20/40 [00:00<00:00, 56.89it/s]\u001b[A\n",
            "Epoch 26: 100% 430/430 [00:07<00:00, 56.71it/s, v_num=0, val/loss=0.227, val/acc=0.937]\n",
            "Epoch 27: 100% 430/430 [00:07<00:00, 56.96it/s, v_num=0, val/loss=0.227, val/acc=0.937]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  50% 20/40 [00:00<00:00, 87.89it/s]\u001b[A\n",
            "Epoch 27: 100% 430/430 [00:08<00:00, 52.28it/s, v_num=0, val/loss=0.224, val/acc=0.938]\n",
            "Epoch 28: 100% 430/430 [00:07<00:00, 55.18it/s, v_num=0, val/loss=0.224, val/acc=0.938]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  50% 20/40 [00:00<00:00, 99.03it/s]\u001b[A\n",
            "Epoch 28: 100% 430/430 [00:08<00:00, 50.86it/s, v_num=0, val/loss=0.222, val/acc=0.938]\n",
            "Epoch 29: 100% 430/430 [00:06<00:00, 64.81it/s, v_num=0, val/loss=0.222, val/acc=0.938]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  50% 20/40 [00:00<00:00, 84.50it/s]\u001b[A\n",
            "Epoch 29: 100% 430/430 [00:07<00:00, 58.58it/s, v_num=0, val/loss=0.219, val/acc=0.939]\n",
            "Epoch 30: 100% 430/430 [00:07<00:00, 54.49it/s, v_num=0, val/loss=0.219, val/acc=0.939]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  50% 20/40 [00:00<00:00, 103.20it/s]\u001b[A\n",
            "Epoch 30: 100% 430/430 [00:08<00:00, 50.12it/s, v_num=0, val/loss=0.216, val/acc=0.940]\n",
            "Epoch 31: 100% 430/430 [00:07<00:00, 59.80it/s, v_num=0, val/loss=0.216, val/acc=0.940]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  50% 20/40 [00:00<00:00, 60.86it/s]\u001b[A\n",
            "Epoch 31: 100% 430/430 [00:08<00:00, 52.05it/s, v_num=0, val/loss=0.214, val/acc=0.940]\n",
            "Epoch 32: 100% 430/430 [00:06<00:00, 63.03it/s, v_num=0, val/loss=0.214, val/acc=0.940]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  50% 20/40 [00:00<00:00, 99.68it/s]\u001b[A\n",
            "Epoch 32: 100% 430/430 [00:07<00:00, 57.33it/s, v_num=0, val/loss=0.212, val/acc=0.941]\n",
            "Epoch 33: 100% 430/430 [00:07<00:00, 56.54it/s, v_num=0, val/loss=0.212, val/acc=0.941]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  50% 20/40 [00:00<00:00, 95.80it/s]\u001b[A\n",
            "Epoch 33: 100% 430/430 [00:08<00:00, 51.80it/s, v_num=0, val/loss=0.210, val/acc=0.941]\n",
            "Epoch 34: 100% 430/430 [00:06<00:00, 64.00it/s, v_num=0, val/loss=0.210, val/acc=0.941]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  50% 20/40 [00:00<00:00, 93.15it/s]\u001b[A\n",
            "Epoch 34: 100% 430/430 [00:07<00:00, 58.04it/s, v_num=0, val/loss=0.207, val/acc=0.942]\n",
            "Epoch 35: 100% 430/430 [00:07<00:00, 56.01it/s, v_num=0, val/loss=0.207, val/acc=0.942]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  50% 20/40 [00:00<00:00, 87.15it/s]\u001b[A\n",
            "Epoch 35: 100% 430/430 [00:08<00:00, 51.26it/s, v_num=0, val/loss=0.206, val/acc=0.942]\n",
            "Epoch 36: 100% 430/430 [00:07<00:00, 57.42it/s, v_num=0, val/loss=0.206, val/acc=0.942]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  50% 20/40 [00:00<00:00, 52.42it/s]\u001b[A\n",
            "Epoch 36: 100% 430/430 [00:08<00:00, 51.13it/s, v_num=0, val/loss=0.204, val/acc=0.943]\n",
            "Epoch 37: 100% 430/430 [00:06<00:00, 64.85it/s, v_num=0, val/loss=0.204, val/acc=0.943]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  50% 20/40 [00:00<00:00, 76.74it/s]\u001b[A\n",
            "Epoch 37: 100% 430/430 [00:07<00:00, 58.55it/s, v_num=0, val/loss=0.202, val/acc=0.943]\n",
            "Epoch 38: 100% 430/430 [00:07<00:00, 54.84it/s, v_num=0, val/loss=0.202, val/acc=0.943]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  50% 20/40 [00:00<00:00, 82.56it/s]\u001b[A\n",
            "Epoch 38: 100% 430/430 [00:08<00:00, 50.33it/s, v_num=0, val/loss=0.200, val/acc=0.944]\n",
            "Epoch 39: 100% 430/430 [00:06<00:00, 64.20it/s, v_num=0, val/loss=0.200, val/acc=0.944]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  50% 20/40 [00:00<00:00, 64.96it/s]\u001b[A\n",
            "Epoch 39: 100% 430/430 [00:07<00:00, 56.72it/s, v_num=0, val/loss=0.199, val/acc=0.944]\n",
            "Epoch 40: 100% 430/430 [00:07<00:00, 57.62it/s, v_num=0, val/loss=0.199, val/acc=0.944]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  50% 20/40 [00:00<00:00, 86.46it/s]\u001b[A\n",
            "Epoch 40: 100% 430/430 [00:08<00:00, 52.88it/s, v_num=0, val/loss=0.197, val/acc=0.945]\n",
            "Epoch 41: 100% 430/430 [00:07<00:00, 56.00it/s, v_num=0, val/loss=0.197, val/acc=0.945]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  50% 20/40 [00:00<00:00, 98.59it/s]\u001b[A\n",
            "Epoch 41: 100% 430/430 [00:08<00:00, 51.46it/s, v_num=0, val/loss=0.195, val/acc=0.945]\n",
            "Epoch 42: 100% 430/430 [00:06<00:00, 62.76it/s, v_num=0, val/loss=0.195, val/acc=0.945]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  50% 20/40 [00:00<00:00, 70.54it/s]\u001b[A\n",
            "Epoch 42: 100% 430/430 [00:07<00:00, 57.00it/s, v_num=0, val/loss=0.194, val/acc=0.945]\n",
            "Epoch 43: 100% 430/430 [00:07<00:00, 55.41it/s, v_num=0, val/loss=0.194, val/acc=0.945]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  50% 20/40 [00:00<00:00, 83.33it/s]\u001b[A\n",
            "Epoch 43: 100% 430/430 [00:08<00:00, 50.69it/s, v_num=0, val/loss=0.193, val/acc=0.946]\n",
            "Epoch 44: 100% 430/430 [00:07<00:00, 59.79it/s, v_num=0, val/loss=0.193, val/acc=0.946]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  50% 20/40 [00:00<00:00, 55.71it/s]\u001b[A\n",
            "Epoch 44: 100% 430/430 [00:08<00:00, 52.00it/s, v_num=0, val/loss=0.191, val/acc=0.946]\n",
            "Epoch 45: 100% 430/430 [00:06<00:00, 63.17it/s, v_num=0, val/loss=0.191, val/acc=0.946]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  50% 20/40 [00:00<00:00, 92.29it/s]\u001b[A\n",
            "Epoch 45: 100% 430/430 [00:07<00:00, 56.68it/s, v_num=0, val/loss=0.190, val/acc=0.946]\n",
            "Epoch 46: 100% 430/430 [00:07<00:00, 55.80it/s, v_num=0, val/loss=0.190, val/acc=0.946]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  50% 20/40 [00:00<00:00, 80.86it/s]\u001b[A\n",
            "Epoch 46: 100% 430/430 [00:08<00:00, 51.20it/s, v_num=0, val/loss=0.189, val/acc=0.947]\n",
            "Epoch 47: 100% 430/430 [00:06<00:00, 63.82it/s, v_num=0, val/loss=0.189, val/acc=0.947]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  50% 20/40 [00:00<00:00, 100.39it/s]\u001b[A\n",
            "Epoch 47: 100% 430/430 [00:07<00:00, 57.57it/s, v_num=0, val/loss=0.188, val/acc=0.947]\n",
            "Epoch 48: 100% 430/430 [00:07<00:00, 55.94it/s, v_num=0, val/loss=0.188, val/acc=0.947]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  50% 20/40 [00:00<00:00, 94.59it/s]\u001b[A\n",
            "Epoch 48: 100% 430/430 [00:08<00:00, 51.30it/s, v_num=0, val/loss=0.187, val/acc=0.947]\n",
            "Epoch 49: 100% 430/430 [00:07<00:00, 54.87it/s, v_num=0, val/loss=0.187, val/acc=0.947]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  50% 20/40 [00:00<00:00, 92.39it/s]\u001b[A\n",
            "Epoch 49: 100% 430/430 [00:08<00:00, 50.42it/s, v_num=0, val/loss=0.186, val/acc=0.948]\n",
            "Epoch 49: 100% 430/430 [00:08<00:00, 50.42it/s, v_num=0, val/loss=0.186, val/acc=0.948]`Trainer.fit` stopped: `max_epochs=50` reached.\n",
            "Epoch 49: 100% 430/430 [00:08<00:00, 50.35it/s, v_num=0, val/loss=0.186, val/acc=0.948]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 使用CPU(pytorch_lightning==2.0.0 或 2.0.1;post0 結果都一樣)，會反覆出現\"...Validation DataLoader...\"\n",
        "# !python train_u.py --root_dir \"./\" --num_epoch 5 --exp_name train_u_5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35iVQFzy1lsy",
        "outputId": "73ddd265-549c-4e30-e01a-ae1b30d3bea1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Global seed set to 1234\n",
            "GPU available: False, used: False\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./MNIST/raw/train-images-idx3-ubyte.gz\n",
            "100% 9912422/9912422 [00:00<00:00, 109676164.06it/s]\n",
            "Extracting ./MNIST/raw/train-images-idx3-ubyte.gz to ./MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "100% 28881/28881 [00:00<00:00, 145946619.07it/s]\n",
            "Extracting ./MNIST/raw/train-labels-idx1-ubyte.gz to ./MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./MNIST/raw/t10k-images-idx3-ubyte.gz\n",
            "100% 1648877/1648877 [00:00<00:00, 29868067.95it/s]\n",
            "Extracting ./MNIST/raw/t10k-images-idx3-ubyte.gz to ./MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "100% 4542/4542 [00:00<00:00, 21648328.15it/s]\n",
            "Extracting ./MNIST/raw/t10k-labels-idx1-ubyte.gz to ./MNIST/raw\n",
            "\n",
            "Missing logger folder: logs/expu1\n",
            "\n",
            "  | Name | Type        | Params\n",
            "-------------------------------------\n",
            "0 | net  | LinearModel | 101 K \n",
            "-------------------------------------\n",
            "101 K     Trainable params\n",
            "0         Non-trainable params\n",
            "101 K     Total params\n",
            "0.407     Total estimated model params size (MB)\n",
            "2024-03-07 03:05:10.670458: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-03-07 03:05:10.670563: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-03-07 03:05:10.672968: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-03-07 03:05:12.743380: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Sanity Checking: 0it [00:00, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Epoch 0: 100% 430/430 [00:10<00:00, 39.13it/s, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   2% 1/40 [00:00<00:00, 161.13it/s]\u001b[A\n",
            "Validation DataLoader 0:   5% 2/40 [00:00<00:00, 105.42it/s]\u001b[A\n",
            "Validation DataLoader 0:   8% 3/40 [00:00<00:00, 124.04it/s]\u001b[A\n",
            "Validation DataLoader 0:  10% 4/40 [00:00<00:00, 82.70it/s] \u001b[A\n",
            "Validation DataLoader 0:  12% 5/40 [00:00<00:00, 81.63it/s]\u001b[A\n",
            "Validation DataLoader 0:  15% 6/40 [00:00<00:00, 70.39it/s]\u001b[A\n",
            "Validation DataLoader 0:  18% 7/40 [00:00<00:00, 72.74it/s]\u001b[A\n",
            "Validation DataLoader 0:  20% 8/40 [00:00<00:00, 74.62it/s]\u001b[A\n",
            "Validation DataLoader 0:  22% 9/40 [00:00<00:00, 73.02it/s]\u001b[A\n",
            "Validation DataLoader 0:  25% 10/40 [00:00<00:00, 72.98it/s]\u001b[A\n",
            "Validation DataLoader 0:  28% 11/40 [00:00<00:00, 69.84it/s]\u001b[A\n",
            "Validation DataLoader 0:  30% 12/40 [00:00<00:00, 66.27it/s]\u001b[A\n",
            "Validation DataLoader 0:  32% 13/40 [00:00<00:00, 67.63it/s]\u001b[A\n",
            "Validation DataLoader 0:  35% 14/40 [00:00<00:00, 67.86it/s]\u001b[A\n",
            "Validation DataLoader 0:  38% 15/40 [00:00<00:00, 69.70it/s]\u001b[A\n",
            "Validation DataLoader 0:  40% 16/40 [00:00<00:00, 62.12it/s]\u001b[A\n",
            "Validation DataLoader 0:  42% 17/40 [00:00<00:00, 63.38it/s]\u001b[A\n",
            "Validation DataLoader 0:  45% 18/40 [00:00<00:00, 61.14it/s]\u001b[A\n",
            "Validation DataLoader 0:  48% 19/40 [00:00<00:00, 63.48it/s]\u001b[A\n",
            "Validation DataLoader 0:  50% 20/40 [00:00<00:00, 65.75it/s]\u001b[A\n",
            "Validation DataLoader 0:  52% 21/40 [00:00<00:00, 66.80it/s]\u001b[A\n",
            "Validation DataLoader 0:  55% 22/40 [00:00<00:00, 57.51it/s]\u001b[A\n",
            "Validation DataLoader 0:  57% 23/40 [00:00<00:00, 59.55it/s]\u001b[A\n",
            "Validation DataLoader 0:  60% 24/40 [00:00<00:00, 60.57it/s]\u001b[A\n",
            "Validation DataLoader 0:  62% 25/40 [00:00<00:00, 61.52it/s]\u001b[A\n",
            "Validation DataLoader 0:  65% 26/40 [00:00<00:00, 55.74it/s]\u001b[A\n",
            "Validation DataLoader 0:  68% 27/40 [00:00<00:00, 57.42it/s]\u001b[A\n",
            "Validation DataLoader 0:  70% 28/40 [00:00<00:00, 58.29it/s]\u001b[A\n",
            "Validation DataLoader 0:  72% 29/40 [00:00<00:00, 60.00it/s]\u001b[A\n",
            "Validation DataLoader 0:  75% 30/40 [00:00<00:00, 58.64it/s]\u001b[A\n",
            "Validation DataLoader 0:  78% 31/40 [00:00<00:00, 60.12it/s]\u001b[A\n",
            "Validation DataLoader 0:  80% 32/40 [00:00<00:00, 60.55it/s]\u001b[A\n",
            "Validation DataLoader 0:  82% 33/40 [00:00<00:00, 61.66it/s]\u001b[A\n",
            "Validation DataLoader 0:  85% 34/40 [00:00<00:00, 58.83it/s]\u001b[A\n",
            "Validation DataLoader 0:  88% 35/40 [00:00<00:00, 60.28it/s]\u001b[A\n",
            "Validation DataLoader 0:  90% 36/40 [00:00<00:00, 61.70it/s]\u001b[A\n",
            "Validation DataLoader 0:  92% 37/40 [00:00<00:00, 63.13it/s]\u001b[A\n",
            "Validation DataLoader 0:  95% 38/40 [00:00<00:00, 63.21it/s]\u001b[A\n",
            "Validation DataLoader 0:  98% 39/40 [00:00<00:00, 64.66it/s]\u001b[A\n",
            "Epoch 0: 100% 430/430 [00:11<00:00, 36.30it/s, v_num=0, val/loss=0.654, val/acc=0.847]\n",
            "Epoch 1: 100% 430/430 [00:09<00:00, 45.10it/s, v_num=0, val/loss=0.654, val/acc=0.847]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   2% 1/40 [00:00<00:00, 46.82it/s]\u001b[A\n",
            "Validation DataLoader 0:   5% 2/40 [00:00<00:01, 29.26it/s]\u001b[A\n",
            "Validation DataLoader 0:   8% 3/40 [00:00<00:01, 34.74it/s]\u001b[A\n",
            "Validation DataLoader 0:  10% 4/40 [00:00<00:00, 38.69it/s]\u001b[A\n",
            "Validation DataLoader 0:  12% 5/40 [00:00<00:00, 40.21it/s]\u001b[A\n",
            "Validation DataLoader 0:  15% 6/40 [00:00<00:00, 39.38it/s]\u001b[A\n",
            "Validation DataLoader 0:  18% 7/40 [00:00<00:00, 39.89it/s]\u001b[A\n",
            "Validation DataLoader 0:  20% 8/40 [00:00<00:00, 40.53it/s]\u001b[A\n",
            "Validation DataLoader 0:  22% 9/40 [00:00<00:00, 40.44it/s]\u001b[A\n",
            "Validation DataLoader 0:  25% 10/40 [00:00<00:00, 40.08it/s]\u001b[A\n",
            "Validation DataLoader 0:  28% 11/40 [00:00<00:00, 38.68it/s]\u001b[A\n",
            "Validation DataLoader 0:  30% 12/40 [00:00<00:00, 39.82it/s]\u001b[A\n",
            "Validation DataLoader 0:  32% 13/40 [00:00<00:00, 34.27it/s]\u001b[A\n",
            "Validation DataLoader 0:  35% 14/40 [00:00<00:00, 33.87it/s]\u001b[A\n",
            "Validation DataLoader 0:  38% 15/40 [00:00<00:00, 34.22it/s]\u001b[A\n",
            "Validation DataLoader 0:  40% 16/40 [00:00<00:00, 34.98it/s]\u001b[A\n",
            "Validation DataLoader 0:  42% 17/40 [00:00<00:00, 35.43it/s]\u001b[A\n",
            "Validation DataLoader 0:  45% 18/40 [00:00<00:00, 35.67it/s]\u001b[A\n",
            "Validation DataLoader 0:  48% 19/40 [00:00<00:00, 35.69it/s]\u001b[A\n",
            "Validation DataLoader 0:  50% 20/40 [00:00<00:00, 36.41it/s]\u001b[A\n",
            "Validation DataLoader 0:  52% 21/40 [00:00<00:00, 35.16it/s]\u001b[A\n",
            "Validation DataLoader 0:  55% 22/40 [00:00<00:00, 35.52it/s]\u001b[A\n",
            "Validation DataLoader 0:  57% 23/40 [00:00<00:00, 35.64it/s]\u001b[A\n",
            "Validation DataLoader 0:  60% 24/40 [00:00<00:00, 36.34it/s]\u001b[A\n",
            "Validation DataLoader 0:  62% 25/40 [00:00<00:00, 35.10it/s]\u001b[A\n",
            "Validation DataLoader 0:  65% 26/40 [00:00<00:00, 35.41it/s]\u001b[A\n",
            "Validation DataLoader 0:  68% 27/40 [00:00<00:00, 35.67it/s]\u001b[A\n",
            "Validation DataLoader 0:  70% 28/40 [00:00<00:00, 36.11it/s]\u001b[A\n",
            "Validation DataLoader 0:  72% 29/40 [00:00<00:00, 33.78it/s]\u001b[A\n",
            "Validation DataLoader 0:  75% 30/40 [00:00<00:00, 34.04it/s]\u001b[A\n",
            "Validation DataLoader 0:  78% 31/40 [00:00<00:00, 34.10it/s]\u001b[A\n",
            "Validation DataLoader 0:  80% 32/40 [00:00<00:00, 35.08it/s]\u001b[A\n",
            "Validation DataLoader 0:  82% 33/40 [00:00<00:00, 34.68it/s]\u001b[A\n",
            "Validation DataLoader 0:  85% 34/40 [00:01<00:00, 33.52it/s]\u001b[A\n",
            "Validation DataLoader 0:  88% 35/40 [00:01<00:00, 34.27it/s]\u001b[A\n",
            "Validation DataLoader 0:  90% 36/40 [00:01<00:00, 34.86it/s]\u001b[A\n",
            "Validation DataLoader 0:  92% 37/40 [00:01<00:00, 34.80it/s]\u001b[A\n",
            "Validation DataLoader 0:  95% 38/40 [00:01<00:00, 34.90it/s]\u001b[A\n",
            "Validation DataLoader 0:  98% 39/40 [00:01<00:00, 35.72it/s]\u001b[A\n",
            "Epoch 1: 100% 430/430 [00:11<00:00, 39.07it/s, v_num=0, val/loss=0.533, val/acc=0.870]\n",
            "Epoch 2: 100% 430/430 [00:09<00:00, 44.16it/s, v_num=0, val/loss=0.533, val/acc=0.870]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   2% 1/40 [00:00<00:00, 76.04it/s]\u001b[A\n",
            "Validation DataLoader 0:   5% 2/40 [00:00<00:00, 43.41it/s]\u001b[A\n",
            "Validation DataLoader 0:   8% 3/40 [00:00<00:00, 56.05it/s]\u001b[A\n",
            "Validation DataLoader 0:  10% 4/40 [00:00<00:00, 60.55it/s]\u001b[A\n",
            "Validation DataLoader 0:  12% 5/40 [00:00<00:00, 58.76it/s]\u001b[A\n",
            "Validation DataLoader 0:  15% 6/40 [00:00<00:00, 65.94it/s]\u001b[A\n",
            "Validation DataLoader 0:  18% 7/40 [00:00<00:00, 67.92it/s]\u001b[A\n",
            "Validation DataLoader 0:  20% 8/40 [00:00<00:00, 74.98it/s]\u001b[A\n",
            "Validation DataLoader 0:  22% 9/40 [00:00<00:00, 52.40it/s]\u001b[A\n",
            "Validation DataLoader 0:  25% 10/40 [00:00<00:00, 55.53it/s]\u001b[A\n",
            "Validation DataLoader 0:  28% 11/40 [00:00<00:00, 58.42it/s]\u001b[A\n",
            "Validation DataLoader 0:  30% 12/40 [00:00<00:00, 59.95it/s]\u001b[A\n",
            "Validation DataLoader 0:  32% 13/40 [00:00<00:00, 49.81it/s]\u001b[A\n",
            "Validation DataLoader 0:  35% 14/40 [00:00<00:00, 51.87it/s]\u001b[A\n",
            "Validation DataLoader 0:  38% 15/40 [00:00<00:00, 52.30it/s]\u001b[A\n",
            "Validation DataLoader 0:  40% 16/40 [00:00<00:00, 53.14it/s]\u001b[A\n",
            "Validation DataLoader 0:  42% 17/40 [00:00<00:00, 49.46it/s]\u001b[A\n",
            "Validation DataLoader 0:  45% 18/40 [00:00<00:00, 49.68it/s]\u001b[A\n",
            "Validation DataLoader 0:  48% 19/40 [00:00<00:00, 51.07it/s]\u001b[A\n",
            "Validation DataLoader 0:  50% 20/40 [00:00<00:00, 52.21it/s]\u001b[A\n",
            "Validation DataLoader 0:  52% 21/40 [00:00<00:00, 53.35it/s]\u001b[A\n",
            "Validation DataLoader 0:  55% 22/40 [00:00<00:00, 52.38it/s]\u001b[A\n",
            "Validation DataLoader 0:  57% 23/40 [00:00<00:00, 51.60it/s]\u001b[A\n",
            "Validation DataLoader 0:  60% 24/40 [00:00<00:00, 50.55it/s]\u001b[A\n",
            "Validation DataLoader 0:  62% 25/40 [00:00<00:00, 50.80it/s]\u001b[A\n",
            "Validation DataLoader 0:  65% 26/40 [00:00<00:00, 50.50it/s]\u001b[A\n",
            "Validation DataLoader 0:  68% 27/40 [00:00<00:00, 49.54it/s]\u001b[A\n",
            "Validation DataLoader 0:  70% 28/40 [00:00<00:00, 50.35it/s]\u001b[A\n",
            "Validation DataLoader 0:  72% 29/40 [00:00<00:00, 48.86it/s]\u001b[A\n",
            "Validation DataLoader 0:  75% 30/40 [00:00<00:00, 49.18it/s]\u001b[A\n",
            "Validation DataLoader 0:  78% 31/40 [00:00<00:00, 49.13it/s]\u001b[A\n",
            "Validation DataLoader 0:  80% 32/40 [00:00<00:00, 50.00it/s]\u001b[A\n",
            "Validation DataLoader 0:  82% 33/40 [00:00<00:00, 47.53it/s]\u001b[A\n",
            "Validation DataLoader 0:  85% 34/40 [00:00<00:00, 47.41it/s]\u001b[A\n",
            "Validation DataLoader 0:  88% 35/40 [00:00<00:00, 46.41it/s]\u001b[A\n",
            "Validation DataLoader 0:  90% 36/40 [00:00<00:00, 47.29it/s]\u001b[A\n",
            "Validation DataLoader 0:  92% 37/40 [00:00<00:00, 47.23it/s]\u001b[A\n",
            "Validation DataLoader 0:  95% 38/40 [00:00<00:00, 48.20it/s]\u001b[A\n",
            "Validation DataLoader 0:  98% 39/40 [00:00<00:00, 49.34it/s]\u001b[A\n",
            "Epoch 2: 100% 430/430 [00:10<00:00, 39.91it/s, v_num=0, val/loss=0.475, val/acc=0.882]\n",
            "Epoch 3: 100% 430/430 [00:10<00:00, 39.25it/s, v_num=0, val/loss=0.475, val/acc=0.882]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   2% 1/40 [00:00<00:00, 231.17it/s]\u001b[A\n",
            "Validation DataLoader 0:   5% 2/40 [00:00<00:00, 223.48it/s]\u001b[A\n",
            "Validation DataLoader 0:   8% 3/40 [00:00<00:00, 94.43it/s] \u001b[A\n",
            "Validation DataLoader 0:  10% 4/40 [00:00<00:00, 77.85it/s]\u001b[A\n",
            "Validation DataLoader 0:  12% 5/40 [00:00<00:00, 63.24it/s]\u001b[A\n",
            "Validation DataLoader 0:  15% 6/40 [00:00<00:00, 68.10it/s]\u001b[A\n",
            "Validation DataLoader 0:  18% 7/40 [00:00<00:00, 68.80it/s]\u001b[A\n",
            "Validation DataLoader 0:  20% 8/40 [00:00<00:00, 66.87it/s]\u001b[A\n",
            "Validation DataLoader 0:  22% 9/40 [00:00<00:00, 68.61it/s]\u001b[A\n",
            "Validation DataLoader 0:  25% 10/40 [00:00<00:00, 71.33it/s]\u001b[A\n",
            "Validation DataLoader 0:  28% 11/40 [00:00<00:00, 73.01it/s]\u001b[A\n",
            "Validation DataLoader 0:  30% 12/40 [00:00<00:00, 72.82it/s]\u001b[A\n",
            "Validation DataLoader 0:  32% 13/40 [00:00<00:00, 56.42it/s]\u001b[A\n",
            "Validation DataLoader 0:  35% 14/40 [00:00<00:00, 59.87it/s]\u001b[A\n",
            "Validation DataLoader 0:  38% 15/40 [00:00<00:00, 55.59it/s]\u001b[A\n",
            "Validation DataLoader 0:  40% 16/40 [00:00<00:00, 54.83it/s]\u001b[A\n",
            "Validation DataLoader 0:  42% 17/40 [00:00<00:00, 56.04it/s]\u001b[A\n",
            "Validation DataLoader 0:  45% 18/40 [00:00<00:00, 54.67it/s]\u001b[A\n",
            "Validation DataLoader 0:  48% 19/40 [00:00<00:00, 53.23it/s]\u001b[A\n",
            "Validation DataLoader 0:  50% 20/40 [00:00<00:00, 55.23it/s]\u001b[A\n",
            "Validation DataLoader 0:  52% 21/40 [00:00<00:00, 56.72it/s]\u001b[A\n",
            "Validation DataLoader 0:  55% 22/40 [00:00<00:00, 55.13it/s]\u001b[A\n",
            "Validation DataLoader 0:  57% 23/40 [00:00<00:00, 51.33it/s]\u001b[A\n",
            "Validation DataLoader 0:  60% 24/40 [00:00<00:00, 51.93it/s]\u001b[A\n",
            "Validation DataLoader 0:  62% 25/40 [00:00<00:00, 53.64it/s]\u001b[A\n",
            "Validation DataLoader 0:  65% 26/40 [00:00<00:00, 55.39it/s]\u001b[A\n",
            "Validation DataLoader 0:  68% 27/40 [00:00<00:00, 53.51it/s]\u001b[A\n",
            "Validation DataLoader 0:  70% 28/40 [00:00<00:00, 53.58it/s]\u001b[A\n",
            "Validation DataLoader 0:  72% 29/40 [00:00<00:00, 54.68it/s]\u001b[A\n",
            "Validation DataLoader 0:  75% 30/40 [00:00<00:00, 54.49it/s]\u001b[A\n",
            "Validation DataLoader 0:  78% 31/40 [00:00<00:00, 54.49it/s]\u001b[A\n",
            "Validation DataLoader 0:  80% 32/40 [00:00<00:00, 53.18it/s]\u001b[A\n",
            "Validation DataLoader 0:  82% 33/40 [00:00<00:00, 53.78it/s]\u001b[A\n",
            "Validation DataLoader 0:  85% 34/40 [00:00<00:00, 53.41it/s]\u001b[A\n",
            "Validation DataLoader 0:  88% 35/40 [00:00<00:00, 54.17it/s]\u001b[A\n",
            "Validation DataLoader 0:  90% 36/40 [00:00<00:00, 54.76it/s]\u001b[A\n",
            "Validation DataLoader 0:  92% 37/40 [00:00<00:00, 55.98it/s]\u001b[A\n",
            "Validation DataLoader 0:  95% 38/40 [00:00<00:00, 56.29it/s]\u001b[A\n",
            "Validation DataLoader 0:  98% 39/40 [00:00<00:00, 57.52it/s]\u001b[A\n",
            "Epoch 3: 100% 430/430 [00:11<00:00, 35.97it/s, v_num=0, val/loss=0.441, val/acc=0.888]\n",
            "Epoch 4: 100% 430/430 [00:11<00:00, 35.89it/s, v_num=0, val/loss=0.441, val/acc=0.888]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   2% 1/40 [00:00<00:00, 97.46it/s]\u001b[A\n",
            "Validation DataLoader 0:   5% 2/40 [00:00<00:00, 57.37it/s]\u001b[A\n",
            "Validation DataLoader 0:   8% 3/40 [00:00<00:00, 62.68it/s]\u001b[A\n",
            "Validation DataLoader 0:  10% 4/40 [00:00<00:00, 66.80it/s]\u001b[A\n",
            "Validation DataLoader 0:  12% 5/40 [00:00<00:00, 68.33it/s]\u001b[A\n",
            "Validation DataLoader 0:  15% 6/40 [00:00<00:00, 71.58it/s]\u001b[A\n",
            "Validation DataLoader 0:  18% 7/40 [00:00<00:00, 70.11it/s]\u001b[A\n",
            "Validation DataLoader 0:  20% 8/40 [00:00<00:00, 66.16it/s]\u001b[A\n",
            "Validation DataLoader 0:  22% 9/40 [00:00<00:00, 53.02it/s]\u001b[A\n",
            "Validation DataLoader 0:  25% 10/40 [00:00<00:00, 56.24it/s]\u001b[A\n",
            "Validation DataLoader 0:  28% 11/40 [00:00<00:00, 56.20it/s]\u001b[A\n",
            "Validation DataLoader 0:  30% 12/40 [00:00<00:00, 54.94it/s]\u001b[A\n",
            "Validation DataLoader 0:  32% 13/40 [00:00<00:00, 51.06it/s]\u001b[A\n",
            "Validation DataLoader 0:  35% 14/40 [00:00<00:00, 52.47it/s]\u001b[A\n",
            "Validation DataLoader 0:  38% 15/40 [00:00<00:00, 53.23it/s]\u001b[A\n",
            "Validation DataLoader 0:  40% 16/40 [00:00<00:00, 55.21it/s]\u001b[A\n",
            "Validation DataLoader 0:  42% 17/40 [00:00<00:00, 50.09it/s]\u001b[A\n",
            "Validation DataLoader 0:  45% 18/40 [00:00<00:00, 52.20it/s]\u001b[A\n",
            "Validation DataLoader 0:  48% 19/40 [00:00<00:00, 51.21it/s]\u001b[A\n",
            "Validation DataLoader 0:  50% 20/40 [00:00<00:00, 53.42it/s]\u001b[A\n",
            "Validation DataLoader 0:  52% 21/40 [00:00<00:00, 51.73it/s]\u001b[A\n",
            "Validation DataLoader 0:  55% 22/40 [00:00<00:00, 53.02it/s]\u001b[A\n",
            "Validation DataLoader 0:  57% 23/40 [00:00<00:00, 52.16it/s]\u001b[A\n",
            "Validation DataLoader 0:  60% 24/40 [00:00<00:00, 52.47it/s]\u001b[A\n",
            "Validation DataLoader 0:  62% 25/40 [00:00<00:00, 52.52it/s]\u001b[A\n",
            "Validation DataLoader 0:  65% 26/40 [00:00<00:00, 53.41it/s]\u001b[A\n",
            "Validation DataLoader 0:  68% 27/40 [00:00<00:00, 50.97it/s]\u001b[A\n",
            "Validation DataLoader 0:  70% 28/40 [00:00<00:00, 51.61it/s]\u001b[A\n",
            "Validation DataLoader 0:  72% 29/40 [00:00<00:00, 51.91it/s]\u001b[A\n",
            "Validation DataLoader 0:  75% 30/40 [00:00<00:00, 52.28it/s]\u001b[A\n",
            "Validation DataLoader 0:  78% 31/40 [00:00<00:00, 52.02it/s]\u001b[A\n",
            "Validation DataLoader 0:  80% 32/40 [00:00<00:00, 53.22it/s]\u001b[A\n",
            "Validation DataLoader 0:  82% 33/40 [00:00<00:00, 51.80it/s]\u001b[A\n",
            "Validation DataLoader 0:  85% 34/40 [00:00<00:00, 52.86it/s]\u001b[A\n",
            "Validation DataLoader 0:  88% 35/40 [00:00<00:00, 53.30it/s]\u001b[A\n",
            "Validation DataLoader 0:  90% 36/40 [00:00<00:00, 53.99it/s]\u001b[A\n",
            "Validation DataLoader 0:  92% 37/40 [00:00<00:00, 54.38it/s]\u001b[A\n",
            "Validation DataLoader 0:  95% 38/40 [00:00<00:00, 55.66it/s]\u001b[A\n",
            "Validation DataLoader 0:  98% 39/40 [00:00<00:00, 56.90it/s]\u001b[A\n",
            "Epoch 4: 100% 430/430 [00:12<00:00, 33.09it/s, v_num=0, val/loss=0.420, val/acc=0.893]\n",
            "Epoch 4: 100% 430/430 [00:12<00:00, 33.09it/s, v_num=0, val/loss=0.420, val/acc=0.893]`Trainer.fit` stopped: `max_epochs=5` reached.\n",
            "Epoch 4: 100% 430/430 [00:13<00:00, 33.06it/s, v_num=0, val/loss=0.420, val/acc=0.893]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color=\"red\">壓縮資料夾，用以下載</font>"
      ],
      "metadata": {
        "id": "6jBNA368KXQE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !zip -r logs_train_50.zip logs/train_50\n",
        "!zip -r logs_train_u_50.zip logs/train_u_50"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HSialApmpu0s",
        "outputId": "b9630366-cb12-4d51-8ef7-6679b9635584"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: logs/train_u_50/ (stored 0%)\n",
            "  adding: logs/train_u_50/version_0/ (stored 0%)\n",
            "  adding: logs/train_u_50/version_0/hparams.yaml (deflated 16%)\n",
            "  adding: logs/train_u_50/version_0/events.out.tfevents.1709796671.0874785c57eb.2014.0 (deflated 69%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r ckpts_train_u_50.zip ckpts/train_u_50"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vi7CKSp775Vq",
        "outputId": "d11531a7-8590-47d7-f749-ce265f7d62c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: ckpts/train_u_50/ (stored 0%)\n",
            "  adding: ckpts/train_u_50/epoch=49.ckpt (deflated 11%)\n",
            "  adding: ckpts/train_u_50/epoch=48.ckpt (deflated 11%)\n",
            "  adding: ckpts/train_u_50/epoch=45.ckpt (deflated 11%)\n",
            "  adding: ckpts/train_u_50/epoch=46.ckpt (deflated 11%)\n",
            "  adding: ckpts/train_u_50/epoch=47.ckpt (deflated 11%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color=\"red\">上傳後，解壓使用</font>"
      ],
      "metadata": {
        "id": "-_P4twADMNF9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip ckpts_train_u_50.zip\n",
        "!unzip logs_train_u_50.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GDfUWE283v3o",
        "outputId": "19b18f1e-2d79-4de0-b580-e4310b210c50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  ckpts_train_u_50.zip\n",
            "   creating: ckpts/train_u_50/\n",
            "  inflating: ckpts/train_u_50/epoch=49.ckpt  \n",
            "  inflating: ckpts/train_u_50/epoch=48.ckpt  \n",
            "  inflating: ckpts/train_u_50/epoch=45.ckpt  \n",
            "  inflating: ckpts/train_u_50/epoch=46.ckpt  \n",
            "  inflating: ckpts/train_u_50/epoch=47.ckpt  \n",
            "Archive:  logs_train_u_50.zip\n",
            "   creating: logs/train_u_50/\n",
            "   creating: logs/train_u_50/version_0/\n",
            "  inflating: logs/train_u_50/version_0/hparams.yaml  \n",
            "  inflating: logs/train_u_50/version_0/events.out.tfevents.1709796671.0874785c57eb.2014.0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color=\"red\">Step 7 -- 用 `tensorboard` 檢視實驗log</font>\n",
        "[Can I use TensorBoard with Google Colab?](https://stackoverflow.com/questions/47818822/can-i-use-tensorboard-with-google-colab)"
      ],
      "metadata": {
        "id": "1XPz8hCAvy-L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorrt --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DALtpmI6F4eG",
        "outputId": "3432bc6e-3834-4d1c-da38-73cdbadcb032"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for tensorrt (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard"
      ],
      "metadata": {
        "id": "95iL2ra2l_68"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 產生的結果無法儲存\n",
        "%tensorboard --logdir logs"
      ],
      "metadata": {
        "id": "UpS-iSbPN-Nz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf logs"
      ],
      "metadata": {
        "id": "kAvhQ72t0yrm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf ckpts"
      ],
      "metadata": {
        "id": "5Ae0f3oKwV6x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o7S5GT6WEM52"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}