{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "b_5nPnxs2sSu"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CASE 1\n",
        "### 範例一：沒有batch, data(如句子)只有一個時間點的資料(seq_len=1, 如只含有一單詞)"
      ],
      "metadata": {
        "id": "W41qKVeG3AOD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#network parameters\n",
        "input_size = 2   ## 輸入神經元 Xt (t指某個時間) 的特徵向量長度\n",
        "hidden_size = 2  ## hidden h 的特徵向量長度\n",
        "num_layers = 1   ## 只有一層 hidden layer A\n",
        "\n",
        "#data parameters\n",
        "seq_len = 1\n",
        "# (case 1不使用batch)batch_size = 2\n",
        "data_dim = input_size"
      ],
      "metadata": {
        "id": "VKNFKPwR3Ttg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#input data\n",
        "data = torch.randn(seq_len, data_dim)\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v9tDQWyA3ThA",
        "outputId": "5adfd17e-29bf-426c-c9b5-113330152dc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.8055, -2.1205]])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* data的shpae是[1,2], 與官網說明(如下)完全一致\n",
        "> -- **input**: tensor of shape (*L*,*H_in*) for unbatched input -- *L* 是 seq_len, *H_in* 是 input_size\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "GY-x229dIY5G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#official rnn in pytorch\n",
        "ornn = nn.RNN(input_size, hidden_size, num_layers)"
      ],
      "metadata": {
        "id": "4gKv5O745qoU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#init hidden state\n",
        "h0 = torch.randn(num_layers,hidden_size)\n",
        "h0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qmBUiGWM3TSR",
        "outputId": "6c19df48-bb6e-4f4f-837f-7e9ed08d5e8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-1.6190, -0.7052]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* h0的shape是[1,2], 與官網說明(如下)完全一致\n",
        "> -- **h_0**: tensor of shape (*D* * *num_layers*, *H_out*) for unbatched input -- *D* 是 1 (非雙向), *H_out* 是 hidden_size"
      ],
      "metadata": {
        "id": "G-ap5S1aORv3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 輸入data，根據h0執行ornn，也可以不用自行提供h0~\n",
        "official_output, official_hn = ornn(data,h0)\n",
        "official_output, official_hn # 兩者結果會相同,因為seq_len=1,official_output就是official_hn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XbwwTdkB3TDK",
        "outputId": "0319e225-f87d-4b7e-b513-eb9da7eac85f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 0.9922, -0.2327]], grad_fn=<SqueezeBackward1>),\n",
              " tensor([[ 0.9922, -0.2327]], grad_fn=<SqueezeBackward1>))"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* official_output的shape是[1,2],與官網說明(如下)完全一致\n",
        "> --**output**: tensor of shape (*L*, *D* * *H_out*) for unbatched input!
        "* official_hn的shape是[1,2],與官網說明(如下)完全一致\n",
        "> --**h_n**--: tensor of shape (*D* * *num_layers*, *H_out*) for unbatched input"
      ],
      "metadata": {
        "id": "jHTX1tTOEGFL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "輔助用--顯示模型中不同層的`name`與`weight`\n",
        "```python\n",
        "for name, param in ornn.named_parameters():\n",
        "    print(name, param.data)\n",
        "# 顯示實例\n",
        "# weight_ih_l0 tensor([[ 0.5115, -0.6934],\n",
        "#             [ 0.3216,  0.3994]])\n",
        "# weight_hh_l0 tensor([[-0.6004, -0.4624],\n",
        "#             [-0.6839,  0.4299]])\n",
        "# bias_ih_l0 tensor([0.1310, 0.1641])\n",
        "# bias_hh_l0 tensor([ 0.2844, -0.0994])\n",
        "```\n",
        "\n",
        "\n",
        "顯示模型中不同層的`name`與`weight`的另一個方法\n",
        "```python\n",
        "ornn.state_dict()\n",
        "# 顯示實例\n",
        "# OrderedDict([('weight_ih_l0',\n",
        "#         tensor([[ 0.5115, -0.6934],\n",
        "#             [ 0.3216,  0.3994]])),\n",
        "#         ('weight_hh_l0',\n",
        "#         tensor([[-0.6004, -0.4624],\n",
        "#             [-0.6839,  0.4299]])),\n",
        "#         ('bias_ih_l0', tensor([0.1310, 0.1641])),\n",
        "#         ('bias_hh_l0', tensor([ 0.2844, -0.0994]))])\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "uqerezPoYMP1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 自行計算rnn的一種方式,也是最簡化的方式(用.data取代nn.Parameter)\n",
        "XWi = data@ornn.weight_ih_l0.data.T # 執行Xt*W_ih^T\n",
        "#[1,2] <- [1,2]@[2,2]\n",
        "b_ih = ornn.bias_ih_l0.data\n",
        "#[1,2] <- [1,2]\n",
        "hWh = h0@ornn.weight_hh_l0.data.T # h0*W_hh^T\n",
        "#[1,2] <- [1,2]@[2,2]\n",
        "b_hh = ornn.bias_hh_l0.data\n",
        "#[1,2] <- [1,2]\n",
        "resultf = torch.tanh(XWi+b_ih+hWh+b_hh)\n",
        "#[1,2] <- [1,2]\n",
        "resultf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YtP3E_Vn9Szm",
        "outputId": "82d1bba5-a5d2-40b7-805c-4914d5b94bec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.9922, -0.2327]])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```python\n",
        "# 自行計算rnn的其依方式\n",
        "XWi = torch.matmul(data,ornn.state_dict()['weight_ih_l0'].T) # Xt*W_ih^T\n",
        "b_ih = ornn.state_dict()['bias_ih_l0']\n",
        "hWh = torch.matmul(h0,ornn.state_dict()['weight_hh_l0'].T) # h0*W_hh^T\n",
        "b_hh = ornn.state_dict()['bias_hh_l0']\n",
        "\n",
        "result = torch.tanh(XWi+b_ih+hWh+b_hh)\n",
        "```\n",
        "\n",
        "\n",
        "```python\n",
        "# 自行計算rnn的另一種方式(用@取代matmul)\n",
        "XWi = data@torch.nn.Parameter(ornn.weight_ih_l0.T) # Xt*W_ih^T\n",
        "b_ih = torch.nn.Parameter(ornn.bias_ih_l0)\n",
        "hWh = h0@torch.nn.Parameter(ornn.weight_hh_l0.T) # h0*W_hh^T\n",
        "b_hh = torch.nn.Parameter(ornn.bias_hh_l0)\n",
        "\n",
        "result0 = torch.tanh(XWi+b_ih+hWh+b_hh)\n",
        "```\n",
        "* `resultf`與`official_hn`(`official_output`),結果相同\n",
        "* `result`、`result0`、`resultf等,三個結果均相同\n"
      ],
      "metadata": {
        "id": "hE3KVuuHmXVF"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XeY-vLo67T9p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CASE 2\n",
        "### 範例二：沒有batch, data(如句子)有兩個時間點的資料(seq_len=2, 如只含有2單詞)"
      ],
      "metadata": {
        "id": "4IIYe8rF3EZx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#network parameters\n",
        "input_size = 2   # 輸入神經元 Xt (t指某個時間) 的特徵向量長度\n",
        "hidden_size = 2  # hidden h 的特徵向量長度\n",
        "num_layers = 1   # 只有一層 hidden layer A\n",
        "\n",
        "#data parameters\n",
        "seq_len = 2\n",
        "data_dim = input_size"
      ],
      "metadata": {
        "id": "uWHRDajO3I1Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#input data\n",
        "data = torch.randn(seq_len, data_dim)\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "COsfVkQ3p95K",
        "outputId": "c14812ce-bbfd-4ea8-b271-ed353c61afa3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.3186, 0.2621],\n",
              "        [0.0803, 0.1127]])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* data的shpae是[2,2], 與官網說明(如下)完全一致\n",
        "> -- **input**: tensor of shape (*L*,*H_in*) for unbatched input -- *L* 是 seq_len, *H_in* 是 input_size"
      ],
      "metadata": {
        "id": "_PQJdYeXRPlv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#official rnn in pytorch\n",
        "ornn = nn.RNN(input_size, hidden_size, num_layers)"
      ],
      "metadata": {
        "id": "CdAt8fYaqbjO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#init hidden state\n",
        "h0 = torch.randn(num_layers,hidden_size)\n",
        "h0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZsyeK2SqgOn",
        "outputId": "6f19d4d2-1cd9-4009-b5b7-aa7b35a74cdf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.8117, -1.3520]])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* h0的shape是[1,2], 與官網說明(如下)完全一致\n",
        "> -- **h_0**: tensor of shape (*D* * *num_layers*, *H_out*) for unbatched input -- *D* 是 1 (非雙向), *H_out* 是 hidden_size"
      ],
      "metadata": {
        "id": "6-1n6t_OSb89"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#輸入data，根據h0執行ornn\n",
        "official_output, official_hn = ornn(data,h0)\n",
        "official_output, official_hn ## official_output的最後一個row跟official_hn是一樣的"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SRvI7xpRqhoF",
        "outputId": "10812961-1b8a-4096-e6b0-5dfa1d108d7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[-0.4101,  0.3046],\n",
              "         [-0.2281,  0.7439]], grad_fn=<SqueezeBackward1>),\n",
              " tensor([[-0.2281,  0.7439]], grad_fn=<SqueezeBackward1>))"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* official_output的shape是[2,2],與官網說明(如下)完全一致\n",
        "> --**output**: tensor of shape (*L*, *D* * *H_out*) for unbatched input\n",
        "* official_hn的shape是[1,2],與官網說明(如下)完全一致\n",
        "> --**h_n**--: tensor of shape (*D* * *num_layers*, *H_out*) for unbatched input"
      ],
      "metadata": {
        "id": "y6ncVDwtFWPB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 自行計算rnn：此時 X(t) 是 data[0]\n",
        "XWi = data[0]@ornn.weight_ih_l0.data.T # 執行Xt*W_ih^T\n",
        "#[1,2] <- [1,2]@[2,2]\n",
        "b_ih = ornn.bias_ih_l0.data\n",
        "#[1,2] <- [1,2]\n",
        "hWh = h0@ornn.weight_hh_l0.data.T # h0*W_hh^T\n",
        "#[1,2] <- [1,2]@[2,2]\n",
        "b_hh = ornn.bias_hh_l0.data\n",
        "#[1,2] <- [1,2]\n",
        "h1 = torch.tanh(XWi+b_ih+hWh+b_hh)\n",
        "#[1,2] <- [1,2]+[1,2]+[1,2]+[1,2]\n",
        "h1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3mUWHZKYtkhr",
        "outputId": "2d7eed20-829c-4892-82ca-7293a0f60f9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.4101,  0.3046]])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 此時輸入是 X(t+1) 是 data[1] , h1 是 result\n",
        "XWi = data[1]@ornn.weight_ih_l0.data.T # X(t+1)*W_ih^T\n",
        "#[1,2] <- [1,2]@[2,2]\n",
        "hWh = h1@ornn.weight_hh_l0.data.T # h1*W_hh^T\n",
        "#[1,2] <- [1,2]@[2,2]\n",
        "result = torch.tanh(XWi+b_ih+hWh+b_hh)\n",
        "#[1,2] <- [1,2]+[1,2]+[1,2]+[1,2]\n",
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MhFpfBGW1woq",
        "outputId": "e86277a7-c707-4034-b520-5a5690a8d89f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.2281,  0.7439]])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* `result`跟`official_hn`是一樣的\n",
        "* `h1`與`result`合起來跟`official_output`是一樣的"
      ],
      "metadata": {
        "id": "skZqPzSS2dM-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CASE 3\n",
        "\n",
        "### 範例三：有batch, data(如句子)只有一個時間點的資料(seq_len=1, 如只含有一單詞) <font color=\"red\">`batch_first=False`(by default)</font>"
      ],
      "metadata": {
        "id": "B5poVHff2zt2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#network parameters\n",
        "input_size = 2   # 輸入神經元 Xt (t指某個時間) 的特徵向量長度\n",
        "hidden_size = 3  # hidden h 的特徵向量長度\n",
        "num_layers = 1   # 只有一層 hidden layer A"
      ],
      "metadata": {
        "id": "HL5HVAI22ye9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#data parameters\n",
        "seq_len = 1\n",
        "batch_size = 2  ## case3 使用 batch\n",
        "data_dim = input_size"
      ],
      "metadata": {
        "id": "fKYwHHzJ3pfA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#input data\n",
        "data = torch.randn(seq_len, batch_size, data_dim)\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aO9SW3as3sg_",
        "outputId": "0cae440f-d06d-4366-b08c-fcaab4728686"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 1.3097,  0.5200],\n",
              "         [-0.0141,  0.9497]]])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* data的shpae是[1,2,2], 與官網說明(如下)完全一致\n",
        "> -- **input**: tensor of shape (*L*, *N*, *H_in*) when `batch_first=Falset` -- *L* 是 seq_len, *N* 是 batch_size, *H_in* 是 input_size"
      ],
      "metadata": {
        "id": "-sPiC-I1SuCF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#official rnn in pytorch\n",
        "ornn = nn.RNN(input_size, hidden_size, num_layers)"
      ],
      "metadata": {
        "id": "Om6RleIR5Un8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#init hidden state\n",
        "h0 = torch.randn(num_layers,batch_size,hidden_size)\n",
        "h0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kiJkGm8D5ZzC",
        "outputId": "a550e83c-1176-4c46-cf76-cdb3f02070c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.1118,  1.9961, -1.8162],\n",
              "         [-2.0644, -1.5025, -0.8198]]])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* h0的shape是[1,2,3], 與官網說明(如下)完全一致\n",
        "> -- **input**: tensor of shape (*D* * *num_layers*, *N*, *H_out*) -- *D* 是 1 (非雙向), *N* 是 batch_size, *H_out* 是 hidden_size"
      ],
      "metadata": {
        "id": "La4Fon6kUUDy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#輸入data，根據h0執行ornn\n",
        "official_output, official_hn = ornn(data,h0)\n",
        "official_output, official_hn # 兩者結果會相同,因為seq_len=1,official_output就是official_hn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jESgc6Ly5b5a",
        "outputId": "bffc0953-01bc-41c4-f9e2-b2abe81b1780"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[-0.5961,  0.2450, -0.4397],\n",
              "          [ 0.7579, -0.9576,  0.0932]]], grad_fn=<StackBackward0>),\n",
              " tensor([[[-0.5961,  0.2450, -0.4397],\n",
              "          [ 0.7579, -0.9576,  0.0932]]], grad_fn=<StackBackward0>))"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* official_output的shape是[1,2,3],與官網說明(如下)完全一致\n",
        "> --**output**: tensor of shape (*L*, *N*, *D* * *H_out*) when batch_first=False\n",
        "* official_hn的shape是[1,2,3],與官網說明(如下)完全一致\n",
        "> --**h_n**--: tensor of shape (*D* * num_layers, *N*, *H_out*)"
      ],
      "metadata": {
        "id": "zZZyzdOaFkG4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "```python\n",
        "for name, param in ornn.named_parameters():\n",
        "    print(name, param.data)\n",
        "    \n",
        "# 顯示實例\n",
        "# weight_ih_l0 tensor([[ 0.2118,  0.1362],\n",
        "#             [-0.2425, -0.0603],\n",
        "#             [-0.2240, -0.1886]])\n",
        "# weight_hh_l0 tensor([[-0.5366, -0.1552,  0.1902],\n",
        "#             [ 0.5705,  0.2271, -0.4266],\n",
        "#             [ 0.2376, -0.4090, -0.5661]])\n",
        "# bias_ih_l0 tensor([ 0.1009, -0.4630,  0.1333])\n",
        "# bias_hh_l0 tensor([-0.4209, -0.2299, -0.4520])\n",
        "```\n",
        "* 注意`weight_ih_l0`的下標是`ih` , `i`是`input`(size為2) , `h`是`hidden`(size為3), 但`weight_ih_l0`的size是(3,2)\n"
      ],
      "metadata": {
        "id": "fL4n8SOEBPOd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 自行計算rnn的一種方式,也是最簡化的方式(用.data取代nn.Parameter)\n",
        "XWi = data@ornn.weight_ih_l0.data.T # 執行Xt*W_ih^T\n",
        "#[1,2,3] <- [1,2,2]@[2,3]\n",
        "b_ih = ornn.bias_ih_l0.data\n",
        "#[1,3] <- [1,3]\n",
        "hWh = h0@ornn.weight_hh_l0.data.T # h0*W_hh^T\n",
        "#[1,2,3] <- [1,2,3]@[3,3]\n",
        "b_hh = ornn.bias_hh_l0.data\n",
        "#[1,3] <- [1,3]\n",
        "resultf = torch.tanh(XWi+b_ih+hWh+b_hh)\n",
        "#[1,2,3] <- [1,2,3]+[1,3]+[1,2,3]+[1,3] ## [1,3] 會擴展成 [2,3] 再展成 [1,2,3]\n",
        "resultf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TVEMuEgNC6Ms",
        "outputId": "fcb880d2-1203-4190-c29b-459f039acc9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-0.5961,  0.2450, -0.4397],\n",
              "         [ 0.7579, -0.9576,  0.0932]]])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* `result`跟`official_hn`(`official_hn`)是一樣的"
      ],
      "metadata": {
        "id": "We9aAjo4gitu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CASE -- Customized RNN Model\n",
        "\n",
        "### 自訂具結構性的RNN模型(根據之前`自行計算rnn方式`)"
      ],
      "metadata": {
        "id": "u3ocSqixgrRU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#rnn implemented by myself\n",
        "class MyRNN():\n",
        "    def __init__(self):\n",
        "        #keep weights and bias parameters the same with official rnn\n",
        "        # to make the compare with official rnn by final result\n",
        "        self.W_ih = torch.nn.Parameter(ornn.weight_ih_l0.T)\n",
        "        self.b_ih = torch.nn.Parameter(ornn.bias_ih_l0)\n",
        "        self.W_hh = torch.nn.Parameter(ornn.weight_hh_l0.T)\n",
        "        self.b_hh = torch.nn.Parameter(ornn.bias_hh_l0)\n",
        "        self.ht = torch.nn.Parameter(h0)\n",
        "        self.myoutput = []\n",
        "\n",
        "    def forward(self,x): ## x 就是之後將輸入的data\n",
        "        for i in range(seq_len):\n",
        "            igates = x[i] @ self.W_ih + self.b_ih\n",
        "            hgates = self.ht @ self.W_hh + self.b_hh\n",
        "            self.ht = torch.tanh(igates + hgates)\n",
        "            self.myoutput.append(self.ht)\n",
        "        return self.ht,self.myoutput"
      ],
      "metadata": {
        "id": "fuziEW0mhkua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "myrnn = MyRNN()\n",
        "myht,myoutput = myrnn.forward(data)\n",
        "myht,myoutput"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yYz0FcEmiKEt",
        "outputId": "b29d9bb1-ff85-4673-daa0-f135a9a652fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[-0.5961,  0.2450, -0.4397],\n",
              "          [ 0.7579, -0.9576,  0.0932]]], grad_fn=<TanhBackward0>),\n",
              " [tensor([[[-0.5961,  0.2450, -0.4397],\n",
              "           [ 0.7579, -0.9576,  0.0932]]], grad_fn=<TanhBackward0>)])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 注意如果要寫成 myht, myoutput = myrnn(data), `class MyRNN()`要改成如下"
      ],
      "metadata": {
        "id": "XpFFQKjZn17E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyRNN(nn.Module): # 修改過, 否則 object is not callable\n",
        "    def __init__(self):\n",
        "        super(MyRNN,self).__init__() # 修改過, 否則 object is not callable\n",
        "\n",
        "        self.W_ih = torch.nn.Parameter(ornn.weight_ih_l0.T)\n",
        "        self.b_ih = torch.nn.Parameter(ornn.bias_ih_l0)\n",
        "        self.W_hh = torch.nn.Parameter(ornn.weight_hh_l0.T)\n",
        "        self.b_hh = torch.nn.Parameter(ornn.bias_hh_l0)\n",
        "        self.ht = torch.nn.Parameter(h0)\n",
        "        self.myoutput = []\n",
        "\n",
        "    def forward(self,x):\n",
        "        for i in range(seq_len):\n",
        "            igates = torch.matmul(x[i],self.W_ih) + self.b_ih\n",
        "            hgates = torch.matmul(self.ht,self.W_hh) + self.b_hh\n",
        "            self.ht = torch.nn.Parameter(torch.tanh(igates + hgates)) # 修改過\n",
        "            # 若上行沒修改過,則 cannot assign 'torch.FloatTensor' as parameter ht\n",
        "            # 或是上行不執行, 以下self.ht直接用 torch.tanh(igates + hgates)取代\n",
        "            self.myoutput.append(self.ht.data)\n",
        "        return self.ht.data,self.myoutput"
      ],
      "metadata": {
        "id": "6IWBHet_nnwB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "myrnn = MyRNN()\n",
        "myht,myoutput = myrnn.forward(data)\n",
        "myht,myoutput"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oiAfO9-8obRX",
        "outputId": "7f72bf5d-bdf0-40a9-f33f-466d3f5f51c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[-0.5961,  0.2450, -0.4397],\n",
              "          [ 0.7579, -0.9576,  0.0932]]]),\n",
              " [tensor([[[-0.5961,  0.2450, -0.4397],\n",
              "           [ 0.7579, -0.9576,  0.0932]]])])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# [CLASS torch.nn.RNN 官網說明](https://pytorch.org/docs/stable/generated/torch.nn.RNN.html#torch.nn.RNN)"
      ],
      "metadata": {
        "id": "0zTLwIVPH-d5"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HFfRBjBDIOJS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RNN VS. LSTM"
      ],
      "metadata": {
        "id": "C9EiPWj92hiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color=\"red\">C1 -- RNN,且`batch_first=False`(by default) 附 結構圖</font>"
      ],
      "metadata": {
        "id": "p5vbhB01NQti"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = 5 ##L\n",
        "hidden_size = 5*2 ##L\n",
        "num_layers = 2 ##L\n",
        "\n",
        "seq_len = 3 ##L\n",
        "batch_size = 4 ##L\n",
        "data_dim = input_size"
      ],
      "metadata": {
        "id": "EqSLJweg4BHZ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = torch.randn(seq_len, batch_size, data_dim) ## 給 ornn 模型使用\n",
        "\"\"\"data 的 shape, 就是 seq_len,batch_size,data_dim\"\"\"\n",
        "\n",
        "ornn = nn.RNN(input_size, hidden_size, num_layers) # batch_first = False (by default)\n",
        "\n",
        "\n",
        "h0 = torch.randn(num_layers,batch_size,hidden_size) # optional -- 可以不提供\n",
        "\"\"\"h0 的 shape, 就是 num_layers,batch_size,hidden_size\"\"\"\n",
        "\n",
        "ornn_out, o_hn = ornn(data,h0) # h0 可以不提供\n",
        "data.shape, h0.shape, ornn_out.shape, o_hn.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "51syfcBj5MyN",
        "outputId": "b3029f59-1a7d-42e2-f3fb-931409e23dcd"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([3, 4, 5]),\n",
              " torch.Size([2, 4, 10]),\n",
              " torch.Size([3, 4, 10]),\n",
              " torch.Size([2, 4, 10]))"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* ornn_out的shape是[3,4,10],與官網說明(如下)完全一致\n",
        "> --**output**: tensor of shape (*L*, *N*, *D* * *H_out*) when batch_first=False\n",
        "* o_hn的shape是[2,4,10],與官網說明(如下)完全一致\n",
        "> --**h_n**--: tensor of shape (*D* * num_layers, *N*, *H_out*)"
      ],
      "metadata": {
        "id": "o6N-PGaoG2NQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## 顯示模型中的weights與bias\n",
        "for name, param in ornn.named_parameters():\n",
        "  print(name, param.data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kBgBFMUKA2ww",
        "outputId": "087ee01a-ad08-4164-d831-5d11a2c97797"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "weight_ih_l0 torch.Size([10, 5])\n",
            "weight_hh_l0 torch.Size([10, 10])\n",
            "bias_ih_l0 torch.Size([10])\n",
            "bias_hh_l0 torch.Size([10])\n",
            "weight_ih_l1 torch.Size([10, 10])\n",
            "weight_hh_l1 torch.Size([10, 10])\n",
            "bias_ih_l1 torch.Size([10])\n",
            "bias_hh_l1 torch.Size([10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"./images/shapes.jpg\">"
      ],
      "metadata": {
        "id": "xVXrMpngNxb3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color=\"red\">C2 -- RNN,且`batch_first=True`</font>"
      ],
      "metadata": {
        "id": "5UwPIY4m-GfO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "N = 256    ## batch_size\n",
        "L = 150    ## tokens(seq_len)\n",
        "Hin = 256   ## input_size\n",
        "Hout = 128  ## hidden_size"
      ],
      "metadata": {
        "id": "f6wkJsVo_7il"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ndata = torch.randn(N, L, Hin) ## 給 nrnn 模型使用 (假設此 ndata 是經過 Embedding Model 處理後的output)\n",
        "\n",
        "nrnn = nn.RNN(Hin, Hout, 1, batch_first=True) ## 1 指的是 num_layers\n",
        "\n",
        "nrnn_out, nhn = nrnn(ndata) ## 不提供 h_0\n",
        "ndata.shape, nrnn_out.shape, nhn.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hJKaLs137XqC",
        "outputId": "768b386f-6d09-46a8-b8c8-afd33e5ca311"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([256, 150, 256]),\n",
              " torch.Size([256, 150, 128]),\n",
              " torch.Size([1, 256, 128]))"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 顯示模型中的weights與bias\n",
        "for name, param in nrnn.named_parameters():\n",
        "  print(name, param.data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G2GUJM04AfBb",
        "outputId": "eba6dcef-bf7a-4704-da9e-4459ac39e129"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "weight_ih_l0 torch.Size([128, 256])\n",
            "weight_hh_l0 torch.Size([128, 128])\n",
            "bias_ih_l0 torch.Size([128])\n",
            "bias_hh_l0 torch.Size([128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color=\"red\">C3 -- LSTM,且`batch_first=True`</font>"
      ],
      "metadata": {
        "id": "x10oCHIU_W0h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "N = 256    ## batch_size\n",
        "L = 150    ## tokens(seq_len)\n",
        "Hin = 256   ## input_size\n",
        "Hout = 128  ## hidden_size"
      ],
      "metadata": {
        "id": "yZaF1qAt_4NI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embout = torch.randn(256, 150, 256)   # batch =256, tokens(seq_len) = 150, input_size = 256\n",
        "\n",
        "lstm = nn.LSTM(256, 128, 1, batch_first=True)\n",
        "\n",
        "out, (hn, cn) = lstm(embout)\n",
        "embout.shape, out.shape, hn.shape, cn.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aRsyrToN50iM",
        "outputId": "e1b834e4-8ad8-4029-b948-225b499ba1c7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([256, 150, 256]),\n",
              " torch.Size([256, 150, 128]),\n",
              " torch.Size([1, 256, 128]),\n",
              " torch.Size([1, 256, 128]))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 顯示模型中的weights與bias\n",
        "for name, param in lstm.named_parameters():\n",
        "  print(name, param.data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9iGoYrdMBJao",
        "outputId": "b1fa11a1-9a0d-4229-b326-f18c8b9ae9a7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "weight_ih_l0 torch.Size([512, 256])\n",
            "weight_hh_l0 torch.Size([512, 128])\n",
            "bias_ih_l0 torch.Size([512])\n",
            "bias_hh_l0 torch.Size([512])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "-FaUjT3JCCil"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color=\"red\">C4 -- LSTM,且`batch_first=True`</font>"
      ],
      "metadata": {
        "id": "Tco-txmiHl0n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# data.shape, h0.shape, official_output.shape, official_hn.shape, ndat.shape, nrnn_out.shape, nhn.shape\n",
        "lstmn = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "\n",
        "input = torch.randn(batch_size, seq_len, data_dim)\n",
        "\n",
        "output, (hn, cn) = lstmn(input)\n",
        "output.shape, hn.shape, cn.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nz-cTsp52nCU",
        "outputId": "3f763983-a8ca-4849-cde1-b7d4bd7bd45d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([4, 3, 10]), torch.Size([2, 4, 10]), torch.Size([2, 4, 10]))"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 顯示模型中的weights與bias\n",
        "for name, param in lstmn.named_parameters():\n",
        "  print(name, param.data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2dOyKu95CEbL",
        "outputId": "7fd7d7af-fc8d-4eee-fadb-6b4c14dd6fb0"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "weight_ih_l0 torch.Size([40, 5])\n",
            "weight_hh_l0 torch.Size([40, 10])\n",
            "bias_ih_l0 torch.Size([40])\n",
            "bias_hh_l0 torch.Size([40])\n",
            "weight_ih_l1 torch.Size([40, 10])\n",
            "weight_hh_l1 torch.Size([40, 10])\n",
            "bias_ih_l1 torch.Size([40])\n",
            "bias_hh_l1 torch.Size([40])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* <font color=\"red\">`lstmn`的`parameters`數量,對比**C1**中,`ornn`的`parameters`數量,前者是後者的4倍。因為`RNN`的每一個輸出運算,在`LSTM`中,包括`% Long-Term To Remember`, `% Potential Memory To Remember`, `Potential Long-Term Memory`, `% Potential Memory To Remember`等四個單元運算,所以才會有`4倍`的模型參數</font>"
      ],
      "metadata": {
        "id": "f8UEWAfZHOQd"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pxOejwxOCG39"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
