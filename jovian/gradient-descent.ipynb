{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bElTrMJeHoiN"
   },
   "source": [
    "# <center><font color=\"brown\">one variable is unknown</font></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t_xeYbcwHoiy"
   },
   "source": [
    "$$\\hat{y}=\\it{b}+\\it{m}\\times x$$\n",
    "\n",
    "* $\\hat{y}$ : predicated height，$\\it{b}$ : intercept，$\\it{m}$ : slope，$\\it{x}$ : input weight。The residual equation can be shown below.\n",
    ">\n",
    ">$$Res=y-\\hat{y}$$\n",
    "\n",
    "* Assume that $m=0.64$ (i.e., slope is known). Initially, pick a random value for $b$. Assume that $b$ is set to be zero.\n",
    ">\n",
    "> * When (x,y)=(0.5, 1.4),\n",
    "> $$Res=y-\\hat{y}=1.4-(0.64\\times 0.5)=1.1$$\n",
    "> * When (x,y)=(2.3, 1.9),\n",
    "> $$Res=y-\\hat{y}=1.9-(0.64\\times 2.3)=0.4$$\n",
    "> * When (x,y)=(2.9, 3.2),\n",
    "> $$Res=y-\\hat{y}=3.2-(0.64\\times 2.9)=1.3$$\n",
    "\n",
    "* The sum of squared residuals (SSR) is\n",
    "> $1.1^2 + 0.4^2 + 1.3^2 = 3.1$\n",
    "\n",
    "* The goal is by changing $b$ value again and again to make SSR smaller. In this case, the SSR can be expressed as\n",
    ">\n",
    "> $SSR = (1.4 - (b+0.64\\times 0.5))^2 + (1.9 - (b+0.64\\times 2.3))^2 + (3.2 - (b+0.64\\times 2.9))^2$\n",
    "\n",
    "* The gradient of SSR is as follows\n",
    ">\n",
    "> $\\frac{d(SSR)}{db} = -2((1.4 - (b+0.64\\times 0.5)) \\\\-2(1.9 - (b+0.64\\times 2.3)) \\\\-2(3.2 -(b+0.64\\times 2.9))$\n",
    "\n",
    "* Another term step_size is required. \"step_size\" is how $b$ changes between each calculation of the model. step_size at b being $\\underline{b}$ is defined as\n",
    ">\n",
    "> $$step\\_size = \\alpha \\times \\frac{d(SSR)}{db}\\Bigr|_{b=\\underline{b}}$$\n",
    "\n",
    "* Here $\\alpha$ is called <em>learning rate</em>. For each calculation of the model, the value of $b$ would be updated as follows.\n",
    ">\n",
    "> $$b_{new}=b_{old}-step\\_size=b_{old}-\\alpha \\times \\frac{d(SSR)}{db}\\Bigr|_{b=b_{old}} $$\n",
    "\n",
    "* Obviously, when $\\frac{d(SSR)}{db}\\Bigr|_{b=b_{old}}$ is negative, $b_{new}$ should be larger than $b_{old}$. On the other hand, when $\\frac{d(SSR)}{db}\\Bigr|_{b=b_{old}}$ is positive, $b_{new}$ should be smaller than $b_{old}$.\n",
    "\n",
    "<hr>\n",
    "\n",
    "* Now, initializing `bias` and `learning rate` as $b=0，\\alpha=0.1$\n",
    ">\n",
    "> * run 1:\n",
    ">\n",
    "> $$\\frac{d(SSR)}{db}\\Bigr|_{b=0}=-5.7$$\n",
    ">\n",
    "> $$step_{size}=-5.7\\times 0.1=-0.57$$\n",
    ">\n",
    "> $$b_{new}=b_{old}-step\\_size=0-(-0.57)=0.57$$\n",
    ">\n",
    "> * run 2:\n",
    ">\n",
    "> $$\\frac{d(SSR)}{db}\\Bigr|_{b=0.57}=-2.3$$\n",
    ">\n",
    "> $$step_{size}=-2.3\\times 0.1=-0.23$$\n",
    ">\n",
    "> $$b_{new}=b_{old}-step\\_size=0.57-(-0.23)=0.8$$\n",
    ">\n",
    "> * run 3:\n",
    ">\n",
    "> $$\\frac{d(SSR)}{db}\\Bigr|_{b=0.8}=-0.9$$\n",
    ">\n",
    "> $$step_{size}=-0.9\\times 0.1=-0.09$$\n",
    ">\n",
    "> $$b_{new}=b_{old}-step\\_size=0.8-(-0.09)=0.89$$\n",
    ">\n",
    "> * run 4:\n",
    ">\n",
    "> $$\\frac{d(SSR)}{db}\\Bigr|_{b=0.89}=-0.3$$\n",
    ">\n",
    "> $$step_{size}=-0.3\\times 0.1=-0.03$$\n",
    ">\n",
    "> $$b_{new}=b_{old}-step\\_size=0.89-(-0.03)=0.92$$\n",
    ">\n",
    "> * run 5 (skip details):\n",
    ">\n",
    "> $$b_{new}=0.94$$\n",
    ">\n",
    "> * run 6 (skip details):\n",
    ">\n",
    "> $$b_{new}=0.95$$\n",
    "\n",
    "* After 6 runs, $SSR=0.95$. It is much closer to 0, compared to the $SSR=3.1$ in the first run.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6u7rKXWIHoi_"
   },
   "source": [
    "## <center>Summary</center>\n",
    "1. Figure out $SSR$.\n",
    "\n",
    "2. Based on $SSR$, figure out $\\frac{d(SSR)}{db}$\n",
    "\n",
    "3. Pick a random number $\\underline{b}$ as the initial value of $b$\n",
    "\n",
    "4. Find out the slope= $\\frac{d(SSR)}{db}\\Bigr|_{b=\\underline{b}}$\n",
    "\n",
    "5. Then, step_size = $\\alpha$ $\\times$ slope\n",
    "\n",
    "6. $b_{new}$ = $b_{old}$  - step_size\n",
    "\n",
    "repeat the above process until step_size $<$ 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "csxRG6-sHojE"
   },
   "source": [
    "# <center><font color=\"brown\">two variables are both unknown</font></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sb7oShCAHojH"
   },
   "source": [
    "$$\\hat{y}=\\it{b}+\\it{m}\\times x$$\n",
    "\n",
    "* More generally, $m$ and $b$ are both unknown\n",
    ">\n",
    "> $$SSR = (1.4 - (b+m\\times 0.5))^2 + (1.9 - (b+m\\times 2.3))^2 + (3.2 - (b+m\\times 2.9))^2$$\n",
    ">\n",
    "> $$MSE = \\frac{1}{3}SSR$$\n",
    ">\n",
    "> $MSE$ is known as Loss Function.\n",
    ">\n",
    "* The goal is to minimize $MSE$. The gradient of $MSE$ is as follows\n",
    ">\n",
    "> $$\\frac{\\partial(MSE)}{\\partial b}=\\frac{1}{3}\\frac{\\partial(SSR)}{\\partial b}$$\n",
    ">\n",
    "> $$\\frac{\\partial(MSE)}{\\partial m}=\\frac{1}{3}\\frac{\\partial(SSR)}{\\partial m}$$\n",
    ">\n",
    "> $$\\frac{\\partial(SSR)}{\\partial b} = -2((1.4 - (b+m\\times 0.5)) \\\\-2(1.9 - (b+m\\times 2.3)) \\\\-2(3.2 - (b+m\\times 2.9))$$\n",
    ">\n",
    "> $$\\frac{\\partial(SSR)}{\\partial m} = -2\\times 0.5\\times(1.4 - (b+m\\times 0.5)) \\\\-2\\times 2.3\\times (1.9 - (b+m\\times 2.3)) \\\\-2\\times 2.9 \\times(3.2 - (b+m\\times 2.9))$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ovzXuv7yHojJ"
   },
   "source": [
    "* Pick a random number for $b$ and another number for $m$. Assume that $b$=0 and $m$=1.  \n",
    "> * run 1:\n",
    "> $$\\frac{1}{3}\\frac{\\partial(SSR)}{\\partial b}\\Bigr|_{b=0}=-0.5333$$\n",
    "> $$\\frac{1}{3}\\frac{\\partial(SSR)}{\\partial m}\\Bigr|_{m=1}=-0.2667$$\n",
    ">\n",
    "> $$step\\_size_b = -0.5333\\times(0.01)$$\n",
    "> $$step\\_size_m = -0.2667\\times(0.01)$$\n",
    ">\n",
    "> $$b_{new} = 0-(-0.0053)=0.0053$$\n",
    "> $$m_{new} = 1-(-0.0026)=1.0027$$\n",
    ">\n",
    "> * run 2:\n",
    "> $$\\frac{1}{3}\\frac{\\partial(SSR)}{\\partial b}\\Bigr|_{b=0.016}=-0.5125$$\n",
    "> $$\\frac{1}{3}\\frac{\\partial(SSR)}{\\partial m}\\Bigr|_{m=1.008}=-0.2216$$\n",
    ">\n",
    "> $$step\\_size_b = -0.5125\\times(0.01)$$\n",
    "> $$step\\_size_m = -0.2216\\times(0.01)$$\n",
    ">\n",
    "> $$b_{new} = 0.0053-(-0.005125)=0.0105$$\n",
    "> $$m_{new} = 1.0027-(-0.002216)=1.0049$$\n",
    ">\n",
    "> * After much more runs:\n",
    ">\n",
    "> $$b_{new} = 0.95$$\n",
    "> $$m_{new} = 0.64$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RrVwTsEYHojL"
   },
   "source": [
    "## Conslusion\n",
    "\n",
    "* Step 1: Find out $SSR$ and list variable parameters (e.g., $b_1\\ldots m_1\\ldots $). Figure out the gradient formulas $\\bigstar$ of $SSR$ (e.g., $\\frac{\\partial (SSR)}{\\partial b_1}\\ldots \\frac{\\partial (SSR)}{\\partial m_1}\\ldots $)\n",
    "\n",
    "* Step 2: Pick random values for those variable parameters (e.g., $b_1\\ldots m_1\\ldots $)\n",
    "\n",
    "* Step 3: Plug those values in Step 2 into $\\bigstar$ to obtain the slope\n",
    "\n",
    "* Step 4: Find out $step\\_size= \\alpha\\times slope$\n",
    "\n",
    "* Step 5: Update the values for all the variable parameters\n",
    "> $$b_i^{new} = b_i^{new}$$\n",
    "> $$\\vdots$$\n",
    "> $$m_i^{new} = m_i^{new}$$\n",
    "> $$\\vdots$$\n",
    "\n",
    "Repeat Step 3 $\\sim$ Step 5 until $step_size$ $<$ a very small number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-EbaHQgisZNy"
   },
   "source": [
    "# <font color=\"brown\">PyTorch 操作示範</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w5YV2yvlHojO"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uQgxgDoSHojY"
   },
   "outputs": [],
   "source": [
    "# known input data\n",
    "inputs = np.array([[0.5],\n",
    "           [2.3],\n",
    "           [2.9]],\n",
    "           dtype='float32')\n",
    "targets = np.array([[1.4],\n",
    "            [1.9],\n",
    "            [3.2]],\n",
    "            dtype='float32')\n",
    "inputs = torch.from_numpy(inputs)\n",
    "targets = torch.from_numpy(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 424,
     "status": "ok",
     "timestamp": 1702792942542,
     "user": {
      "displayName": "Henry Hsu",
      "userId": "15979258104560629822"
     },
     "user_tz": 360
    },
    "id": "6LuNwBIAHojc",
    "outputId": "af983ef1-005f-41eb-e478-3c886a9374e1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1.]], requires_grad=True), tensor([[0.]], requires_grad=True))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set up the initial values for w and b\n",
    "w = torch.Tensor([[1]]).requires_grad_(True)\n",
    "b = torch.Tensor([[0]]).requires_grad_(True)\n",
    "\n",
    "w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7EfX8kPiHojk"
   },
   "outputs": [],
   "source": [
    "# define the linear regresssion model\n",
    "def model(x):\n",
    "    return x @ w.t() + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XWToPz8OHojn"
   },
   "outputs": [],
   "source": [
    "# define the loss function, based on the mean squared error (MSE).\n",
    "def mse(t1, t2):\n",
    "    diff = t1 - t2\n",
    "    return torch.sum(diff * diff) / diff.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 590,
     "status": "ok",
     "timestamp": 1702781075025,
     "user": {
      "displayName": "Henry Hsu",
      "userId": "15979258104560629822"
     },
     "user_tz": 360
    },
    "id": "2RUMwSK3Hojp",
    "outputId": "2623effc-a7d3-4b24-eeed-ae33683838bd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3533, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# before training, one can take a look at the initial loss value\n",
    "loss = mse(model(inputs), targets)\n",
    "loss\n",
    "# Notes that, based on the initial values of w and b,\n",
    "# mse(inputs, targets) = mse(model(inputs), targets). Since w=1 and b=0, model(inputs)=inputs\n",
    "# [(0.5-1.4)^2 + (2.3-1.9)^2 + (2.9-3.2)^2]/3 = 0.3533"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p8bXZIKAHojy"
   },
   "source": [
    "## run 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1194,
     "status": "ok",
     "timestamp": 1702793134127,
     "user": {
      "displayName": "Henry Hsu",
      "userId": "15979258104560629822"
     },
     "user_tz": 360
    },
    "id": "j7Ft1odYHoj0",
    "outputId": "ee770f24-9e99-443a-831a-461622099df6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3533, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"計算損失\"\"\"\n",
    "preds = model(inputs)\n",
    "loss = mse(preds, targets)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KXt8GjDCHoj2"
   },
   "outputs": [],
   "source": [
    "\"\"\"對損失函數求導\"\"\"\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 611,
     "status": "ok",
     "timestamp": 1702793146388,
     "user": {
      "displayName": "Henry Hsu",
      "userId": "15979258104560629822"
     },
     "user_tz": 360
    },
    "id": "TlFSOVBAHoj4",
    "outputId": "cdda7cb8-11e6-4710-a55e-65fb22941597"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "del loss / del w =  tensor([[-0.2667]])\n",
      "del loss / del b =  tensor([[-0.5333]])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Gradients for weights (第1輪)\"\"\"\n",
    "\n",
    "print(\"del loss / del w = \",w.grad) # 或 print(w.grad.data)\n",
    "print(\"del loss / del b = \",b.grad) # 或 print(b.grad.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tx4JTcJkHoj6"
   },
   "outputs": [],
   "source": [
    "\"\"\"更新 w, b\"\"\"\n",
    "with torch.no_grad():\n",
    "  w -= w.grad * 1e-2\n",
    "  b -= b.grad * 1e-2\n",
    "  w.grad.zero_()\n",
    "  b.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 426,
     "status": "ok",
     "timestamp": 1702794557686,
     "user": {
      "displayName": "Henry Hsu",
      "userId": "15979258104560629822"
     },
     "user_tz": 360
    },
    "id": "XqKX6us2Hoj9",
    "outputId": "9e3d4496-eae6-49c2-c91b-3e973ea17816"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0027]], requires_grad=True)\n",
      "tensor([[0.0053]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"(第1輪)顯示w, b更新後的結果\"\"\"\n",
    "print(w)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 646,
     "status": "ok",
     "timestamp": 1702797264175,
     "user": {
      "displayName": "Henry Hsu",
      "userId": "15979258104560629822"
     },
     "user_tz": 360
    },
    "id": "pFTPBUVsHoj_",
    "outputId": "4ada0c0a-9092-4350-a12b-8e5b9b844f22"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5067],\n",
      "        [2.3115],\n",
      "        [2.9131]], grad_fn=<AddBackward0>)\n",
      "tensor([[1.4000],\n",
      "        [1.9000],\n",
      "        [3.2000]])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"顯示一下，最新的預測結果，對比真實結果\"\"\"\n",
    "preds = model(inputs)\n",
    "print(preds)  # 預測結果\n",
    "print(targets) # 真實結果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dS5ClxjzHokB"
   },
   "source": [
    "## run2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 508,
     "status": "ok",
     "timestamp": 1702798226076,
     "user": {
      "displayName": "Henry Hsu",
      "userId": "15979258104560629822"
     },
     "user_tz": 360
    },
    "id": "tpSlx7PHHokD",
    "outputId": "4d5fbbd6-81f6-4bef-810c-1e4c9983c261"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3499, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"計算損失\"\"\"\n",
    "loss = mse(preds, targets)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OO2UC4imHokE"
   },
   "outputs": [],
   "source": [
    "\"\"\"對損失函數求導\"\"\"\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 387,
     "status": "ok",
     "timestamp": 1702798316734,
     "user": {
      "displayName": "Henry Hsu",
      "userId": "15979258104560629822"
     },
     "user_tz": 360
    },
    "id": "Ve-cyYCysAey",
    "outputId": "a09ff888-b811-4f83-de87-721bd22daa37"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "del loss / del w =  tensor([[-0.2216]])\n",
      "del loss / del b =  tensor([[-0.5125]])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Gradients for weights (第2輪)\"\"\"\n",
    "print(\"del loss / del w = \",w.grad) # 或 print(w.grad.data)\n",
    "print(\"del loss / del b = \",b.grad) # 或 print(b.grad.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PvKRt1bxHokH"
   },
   "outputs": [],
   "source": [
    "\"\"\"更新 w, b\"\"\"\n",
    "with torch.no_grad():\n",
    "  w -= w.grad * 1e-2\n",
    "  b -= b.grad * 1e-2\n",
    "  w.grad.zero_()\n",
    "  b.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 410,
     "status": "ok",
     "timestamp": 1702798691174,
     "user": {
      "displayName": "Henry Hsu",
      "userId": "15979258104560629822"
     },
     "user_tz": 360
    },
    "id": "WVNdNu8PtY0P",
    "outputId": "b2c8e23c-d4ef-498a-d071-83ef1e1d7437"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0049]], requires_grad=True)\n",
      "tensor([[0.0105]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"(第2輪)顯示w, b更新後的結果\"\"\"\n",
    "print(w)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 496,
     "status": "ok",
     "timestamp": 1702798902473,
     "user": {
      "displayName": "Henry Hsu",
      "userId": "15979258104560629822"
     },
     "user_tz": 360
    },
    "id": "GmN9Ulq5HokJ",
    "outputId": "4cf41994-4412-419c-8e5b-2f60388855f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5129],\n",
      "        [2.3217],\n",
      "        [2.9246]], grad_fn=<AddBackward0>)\n",
      "tensor([[1.4000],\n",
      "        [1.9000],\n",
      "        [3.2000]])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"顯示一下，最新的預測結果，對比真實結果\"\"\"\n",
    "preds = model(inputs)\n",
    "print(preds)  # 預測結果\n",
    "print(targets) # 真實結果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pQ0JvBynvWJa"
   },
   "source": [
    "## run 3 ~ run 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n8VpOB_GvcXF"
   },
   "outputs": [],
   "source": [
    "# continue to train the model (run 998 times)\n",
    "for i in range(998):\n",
    "  preds = model(inputs)\n",
    "  loss = mse(preds, targets)\n",
    "  loss.backward()\n",
    "  with torch.no_grad():\n",
    "    w -= w.grad * 1e-2\n",
    "    b -= b.grad * 1e-2\n",
    "    w.grad.zero_()\n",
    "    b.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 502,
     "status": "ok",
     "timestamp": 1702799562751,
     "user": {
      "displayName": "Henry Hsu",
      "userId": "15979258104560629822"
     },
     "user_tz": 360
    },
    "id": "YR2tbSgQwggR",
    "outputId": "924b32c4-a878-4fb3-9a88-2800d6d471b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slope:\t 0.6497616767883301\n",
      "intercept: 0.9282135367393494\n",
      "loss: 0.14829975366592407\n",
      "tensor([[1.2531],\n",
      "        [2.4227],\n",
      "        [2.8125]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# check the slope, the intercept, the loss value and the predicted values\n",
    "preds = model(inputs)\n",
    "loss = mse(preds, targets)\n",
    "\n",
    "print(\"slope:\\t\",w.item())\n",
    "print(\"intercept:\",b.item())\n",
    "print(\"loss:\",loss.item())\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "km5JfcjSjsHR"
   },
   "source": [
    "錯誤更新 w, b\n",
    "```python\n",
    "w.retain_grad()\n",
    "b.retain_grad()\n",
    "w -= w.grad * 1e-2\n",
    "b -= b.grad * 1e-2\n",
    "\n",
    "with torch.set_grad_enabled(is_train):\n",
    "  w.grad.zero_()\n",
    "```  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gqsMDcF85vkD"
   },
   "source": [
    "# 計算工具(備份)\n",
    "\n",
    "\n",
    "```python\n",
    "def funcb(m, b):\n",
    "  return -2*(1.4 - ( b + m * 0.5)) - 2*(1.9 - ( b + m * 2.3)) - 2*(3.2 - ( b + m * 2.9))\n",
    "\n",
    "def funcm(m, b):\n",
    "  return -2*0.5*(1.4 - ( b + m * 0.5)) - 2*2.3*(1.9 - ( b + m * 2.3)) - 2*2.9*(3.2 - ( b + m * 2.9))\n",
    "\n",
    "funcb(1,0)/3, funcm(1,0)/3\n",
    "print('%.4f' %(funcb(1.0027,0.0053)/3))\n",
    "print('%.4f' %(funcm(1.0027,0.0053)/3))\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9TOOxj3l57o3"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "p8bXZIKAHojy",
    "dS5ClxjzHokB",
    "gqsMDcF85vkD"
   ],
   "provenance": [],
   "toc_visible": true
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}