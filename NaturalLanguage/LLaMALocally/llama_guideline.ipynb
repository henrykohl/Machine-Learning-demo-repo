{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# How to Run LLaMA Locally on CPU or GPU  \n",
        "> ([Youtube Video](https://www.youtube.com/watch?v=SvjWDX2NqiM)) -- Python & Langchain & CTransformers Guide\n",
        "\n",
        "* [`Llama Locally` Project GitHub Repository](https://github.dev/henrykohl/llama-locally)\n",
        "\n",
        "* 此 note 是 `Llama Locally` Project 的 ipynb 版本，以及 llama_cpp_python package 安裝於 Windows 7 時，所遇到的各種問題，與可能解決的方式總結"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65f1j0lxQl0v"
      },
      "source": [
        "# 安裝 llama_cpp_python on Windows 7 -- 整理\n",
        "\n",
        "* 在 VS Code 的 virtual environment 下安裝 `!pip install llama-cpp-python --quiet`\n",
        "> note: This error originates from a subprocess, and is likely not a problem with pip.\n",
        ">\n",
        ">  ERROR: Failed building wheel for llama_cpp_python\n",
        "ERROR: Could not build wheels for llama_cpp_python, which is required to install pyproject.toml-based projects\n",
        "\n",
        "> 嘗試過解決方式(但未能成功)\n",
        "\n",
        "* [針對`llama-cpp-python`安装bug：error: subprocess-exited-](https://blog.csdn.net/qq_38463737/article/details/136477026) -- 下載 `whl` 並進行安裝\n",
        "> 安裝了`MinGW64`後，在VS Code的virtual environment中，成功安裝`llama_cpp_python-0.2.77-cp38-cp38-win_amd64.whl`\n",
        "* [Python：如何安装whl文件?](https://blog.csdn.net/DeniuHe/article/details/77163482)\n",
        "\n",
        "* [llama.cpp部署在windows](https://blog.csdn.net/road_of_god/article/details/133901390)\n",
        "> 下載 `CMake` (cmake-3.28.6-windows-x86_64.msi)\n",
        "\n",
        "* [LLama2 CPU Windows 部署-小白踩坑合集](https://blog.csdn.net/m0_55756688/article/details/132515190)\n",
        "\n",
        "> 在安裝了`whl`檔後把`llama.cpp`複製到工作目錄\n",
        "> > 執行`make`\n",
        "\n",
        "\n",
        "\n",
        "* [安装python包时提示Building windows wheels for Python 3.9 requires Microsoft Visual Studio 2022解决方案](https://blog.csdn.net/HYESC/article/details/130965651)\n",
        "\n",
        "* [Installation on Windows failed because Visual Studio is not installed](https://github.com/abetlen/llama-cpp-python/issues/40)\n",
        "\n",
        "* [LLM Note Day 16 - ggml & llama.cpp](https://ithelp.ithome.com.tw/articles/10331129)\n",
        "\n",
        "* [official `llama-cpp-python` GitHub with Guideline](https://github.com/abetlen/llama-cpp-python) \n",
        "\n",
        "* [official `Llama.cpp` of langchain](https://python.langchain.com/v0.2/docs/integrations/llms/llamacpp/)\n",
        "\n",
        "* [Source code for langchain_community.llms.ctransformers](https://api.python.langchain.com/en/latest/_modules/langchain_community/llms/ctransformers.html)\n",
        "\n",
        "* [C Transformers in LangChain Docs](https://langchain.docsforall.com/docs/integrations/llms/ctransformers) (有參考範例)\n",
        "\n",
        "* [C Transformers in LangChain 0.2](https://python.langchain.com/v0.2/docs/integrations/providers/ctransformers/) (有參考範例)\n",
        "\n",
        "* [Could not load Llama model from path: D:\\privateGPT\\ggml-model-q4_0.bin](https://github.com/zylon-ai/private-gpt/issues/113) (沒什麼用)\n",
        "\n",
        "> <font color=\"red\">總結：在 Windows 7 中，沒有安裝 Visual Studio 2022，幾乎無可能成功安裝 `llama-cpp-python` package"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-o6bttICgWF"
      },
      "source": [
        "# Model Download"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mX0z3W1zx8rO"
      },
      "outputs": [],
      "source": [
        "!wget https://huggingface.co/marella/gpt-2-ggml/resolve/main/ggml-model.bin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "flkx1O7_UFqD"
      },
      "outputs": [],
      "source": [
        "!wget https://huggingface.co/TheBloke/Llama-2-13B-chat-GGML/resolve/main/llama-2-13b-chat.ggmlv3.q5_1.bin --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0T6QFqrolKv"
      },
      "source": [
        "# ctransformers\n",
        "> 參考 C Transformers in LangChain Docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6HMJ8sRlYae-",
        "outputId": "09443bd5-8228-41ca-e515-589767555c91"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install ctransformers==0.2.25 --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-S4MojSjwSI",
        "outputId": "fe8348d2-b9b7-4c86-da47-7aa494e0033b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name: ctransformers\n",
            "Version: 0.2.25\n",
            "Summary: Python bindings for the Transformer models implemented in C/C++ using GGML library.\n",
            "Home-page: https://github.com/marella/ctransformers\n",
            "Author: Ravindra Marella\n",
            "Author-email: mv.ravindra007@gmail.com\n",
            "License: MIT\n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: huggingface-hub, py-cpuinfo\n",
            "Required-by: \n"
          ]
        }
      ],
      "source": [
        "!pip show ctransformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "at4GKJ_2BX5w",
        "outputId": "0fc5d050-699b-4b6d-d294-2f79557131c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m974.0/974.0 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m314.7/314.7 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.9/124.9 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.5/142.5 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install langchain_community --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xOnDsF43Pkwt"
      },
      "outputs": [],
      "source": [
        "from langchain_community.llms import CTransformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "id": "_x-fRGoEizDr",
        "outputId": "03bbfb74-1bae-4ec5-f72e-66de1d5bb174"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>langchain_community.llms.ctransformers.CTransformers</b><br/>def warning_emitting_wrapper(*args: Any, **kwargs: Any) -&gt; Any</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/langchain_community/llms/ctransformers.py</a>C Transformers LLM models.\n",
              "\n",
              "To use, you should have the ``ctransformers`` python package installed.\n",
              "See https://github.com/marella/ctransformers\n",
              "\n",
              "Example:\n",
              "    .. code-block:: python\n",
              "\n",
              "        from langchain_community.llms import CTransformers\n",
              "\n",
              "        llm = CTransformers(model=&quot;/path/to/ggml-gpt-2.bin&quot;, model_type=&quot;gpt2&quot;)</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 12);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ],
            "text/plain": [
              "langchain_community.llms.ctransformers.CTransformers"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "CTransformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ESFhHupVMm1"
      },
      "outputs": [],
      "source": [
        "llm=CTransformers(model=\"./llama-2-7b-chat.ggmlv3.q4_0.bin\",\n",
        "                model_type=\"llama\",\n",
        "                config={'max_new_tokens':512,\n",
        "                        'temperature':0.8})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "llm = CTransformers(model='./ggml-model.bin', model_type='gpt2')\n",
        "\n",
        "print(llm.invoke('AI is going to'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "irF3tdwKph9W"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> 若沒事先下載模型，也可以用`CTransformers()` 直接下載後加載模型"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "57ac9fb3883c4be4a618a7df954ef479",
            "fdc87d1377c1467990412134e6b5857a",
            "3f22f544c3fc4eeeaf167401a074e89a",
            "c208344a68cc440e9217a275c41a9af8",
            "088a70d85e3c4183a165272fdb100efb",
            "d7121651edf5480a8218185437de8000",
            "785ae99bee2742ed8138e6da0419d01d",
            "d7d999032f924d20b2d72f790d1ee936",
            "bc8a3bfe72e74270a2f38a4df34cd993",
            "df3d457259124935b1efc0282a3ed454",
            "cf2724c6c81e496f81d8969656b73ace",
            "ffe0b70e8204420cb321b09f23592c46",
            "3bd73ce2def34176bd483d4f8c856f36",
            "f779f3a4d7944e74ad36cec94ff31597",
            "bdf5b3622da145fba486567d5cac86e1",
            "e6d64e4588b74a96b251c05796dc9ddb",
            "0bfef23eb12740fe9939286b1eeed1ff",
            "4d24922765364842811ae58160066880",
            "6e843993d1f34421a4e541f86310766c",
            "e24124902d64423fbebc56cf82945cee",
            "e8ace3e878f444afb2e73532e084f4e8",
            "a66a4069977b46b0994ee3850c6d7592",
            "cad0b3a0ad0d4929933cef35fa001267",
            "5f336c519bc54ccaaece650ce137eb69",
            "86512b6571cb47b78673520736b362e0",
            "3de8dd258d3a47378f99b4c93274a627",
            "fbdc6d5405264f199c4fe144e72e6762",
            "0719af03e2ca4addba96a73cbbddd118",
            "343f81b5f5ab4a6c9ab23909c0d86fae",
            "9fe197c6b9124677bc6cb174d19d374f",
            "c5617e3e50ae4c6facd54d77fee9ac19",
            "52ad3a7ca46e4ebea3d424796b3f7d6b",
            "73840e4c669543b79ec265c84518aefa",
            "e43f5e3fe88b4c0198ab98c634f22834",
            "160698ffd472439da8262556ccdc53e3",
            "0f0309191ce04a9e8555ad958f9fd5f1",
            "384dd6cf31ae42f8aba28323ede810bf",
            "653c618b76cf4af4ae4d82facb39170e",
            "f926a7b06d354058ba310683f5685cec",
            "5f96f938b0594f75bff30eb133458720",
            "e3ba98b9a98c41b28b7954fa8674da86",
            "d5889ee0edff4376bb085a2d2759ce52",
            "7ed194af4d9d41a0858d77b88c61081a",
            "fe30f264278c451789338634dcc3aa6d"
          ]
        },
        "id": "W89QATKhBnC0",
        "outputId": "9fe924e0-59e1-4216-c6e8-8c37819c8f5b"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "57ac9fb3883c4be4a618a7df954ef479",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ffe0b70e8204420cb321b09f23592c46",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cad0b3a0ad0d4929933cef35fa001267",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e43f5e3fe88b4c0198ab98c634f22834",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "ggml-model.bin:   0%|          | 0.00/251M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "llm = CTransformers(model=\"marella/gpt-2-ggml\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijm7wj9SCfh0",
        "outputId": "dec40103-3e2e-419c-c13d-d7d7cf1c4874"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " get out of here and that's why we're so excited about this.\"\n",
            " (Image: Getty Images)\n"
          ]
        }
      ],
      "source": [
        "print(llm.invoke(\"AI is going to\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tqbQA7OuA6wq"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Bhknplt2Kjg"
      },
      "source": [
        "# llama-cpp-python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64cCnKw19Obi"
      },
      "source": [
        "## GGUF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QCFKK9pD9TPr"
      },
      "outputs": [],
      "source": [
        "# !wget https://huggingface.co/TheBloke/Llama-2-7b-Chat-GGUF/blob/main/llama-2-7b-chat.Q3_K_M.gguf\n",
        "!wget https://huggingface.co/TheBloke/Llama-2-7B-Chat-GGUF/resolve/main/llama-2-7b-chat.Q4_0.gguf --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wv7wppZ9Sd3f"
      },
      "source": [
        "<font color=\"red\">警示：如果安裝最新版的，`LlamaCpp`載入模型時會出錯</font>\n",
        "\n",
        "```python\n",
        "!pip install llama-cpp-python --quiet\n",
        "!pip install langchain --quiet\n",
        "!pip install langchain_community --quiet\n",
        "\n",
        "\"\"\"\n",
        "llama-cpp-python、langchain、langchain_community都安裝最新版\n",
        "--llama-cpp-python > 0.2.x都行 (測試過0.2.10沒問題)(0.1.78--LlamaCpp無法import，0.1.79和0.1.80在import LlamaCpp時，整個Program會crash)\n",
        "import LlamaCpp有兩種方式，from langchain.llms 或 from langchain_community\n",
        "若langchain_community沒有安裝，import LlamaCpp無法成功\n",
        "\n",
        "\"\"\"\n",
        "from langchain.llms import LlamaCpp      # import LlamaCpp方式1\n",
        "from langchain_community.llms import LlamaCpp # import LlamaCpp方式2\n",
        "from langchain import PromptTemplate, LLMChain\n",
        "from langchain.callbacks.manager import CallbackManager\n",
        "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
        "\n",
        "callback_manager = CallbackManager([StreamingStdOutCallbackHandler()])\n",
        "\n",
        "\"\"\"\n",
        "from langchain.llms import LlamaCpp 用 from langchain_community.llms import LlamaCpp不影響import LlamaCpp\n",
        "\"\"\"\n",
        "\n",
        "llm = LlamaCpp(\n",
        "    model_path=\"./llama-2-7b-chat.Q4_0.gguf\",\n",
        "    temperature=0.75,\n",
        "    max_tokens=2000,\n",
        "    top_p=1,\n",
        "    callback_manager=callback_manager,\n",
        "    verbose=True,  # Verbose is required to pass to the callback manager\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NqK71fvalN5G",
        "outputId": "6d8ba3be-6c5e-4f6c-d532-3c589651ea11"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for llama-cpp-python (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install llama-cpp-python --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Kls6Afq2jea",
        "outputId": "e29ea18d-83a8-4daa-d3e8-b2fd27f9c8f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m974.0/974.0 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m314.7/314.7 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.9/124.9 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.7/142.7 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install langchain --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jGUjZOfO3vLi",
        "outputId": "349fc71a-cf34-4523-95a4-08220286d3db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install langchain-community --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vMsJQCQqET9O"
      },
      "outputs": [],
      "source": [
        "from langchain.llms import LlamaCpp         # 方式1\n",
        "# from langchain_community.llms import LlamaCpp    # 方式2\n",
        "from langchain_core.callbacks import CallbackManager, StreamingStdOutCallbackHandler\n",
        "from langchain_core.prompts import PromptTemplate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KiLXDCo3Ei7s"
      },
      "outputs": [],
      "source": [
        "template = \"\"\"Question: {question}\n",
        "\n",
        "Answer: Let's work this out in a step by step way to be sure we have the right answer.\"\"\"\n",
        "\n",
        "prompt = PromptTemplate.from_template(template)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q7uCXVNyEkSF"
      },
      "outputs": [],
      "source": [
        "callback_manager = CallbackManager([StreamingStdOutCallbackHandler()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MtysmUTHEeTW",
        "outputId": "638fd68f-afed-42d0-c7a2-22c5cd22db12"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "llama_model_loader: loaded meta data with 19 key-value pairs and 291 tensors from ./llama-2-7b-chat.Q4_0.gguf (version GGUF V2)\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
            "llama_model_loader: - kv   1:                               general.name str              = LLaMA v2\n",
            "llama_model_loader: - kv   2:                       llama.context_length u32              = 4096\n",
            "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
            "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
            "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 11008\n",
            "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
            "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
            "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 32\n",
            "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000001\n",
            "llama_model_loader: - kv  10:                          general.file_type u32              = 2\n",
            "llama_model_loader: - kv  11:                       tokenizer.ggml.model str              = llama\n",
            "llama_model_loader: - kv  12:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
            "llama_model_loader: - kv  13:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
            "llama_model_loader: - kv  14:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
            "llama_model_loader: - kv  15:                tokenizer.ggml.bos_token_id u32              = 1\n",
            "llama_model_loader: - kv  16:                tokenizer.ggml.eos_token_id u32              = 2\n",
            "llama_model_loader: - kv  17:            tokenizer.ggml.unknown_token_id u32              = 0\n",
            "llama_model_loader: - kv  18:               general.quantization_version u32              = 2\n",
            "llama_model_loader: - type  f32:   65 tensors\n",
            "llama_model_loader: - type q4_0:  225 tensors\n",
            "llama_model_loader: - type q6_K:    1 tensors\n",
            "llm_load_vocab: special tokens cache size = 259\n",
            "llm_load_vocab: token to piece cache size = 0.1684 MB\n",
            "llm_load_print_meta: format           = GGUF V2\n",
            "llm_load_print_meta: arch             = llama\n",
            "llm_load_print_meta: vocab type       = SPM\n",
            "llm_load_print_meta: n_vocab          = 32000\n",
            "llm_load_print_meta: n_merges         = 0\n",
            "llm_load_print_meta: n_ctx_train      = 4096\n",
            "llm_load_print_meta: n_embd           = 4096\n",
            "llm_load_print_meta: n_head           = 32\n",
            "llm_load_print_meta: n_head_kv        = 32\n",
            "llm_load_print_meta: n_layer          = 32\n",
            "llm_load_print_meta: n_rot            = 128\n",
            "llm_load_print_meta: n_embd_head_k    = 128\n",
            "llm_load_print_meta: n_embd_head_v    = 128\n",
            "llm_load_print_meta: n_gqa            = 1\n",
            "llm_load_print_meta: n_embd_k_gqa     = 4096\n",
            "llm_load_print_meta: n_embd_v_gqa     = 4096\n",
            "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
            "llm_load_print_meta: f_norm_rms_eps   = 1.0e-06\n",
            "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
            "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
            "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
            "llm_load_print_meta: n_ff             = 11008\n",
            "llm_load_print_meta: n_expert         = 0\n",
            "llm_load_print_meta: n_expert_used    = 0\n",
            "llm_load_print_meta: causal attn      = 1\n",
            "llm_load_print_meta: pooling type     = 0\n",
            "llm_load_print_meta: rope type        = 0\n",
            "llm_load_print_meta: rope scaling     = linear\n",
            "llm_load_print_meta: freq_base_train  = 10000.0\n",
            "llm_load_print_meta: freq_scale_train = 1\n",
            "llm_load_print_meta: n_yarn_orig_ctx  = 4096\n",
            "llm_load_print_meta: rope_finetuned   = unknown\n",
            "llm_load_print_meta: ssm_d_conv       = 0\n",
            "llm_load_print_meta: ssm_d_inner      = 0\n",
            "llm_load_print_meta: ssm_d_state      = 0\n",
            "llm_load_print_meta: ssm_dt_rank      = 0\n",
            "llm_load_print_meta: model type       = 7B\n",
            "llm_load_print_meta: model ftype      = Q4_0\n",
            "llm_load_print_meta: model params     = 6.74 B\n",
            "llm_load_print_meta: model size       = 3.56 GiB (4.54 BPW) \n",
            "llm_load_print_meta: general.name     = LLaMA v2\n",
            "llm_load_print_meta: BOS token        = 1 '<s>'\n",
            "llm_load_print_meta: EOS token        = 2 '</s>'\n",
            "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
            "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
            "llm_load_tensors: ggml ctx size =    0.15 MiB\n",
            "llm_load_tensors:        CPU buffer size =  3647.87 MiB\n",
            "..................................................................................................\n",
            "llama_new_context_with_model: n_batch is less than GGML_KQ_MASK_PAD - increasing to 32\n",
            "llama_new_context_with_model: n_ctx      = 512\n",
            "llama_new_context_with_model: n_batch    = 32\n",
            "llama_new_context_with_model: n_ubatch   = 32\n",
            "llama_new_context_with_model: flash_attn = 0\n",
            "llama_new_context_with_model: freq_base  = 10000.0\n",
            "llama_new_context_with_model: freq_scale = 1\n",
            "llama_kv_cache_init:        CPU KV buffer size =   256.00 MiB\n",
            "llama_new_context_with_model: KV self size  =  256.00 MiB, K (f16):  128.00 MiB, V (f16):  128.00 MiB\n",
            "llama_new_context_with_model:        CPU  output buffer size =     0.12 MiB\n",
            "llama_new_context_with_model:        CPU compute buffer size =     4.41 MiB\n",
            "llama_new_context_with_model: graph nodes  = 1030\n",
            "llama_new_context_with_model: graph splits = 1\n",
            "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | AVX512_BF16 = 0 | FMA = 1 | NEON = 0 | SVE = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 1 | \n",
            "Model metadata: {'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.eos_token_id': '2', 'general.architecture': 'llama', 'llama.context_length': '4096', 'general.name': 'LLaMA v2', 'llama.embedding_length': '4096', 'llama.feed_forward_length': '11008', 'llama.attention.layer_norm_rms_epsilon': '0.000001', 'llama.rope.dimension_count': '128', 'llama.attention.head_count': '32', 'tokenizer.ggml.bos_token_id': '1', 'llama.block_count': '32', 'llama.attention.head_count_kv': '32', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'llama', 'general.file_type': '2'}\n",
            "Using fallback chat format: llama-2\n"
          ]
        }
      ],
      "source": [
        "llm = LlamaCpp(\n",
        "    model_path=\"./llama-2-7b-chat.Q4_0.gguf\",\n",
        "    temperature=0.75,\n",
        "    max_tokens=2000,\n",
        "    top_p=1,\n",
        "    callback_manager=callback_manager,\n",
        "    verbose=True,  # Verbose is required to pass to the callback manager\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "id": "aFWm7fNPGtgo",
        "outputId": "8e2ebdc3-22db-4b5e-a63b-978a141264af"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Answer: The largest country on Earth is Russia, which covers an area of approximately 17.1 million square kilometers (6.6 million square miles)."
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "llama_print_timings:        load time =    4414.19 ms\n",
            "llama_print_timings:      sample time =      20.87 ms /    35 runs   (    0.60 ms per token,  1677.37 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5229.83 ms /     8 tokens (  653.73 ms per token,     1.53 tokens per second)\n",
            "llama_print_timings:        eval time =   28767.40 ms /    35 runs   (  821.93 ms per token,     1.22 tokens per second)\n",
            "llama_print_timings:       total time =   34136.39 ms /    43 tokens\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nAnswer: The largest country on Earth is Russia, which covers an area of approximately 17.1 million square kilometers (6.6 million square miles).'"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# question = \"\"\"\n",
        "# Question: A rap battle between Stephen Colbert and John Oliver\n",
        "# \"\"\"\n",
        "question: str = \"\"\"\n",
        "Question: What is the largest country on Earth?\n",
        "\"\"\"\n",
        "llm.invoke(question)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJ9vts9OnBzx"
      },
      "source": [
        "## GGML"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMxCsW89W0-X"
      },
      "source": [
        "<font color=\"red\">警示：如果安裝最新版的，`LlamaCpp`載入模型時會出錯</font>\n",
        "\n",
        "```python\n",
        "!pip install llama-cpp-python --quiet\n",
        "!pip install langchain --quiet\n",
        "!pip install langchain_community --quiet\n",
        "\n",
        "from langchain.llms import LlamaCpp\n",
        "from langchain import PromptTemplate, LLMChain\n",
        "from langchain.callbacks.manager import CallbackManager\n",
        "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
        "\n",
        "callback_manager = CallbackManager([StreamingStdOutCallbackHandler()])\n",
        "\n",
        "\"\"\"\n",
        "from langchain.llms import LlamaCpp 用 from langchain_community.llms import LlamaCpp不影響import LlamaCpp\n",
        "\"\"\"\n",
        "\n",
        "Llama_model = LlamaCpp(\n",
        "    model_path=\"./llama-2-7b-chat.ggmlv3.q4_0.bin\",\n",
        "    callback_manager=callback_manager,\n",
        "    n_threads=2\n",
        ")\n",
        "\n",
        "```\n",
        "<font color=\"red\">`LlamaCpp`載入模型時出現的錯誤訊息--</font>\n",
        "```message\n",
        "ValidationError: 1 validation error for LlamaCpp\n",
        "__root__\n",
        "  Could not load Llama model from path: ./llama-2-7b-chat.ggmlv3.q4_0.bin. Received error Failed to load model from file: ./llama-2-7b-chat.ggmlv3.q4_0.bin (type=value_error)\n",
        "```\n",
        "\n",
        "\n",
        "* `llama-cpp-python` 安裝最新版，若沒有安裝`langchain_community`，則`LlamaCpp`無法import\n",
        "* 安裝舊些版本(測試過0.2.56和0.1.80)不需要`langchain_community`，但`LlamaCpp`依然無法import\n",
        "* 必需要安裝 <= 0.1.78 版本，才能成功`import LlamaCpp`(不需要langchain_community)\n",
        "* 安裝不同的版本時，最好是`中斷連線並刪除執行階段`再`重新連線`執行，（`重新起動工作階段`有時不一定後續能正常執行），否則既使llama-cpp-python安裝了正確版本，import LlamaCpp依然無法成功\n",
        "* langchain版本不影響import LlamaCpp成功與否（也測試了0.0.314/0.0225版本），而且安裝舊版langchain，可以不需要安裝langchain_community，只是安裝舊版，可能會出現pip's dependency resolver相關的ERROR提示\n",
        "* `import LlamaCpp`可以是`from langchin.llms`或是`from langchain_community`\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "N_ljP0vip9h8"
      },
      "outputs": [],
      "source": [
        "!wget https://huggingface.co/TheBloke/Llama-2-7B-Chat-GGML/resolve/main/llama-2-7b-chat.ggmlv3.q4_0.bin --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QeSuaVwnf9d5",
        "outputId": "e7282eaa-ca64-42a3-8248-09716ea90e96"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.7 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.2/1.7 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for llama-cpp-python (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install llama-cpp-python==0.1.78 --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G0uDtJElXdG_",
        "outputId": "df54cbfc-0b65-4a60-b439-08ea88fe2b30"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m974.0/974.0 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m314.7/314.7 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.2/125.2 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.7/142.7 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# --force-reinstall --upgrade --no-cache-dir --quiet\n",
        "!pip install langchain --quiet # (langchain==0.0.314) 沒問題"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ScjAyqYQuPr",
        "outputId": "2685a314-148d-480d-d287-670923e25567"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install U langchain_community --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "bxAjP2-FIMHD"
      },
      "outputs": [],
      "source": [
        "from langchain_community.llms import LlamaCpp\n",
        "from langchain import PromptTemplate, LLMChain\n",
        "from langchain.callbacks.manager import CallbackManager\n",
        "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "T6PrjRTukg3t"
      },
      "outputs": [],
      "source": [
        "callback_manager = CallbackManager([StreamingStdOutCallbackHandler()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0LTbfXmBNw7T",
        "outputId": "65cdb9b4-ac83-4019-bbf8-849386f96edf"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "AVX = 1 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | VSX = 0 | \n"
          ]
        }
      ],
      "source": [
        "# Llama_model: LlamaCpp = LlamaCpp(\n",
        "#         model_path=\"./llama-2-7b-chat.ggmlv3.q4_0.bin\",\n",
        "#         temperature=0.5,\n",
        "#         max_tokens=2000,\n",
        "#         top_p=1,\n",
        "#         callback_manager = callback_manager,\n",
        "#         verbose=True\n",
        "#     )\n",
        "\n",
        "Llama_model = LlamaCpp(\n",
        "    # model_path=\"./llama-2-7b-chat.Q4_0.gguf\",\n",
        "    model_path=\"./llama-2-7b-chat.ggmlv3.q4_0.bin\",\n",
        "    callback_manager=callback_manager,\n",
        "\n",
        "    n_threads=2\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S7rdN1uXNsST"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> ggml模型加載錯誤時的訊息範例"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1QwAOz_R5Ecx"
      },
      "outputs": [],
      "source": [
        "MODEL_PATH = \"./llama-2-7b-chat.ggmlv3.q4_0.bin\"\n",
        "\n",
        "def load_model() -> LlamaCpp:\n",
        "    \"\"\"Loads Llama model\"\"\"\n",
        "    callback_manager: CallbackManager = CallbackManager([StreamingStdOutCallbackHandler()])\n",
        "\n",
        "    Llama_model: LlamaCpp = LlamaCpp(\n",
        "        model_path=MODEL_PATH,\n",
        "        temperature=0.5,\n",
        "        max_tokens=2000,\n",
        "        top_p=1,\n",
        "        callback_manager = callback_manager,\n",
        "        verbose=True\n",
        "    )\n",
        "\n",
        "    return Llama_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "id": "dLHnOiY75O1o",
        "outputId": "d64961fd-88e9-4be4-aaba-da441fd27415"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "llama_model_load: error loading model: llama_model_loader: failed to load model from ./llama-2-7b-chat.ggmlv3.q4_0.bin\n",
            "\n",
            "llama_load_model_from_file: failed to load model\n"
          ]
        },
        {
          "ename": "ValidationError",
          "evalue": "1 validation error for LlamaCpp\n__root__\n  Could not load Llama model from path: ./llama-2-7b-chat.ggmlv3.q4_0.bin. Received error Failed to load model from file: ./llama-2-7b-chat.ggmlv3.q4_0.bin (type=value_error)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-04e7c95506f2>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mllm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-5-46a81c7ea74b>\u001b[0m in \u001b[0;36mload_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mcallback_manager\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mCallbackManager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCallbackManager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mStreamingStdOutCallbackHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     Llama_model: LlamaCpp = LlamaCpp(\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mmodel_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMODEL_PATH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/load/serializable.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lc_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pydantic/main.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mpydantic.main.BaseModel.__init__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mValidationError\u001b[0m: 1 validation error for LlamaCpp\n__root__\n  Could not load Llama model from path: ./llama-2-7b-chat.ggmlv3.q4_0.bin. Received error Failed to load model from file: ./llama-2-7b-chat.ggmlv3.q4_0.bin (type=value_error)"
          ]
        }
      ],
      "source": [
        "llm = load_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j67LMVT7o2R9"
      },
      "source": [
        "# <font color=\"red\">LLM_Inference_with_llama_cpp_python</font> [resource](https://colab.research.google.com/github/R3gm/InsightSolver-Colab/blob/main/LLM_Inference_with_llama_cpp_python__Llama_2_13b_chat.ipynb#scrollTo=ihaZyg2aYQpH)\n",
        "> <font color=\"red\">llama_cpp.llama.**Llama** and langchain.llms.**LlamaCpp**</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2KjoOLL34IkO"
      },
      "source": [
        "## <font color=\"red\">Step 1 -- 安裝 llama-cpp-python\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2l3jIYP8665k",
        "outputId": "d50256de-b38e-411c-c57f-374ea147df38"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for llama-cpp-python (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install llama-cpp-python==0.1.78 --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cguFAjpx4Uvf"
      },
      "source": [
        "## <font color=\"red\">Step 2 -- 下載 Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MC5N0zLY4z2p"
      },
      "source": [
        "* ### <font color=\"#FF474C\">方式1\n",
        "> 使用 `huggingface_hub.file_download.hf_hub_download`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zsBEAcCf7EUL"
      },
      "outputs": [],
      "source": [
        "!pip install huggingface_hub --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OzvG0kiN7Yus"
      },
      "outputs": [],
      "source": [
        "# 13B-q5_1\n",
        "model_name_or_path = \"TheBloke/Llama-2-13B-chat-GGML\"\n",
        "model_basename = \"llama-2-13b-chat.ggmlv3.q5_1.bin\" # the model is in bin format\n",
        "# 7B-q4_0\n",
        "# model_name_or_path = \"TheBloke/Llama-2-7B-Chat-GGML\"\n",
        "# model_basename = \"llama-2-7b-chat.ggmlv3.q4_0.bin\" # the model is in bin format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        },
        "id": "2afVeSne4q-U",
        "outputId": "a01899d9-ff7d-4799-eb36-e123a152f906"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>huggingface_hub.file_download.hf_hub_download</b><br/>def hf_hub_download(repo_id: str, filename: str, *, subfolder: Optional[str]=None, repo_type: Optional[str]=None, revision: Optional[str]=None, library_name: Optional[str]=None, library_version: Optional[str]=None, cache_dir: Union[str, Path, None]=None, local_dir: Union[str, Path, None]=None, user_agent: Union[Dict, str, None]=None, force_download: bool=False, proxies: Optional[Dict]=None, etag_timeout: float=DEFAULT_ETAG_TIMEOUT, token: Union[bool, str, None]=None, local_files_only: bool=False, headers: Optional[Dict[str, str]]=None, endpoint: Optional[str]=None, legacy_cache_layout: bool=False, resume_download: Optional[bool]=None, force_filename: Optional[str]=None, local_dir_use_symlinks: Union[bool, Literal[&#x27;auto&#x27;]]=&#x27;auto&#x27;) -&gt; str</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py</a>Download a given file if it&#x27;s not already present in the local cache.\n",
              "\n",
              "The new cache file layout looks like this:\n",
              "- The cache directory contains one subfolder per repo_id (namespaced by repo type)\n",
              "- inside each repo folder:\n",
              "    - refs is a list of the latest known revision =&gt; commit_hash pairs\n",
              "    - blobs contains the actual file blobs (identified by their git-sha or sha256, depending on\n",
              "      whether they&#x27;re LFS files or not)\n",
              "    - snapshots contains one subfolder per commit, each &quot;commit&quot; contains the subset of the files\n",
              "      that have been resolved at that particular commit. Each filename is a symlink to the blob\n",
              "      at that particular commit.\n",
              "\n",
              "```\n",
              "[  96]  .\n",
              "└── [ 160]  models--julien-c--EsperBERTo-small\n",
              "    ├── [ 160]  blobs\n",
              "    │   ├── [321M]  403450e234d65943a7dcf7e05a771ce3c92faa84dd07db4ac20f592037a1e4bd\n",
              "    │   ├── [ 398]  7cb18dc9bafbfcf74629a4b760af1b160957a83e\n",
              "    │   └── [1.4K]  d7edf6bd2a681fb0175f7735299831ee1b22b812\n",
              "    ├── [  96]  refs\n",
              "    │   └── [  40]  main\n",
              "    └── [ 128]  snapshots\n",
              "        ├── [ 128]  2439f60ef33a0d46d85da5001d52aeda5b00ce9f\n",
              "        │   ├── [  52]  README.md -&gt; ../../blobs/d7edf6bd2a681fb0175f7735299831ee1b22b812\n",
              "        │   └── [  76]  pytorch_model.bin -&gt; ../../blobs/403450e234d65943a7dcf7e05a771ce3c92faa84dd07db4ac20f592037a1e4bd\n",
              "        └── [ 128]  bbc77c8132af1cc5cf678da3f1ddf2de43606d48\n",
              "            ├── [  52]  README.md -&gt; ../../blobs/7cb18dc9bafbfcf74629a4b760af1b160957a83e\n",
              "            └── [  76]  pytorch_model.bin -&gt; ../../blobs/403450e234d65943a7dcf7e05a771ce3c92faa84dd07db4ac20f592037a1e4bd\n",
              "```\n",
              "\n",
              "If `local_dir` is provided, the file structure from the repo will be replicated in this location. When using this\n",
              "option, the `cache_dir` will not be used and a `.huggingface/` folder will be created at the root of `local_dir`\n",
              "to store some metadata related to the downloaded files. While this mechanism is not as robust as the main\n",
              "cache-system, it&#x27;s optimized for regularly pulling the latest version of a repository.\n",
              "\n",
              "Args:\n",
              "    repo_id (`str`):\n",
              "        A user or an organization name and a repo name separated by a `/`.\n",
              "    filename (`str`):\n",
              "        The name of the file in the repo.\n",
              "    subfolder (`str`, *optional*):\n",
              "        An optional value corresponding to a folder inside the model repo.\n",
              "    repo_type (`str`, *optional*):\n",
              "        Set to `&quot;dataset&quot;` or `&quot;space&quot;` if downloading from a dataset or space,\n",
              "        `None` or `&quot;model&quot;` if downloading from a model. Default is `None`.\n",
              "    revision (`str`, *optional*):\n",
              "        An optional Git revision id which can be a branch name, a tag, or a\n",
              "        commit hash.\n",
              "    library_name (`str`, *optional*):\n",
              "        The name of the library to which the object corresponds.\n",
              "    library_version (`str`, *optional*):\n",
              "        The version of the library.\n",
              "    cache_dir (`str`, `Path`, *optional*):\n",
              "        Path to the folder where cached files are stored.\n",
              "    local_dir (`str` or `Path`, *optional*):\n",
              "        If provided, the downloaded file will be placed under this directory.\n",
              "    user_agent (`dict`, `str`, *optional*):\n",
              "        The user-agent info in the form of a dictionary or a string.\n",
              "    force_download (`bool`, *optional*, defaults to `False`):\n",
              "        Whether the file should be downloaded even if it already exists in\n",
              "        the local cache.\n",
              "    proxies (`dict`, *optional*):\n",
              "        Dictionary mapping protocol to the URL of the proxy passed to\n",
              "        `requests.request`.\n",
              "    etag_timeout (`float`, *optional*, defaults to `10`):\n",
              "        When fetching ETag, how many seconds to wait for the server to send\n",
              "        data before giving up which is passed to `requests.request`.\n",
              "    token (`str`, `bool`, *optional*):\n",
              "        A token to be used for the download.\n",
              "            - If `True`, the token is read from the HuggingFace config\n",
              "              folder.\n",
              "            - If a string, it&#x27;s used as the authentication token.\n",
              "    local_files_only (`bool`, *optional*, defaults to `False`):\n",
              "        If `True`, avoid downloading the file and return the path to the\n",
              "        local cached file if it exists.\n",
              "    headers (`dict`, *optional*):\n",
              "        Additional headers to be sent with the request.\n",
              "    legacy_cache_layout (`bool`, *optional*, defaults to `False`):\n",
              "        If `True`, uses the legacy file cache layout i.e. just call [`hf_hub_url`]\n",
              "        then `cached_download`. This is deprecated as the new cache layout is\n",
              "        more powerful.\n",
              "\n",
              "Returns:\n",
              "    `str`: Local path of file or if networking is off, last version of file cached on disk.\n",
              "\n",
              "Raises:\n",
              "    - [`EnvironmentError`](https://docs.python.org/3/library/exceptions.html#EnvironmentError)\n",
              "    if `token=True` and the token cannot be found.\n",
              "    - [`OSError`](https://docs.python.org/3/library/exceptions.html#OSError)\n",
              "    if ETag cannot be determined.\n",
              "    - [`ValueError`](https://docs.python.org/3/library/exceptions.html#ValueError)\n",
              "    if some parameter value is invalid\n",
              "    - [`~utils.RepositoryNotFoundError`]\n",
              "    If the repository to download from cannot be found. This may be because it doesn&#x27;t exist,\n",
              "    or because it is set to `private` and you do not have access.\n",
              "    - [`~utils.RevisionNotFoundError`]\n",
              "    If the revision to download from cannot be found.\n",
              "    - [`~utils.EntryNotFoundError`]\n",
              "    If the file to download cannot be found.\n",
              "    - [`~utils.LocalEntryNotFoundError`]\n",
              "    If network is disabled or unavailable and file is not found in cache.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 992);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ],
            "text/plain": [
              "<function huggingface_hub.file_download.hf_hub_download(repo_id: str, filename: str, *, subfolder: Optional[str] = None, repo_type: Optional[str] = None, revision: Optional[str] = None, library_name: Optional[str] = None, library_version: Optional[str] = None, cache_dir: Union[str, pathlib.Path, NoneType] = None, local_dir: Union[str, pathlib.Path, NoneType] = None, user_agent: Union[Dict, str, NoneType] = None, force_download: bool = False, proxies: Optional[Dict] = None, etag_timeout: float = 10, token: Union[bool, str, NoneType] = None, local_files_only: bool = False, headers: Optional[Dict[str, str]] = None, endpoint: Optional[str] = None, legacy_cache_layout: bool = False, resume_download: Optional[bool] = None, force_filename: Optional[str] = None, local_dir_use_symlinks: Union[bool, Literal['auto']] = 'auto') -> str>"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## 顯示\n",
        "# hf_hub_download"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "81837a0a735642f1a01a07b97182cd28",
            "4205ffe079b245c5957387613ddbd82b",
            "167e3c70d478475a866817424867dfa2",
            "7fff050cc7df4331be681b9449828f07",
            "efde04fe359e41e4b7e1272fe1b7f11e",
            "79e1cb33de55491e9be0e852ee0faded",
            "499ee69c5806499d85497e22c23cacb9",
            "d6cee11578464c808835ff4ed615c279",
            "21722195880444939020875c65fda921",
            "e564d75800984a0c89cb439055837375",
            "9ea7e82419b246689fd3918555f83c0d"
          ]
        },
        "id": "KNO9wW-57fgv",
        "outputId": "3b4fdded-9b01-4780-dea8-658fa1232726"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "81837a0a735642f1a01a07b97182cd28",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "llama-2-13b-chat.ggmlv3.q5_1.bin:   0%|          | 0.00/9.76G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from huggingface_hub import hf_hub_download\n",
        "\n",
        "model_path = hf_hub_download(repo_id=model_name_or_path, filename=model_basename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "3CGxu91O7jSD",
        "outputId": "24bab46a-1c84-4364-e384-bf5e427a26c2"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/root/.cache/huggingface/hub/models--TheBloke--Llama-2-13B-chat-GGML/snapshots/3140827b4dfcb6b562cd87ee3d7f07109b014dd0/llama-2-13b-chat.ggmlv3.q5_1.bin'"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 顯示用\n",
        "model_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "MDrD5-JpPMn6",
        "outputId": "7e190bed-25d0-4b11-a51f-27e20b888674"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/llama-2-13b-chat.ggmlv3.q5_1.bin'"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 補充 把下載到 cache的檔放，複製到default工作目錄下(./content or /content)\n",
        "import shutil\n",
        "shutil.copy2(model_path, '/content')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CVR3COsh4-jN"
      },
      "source": [
        "* ### <font color=\"#FF474C\">方式2\n",
        "> 使用 `wget` 下載"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rVdKQPQvXU06"
      },
      "outputs": [],
      "source": [
        "# 13B-q5_1\n",
        "!wget https://huggingface.co/TheBloke/Llama-2-13B-chat-GGML/resolve/main/llama-2-13b-chat.ggmlv3.q5_1.bin --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Opb6shr-57D3"
      },
      "outputs": [],
      "source": [
        "# 7B-q4_0\n",
        "!wget https://huggingface.co/TheBloke/Llama-2-7B-Chat-GGML/resolve/main/llama-2-7b-chat.ggmlv3.q4_0.bin --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qHyWFsdK551P"
      },
      "source": [
        "## <font color=\"red\">Step 3： Model Loading"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Jdz7fB7dxlX"
      },
      "source": [
        "* ### <font color=\"#FF474C\">方法1：使用 Llama"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rZEXixMb8RDx",
        "outputId": "60807b3c-323c-4371-b081-f9139b946077"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "AVX = 1 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | VSX = 0 | \n"
          ]
        }
      ],
      "source": [
        "from llama_cpp import Llama\n",
        "\n",
        "lcpp_llm = Llama(\n",
        "    # model_path=model_path,\n",
        "    # model_path=\"/content/llama-2-13b-chat.ggmlv3.q5_1.bin\",\n",
        "    model_path=\"/content/llama-2-7b-chat.ggmlv3.q4_0.bin\",\n",
        "    n_threads=2, # CPU cores\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D9whFLZfAI6l"
      },
      "outputs": [],
      "source": [
        "# n_path = \"/content/llama-2-13b-chat.ggmlv3.q5_1.bin\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9K4sbK_Gb6Di"
      },
      "source": [
        "* ### <font color=\"#FF474C\">方法2：使用 LlamaCpp of LangChain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YTvpr5dqqSEL",
        "outputId": "3ca82511-d629-42a6-c8fd-e0af0afed022"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m974.0/974.0 kB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m314.7/314.7 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.9/124.9 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.5/142.5 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install langchain_community --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gicHQHi1qbNg"
      },
      "outputs": [],
      "source": [
        "from langchain.llms import LlamaCpp\n",
        "from langchain import PromptTemplate, LLMChain\n",
        "from langchain.callbacks.manager import CallbackManager\n",
        "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c_JYygb2qgbv"
      },
      "outputs": [],
      "source": [
        "callback_manager = CallbackManager([StreamingStdOutCallbackHandler()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lRI8pcFigQkW",
        "outputId": "e25dd2a8-610d-408f-9dc9-1f2e2dac66da"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "AVX = 1 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | VSX = 0 | \n"
          ]
        }
      ],
      "source": [
        "## CPU\n",
        "Llama_model = LlamaCpp(\n",
        "    # model_path=\"./llama-2-7b-chat.Q4_0.gguf\",\n",
        "    model_path=\"/content/llama-2-7b-chat.ggmlv3.q4_0.bin\",\n",
        "    callback_manager=callback_manager,\n",
        "    n_threads=2,\n",
        "    verbose=True,\n",
        "    stop = ['USER:'], # Dynamic stopping when such token is detected.\n",
        "    temperature = 0.4,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "puM27yND8xPq",
        "outputId": "097cd93b-88ef-4230-81fb-1e65bcd99a05"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "AVX = 1 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | VSX = 0 | \n"
          ]
        }
      ],
      "source": [
        "## GPU\n",
        "n_gpu_layers = 40  # Change this value based on your model and your GPU VRAM pool.\n",
        "n_batch = 512  # Should be between 1 and n_ctx, consider the amount of VRAM in your GPU.\n",
        "\n",
        "# Loading model,\n",
        "llm = LlamaCpp(\n",
        "    model_path=\"/content/llama-2-7b-chat.ggmlv3.q4_0.bin\",\n",
        "    max_tokens=1024,\n",
        "    n_gpu_layers=n_gpu_layers,\n",
        "    n_batch=n_batch,\n",
        "    callback_manager=callback_manager,\n",
        "    verbose=True,\n",
        "    n_ctx=4096, # Context window\n",
        "    stop = ['USER:'], # Dynamic stopping when such token is detected.\n",
        "    temperature = 0.4,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E_RD5UN99OJ4"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "L0T6QFqrolKv",
        "64cCnKw19Obi",
        "cguFAjpx4Uvf",
        "MC5N0zLY4z2p",
        "CVR3COsh4-jN"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0719af03e2ca4addba96a73cbbddd118": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "088a70d85e3c4183a165272fdb100efb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0bfef23eb12740fe9939286b1eeed1ff": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f0309191ce04a9e8555ad958f9fd5f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e3ba98b9a98c41b28b7954fa8674da86",
            "max": 251222425,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d5889ee0edff4376bb085a2d2759ce52",
            "value": 251222425
          }
        },
        "160698ffd472439da8262556ccdc53e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f926a7b06d354058ba310683f5685cec",
            "placeholder": "​",
            "style": "IPY_MODEL_5f96f938b0594f75bff30eb133458720",
            "value": "ggml-model.bin: 100%"
          }
        },
        "167e3c70d478475a866817424867dfa2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d6cee11578464c808835ff4ed615c279",
            "max": 9763701888,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_21722195880444939020875c65fda921",
            "value": 9763701888
          }
        },
        "21722195880444939020875c65fda921": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "343f81b5f5ab4a6c9ab23909c0d86fae": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "384dd6cf31ae42f8aba28323ede810bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ed194af4d9d41a0858d77b88c61081a",
            "placeholder": "​",
            "style": "IPY_MODEL_fe30f264278c451789338634dcc3aa6d",
            "value": " 251M/251M [00:07&lt;00:00, 43.0MB/s]"
          }
        },
        "3bd73ce2def34176bd483d4f8c856f36": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0bfef23eb12740fe9939286b1eeed1ff",
            "placeholder": "​",
            "style": "IPY_MODEL_4d24922765364842811ae58160066880",
            "value": "config.json: 100%"
          }
        },
        "3de8dd258d3a47378f99b4c93274a627": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_52ad3a7ca46e4ebea3d424796b3f7d6b",
            "placeholder": "​",
            "style": "IPY_MODEL_73840e4c669543b79ec265c84518aefa",
            "value": " 1/1 [00:07&lt;00:00,  7.87s/it]"
          }
        },
        "3f22f544c3fc4eeeaf167401a074e89a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d7d999032f924d20b2d72f790d1ee936",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bc8a3bfe72e74270a2f38a4df34cd993",
            "value": 1
          }
        },
        "4205ffe079b245c5957387613ddbd82b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_79e1cb33de55491e9be0e852ee0faded",
            "placeholder": "​",
            "style": "IPY_MODEL_499ee69c5806499d85497e22c23cacb9",
            "value": "llama-2-13b-chat.ggmlv3.q5_1.bin: 100%"
          }
        },
        "499ee69c5806499d85497e22c23cacb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4d24922765364842811ae58160066880": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "52ad3a7ca46e4ebea3d424796b3f7d6b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57ac9fb3883c4be4a618a7df954ef479": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fdc87d1377c1467990412134e6b5857a",
              "IPY_MODEL_3f22f544c3fc4eeeaf167401a074e89a",
              "IPY_MODEL_c208344a68cc440e9217a275c41a9af8"
            ],
            "layout": "IPY_MODEL_088a70d85e3c4183a165272fdb100efb"
          }
        },
        "5f336c519bc54ccaaece650ce137eb69": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0719af03e2ca4addba96a73cbbddd118",
            "placeholder": "​",
            "style": "IPY_MODEL_343f81b5f5ab4a6c9ab23909c0d86fae",
            "value": "Fetching 1 files: 100%"
          }
        },
        "5f96f938b0594f75bff30eb133458720": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "653c618b76cf4af4ae4d82facb39170e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e843993d1f34421a4e541f86310766c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73840e4c669543b79ec265c84518aefa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "785ae99bee2742ed8138e6da0419d01d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "79e1cb33de55491e9be0e852ee0faded": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ed194af4d9d41a0858d77b88c61081a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7fff050cc7df4331be681b9449828f07": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e564d75800984a0c89cb439055837375",
            "placeholder": "​",
            "style": "IPY_MODEL_9ea7e82419b246689fd3918555f83c0d",
            "value": " 9.76G/9.76G [01:14&lt;00:00, 161MB/s]"
          }
        },
        "81837a0a735642f1a01a07b97182cd28": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4205ffe079b245c5957387613ddbd82b",
              "IPY_MODEL_167e3c70d478475a866817424867dfa2",
              "IPY_MODEL_7fff050cc7df4331be681b9449828f07"
            ],
            "layout": "IPY_MODEL_efde04fe359e41e4b7e1272fe1b7f11e"
          }
        },
        "86512b6571cb47b78673520736b362e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9fe197c6b9124677bc6cb174d19d374f",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c5617e3e50ae4c6facd54d77fee9ac19",
            "value": 1
          }
        },
        "9ea7e82419b246689fd3918555f83c0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9fe197c6b9124677bc6cb174d19d374f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a66a4069977b46b0994ee3850c6d7592": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bc8a3bfe72e74270a2f38a4df34cd993": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bdf5b3622da145fba486567d5cac86e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e8ace3e878f444afb2e73532e084f4e8",
            "placeholder": "​",
            "style": "IPY_MODEL_a66a4069977b46b0994ee3850c6d7592",
            "value": " 26.0/26.0 [00:00&lt;00:00, 732B/s]"
          }
        },
        "c208344a68cc440e9217a275c41a9af8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_df3d457259124935b1efc0282a3ed454",
            "placeholder": "​",
            "style": "IPY_MODEL_cf2724c6c81e496f81d8969656b73ace",
            "value": " 1/1 [00:00&lt;00:00,  2.64it/s]"
          }
        },
        "c5617e3e50ae4c6facd54d77fee9ac19": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cad0b3a0ad0d4929933cef35fa001267": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5f336c519bc54ccaaece650ce137eb69",
              "IPY_MODEL_86512b6571cb47b78673520736b362e0",
              "IPY_MODEL_3de8dd258d3a47378f99b4c93274a627"
            ],
            "layout": "IPY_MODEL_fbdc6d5405264f199c4fe144e72e6762"
          }
        },
        "cf2724c6c81e496f81d8969656b73ace": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d5889ee0edff4376bb085a2d2759ce52": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d6cee11578464c808835ff4ed615c279": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7121651edf5480a8218185437de8000": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7d999032f924d20b2d72f790d1ee936": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df3d457259124935b1efc0282a3ed454": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e24124902d64423fbebc56cf82945cee": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e3ba98b9a98c41b28b7954fa8674da86": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e43f5e3fe88b4c0198ab98c634f22834": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_160698ffd472439da8262556ccdc53e3",
              "IPY_MODEL_0f0309191ce04a9e8555ad958f9fd5f1",
              "IPY_MODEL_384dd6cf31ae42f8aba28323ede810bf"
            ],
            "layout": "IPY_MODEL_653c618b76cf4af4ae4d82facb39170e"
          }
        },
        "e564d75800984a0c89cb439055837375": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6d64e4588b74a96b251c05796dc9ddb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8ace3e878f444afb2e73532e084f4e8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "efde04fe359e41e4b7e1272fe1b7f11e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f779f3a4d7944e74ad36cec94ff31597": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6e843993d1f34421a4e541f86310766c",
            "max": 26,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e24124902d64423fbebc56cf82945cee",
            "value": 26
          }
        },
        "f926a7b06d354058ba310683f5685cec": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fbdc6d5405264f199c4fe144e72e6762": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fdc87d1377c1467990412134e6b5857a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d7121651edf5480a8218185437de8000",
            "placeholder": "​",
            "style": "IPY_MODEL_785ae99bee2742ed8138e6da0419d01d",
            "value": "Fetching 1 files: 100%"
          }
        },
        "fe30f264278c451789338634dcc3aa6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ffe0b70e8204420cb321b09f23592c46": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3bd73ce2def34176bd483d4f8c856f36",
              "IPY_MODEL_f779f3a4d7944e74ad36cec94ff31597",
              "IPY_MODEL_bdf5b3622da145fba486567d5cac86e1"
            ],
            "layout": "IPY_MODEL_e6d64e4588b74a96b251c05796dc9ddb"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
